WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.196869 139672523310912 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.197590 139672523310912 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.198016: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.208133 140183310444352 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.208824 140183310444352 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.209232: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.261599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.271412: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.272051: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c45a825ec0 executing computations on platform Host. Devices:
2019-07-29 05:34:06.272080: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.273423: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.273451: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.274536: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2228
W0729 05:34:06.274670 140183310444352 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

2019-07-29 05:34:06.275480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560c7049e1f0 executing computations on platform Host. Devices:
2019-07-29 05:34:06.275515: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
W0729 05:34:06.275552 140183310444352 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.276162 140183310444352 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-07-29 05:34:06.276950: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.276981: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.278082: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2224
W0729 05:34:06.278223 139672523310912 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.278889 139672523310912 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.279672 139672523310912 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.296204 140183310444352 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.300707 139672523310912 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.305881 140464643467072 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.306428 140464643467072 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.306785: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
W0729 05:34:06.308280 139672523310912 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.314081 139672523310912 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.327321 140183310444352 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.335470 140183310444352 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2019-07-29 05:34:06.339515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.340075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55696982df00 executing computations on platform Host. Devices:
2019-07-29 05:34:06.340103: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.341267: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.341290: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.342709: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2226
W0729 05:34:06.342851 140464643467072 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.343621 140464643467072 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.344092 140464643467072 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.349394 140464643467072 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.364171 140464643467072 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.368707 140464643467072 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.443465 139847427397440 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.444195 139847427397440 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.444654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.457584 140254835648320 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.458111 140254835648320 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.458471: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.467518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.467980: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5583766b6a90 executing computations on platform Host. Devices:
2019-07-29 05:34:06.468004: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.469339: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.469366: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.470365: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2235
W0729 05:34:06.470499 139847427397440 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.471095 139847427397440 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.471465 139847427397440 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.475859 139847427397440 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2019-07-29 05:34:06.478762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.479383: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56381ec15c20 executing computations on platform Host. Devices:
2019-07-29 05:34:06.479411: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.480544: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.480567: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.481341: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2233
W0729 05:34:06.481284 139847427397440 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.481457 140254835648320 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.481986 140254835648320 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.482294 140254835648320 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.485554 139847427397440 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.486566 140254835648320 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.492033 140254835648320 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.495838 139840264374080 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.496549 139840264374080 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.496949: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
W0729 05:34:06.502803 140254835648320 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.513609 140249698912064 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.514331 140249698912064 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.514748: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.529642 139949914994496 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.530282 139949914994496 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.530694: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.539653: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.540242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a7364e3f90 executing computations on platform Host. Devices:
2019-07-29 05:34:06.540272: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.541634: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.541661: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.542647: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2232
W0729 05:34:06.542777 139840264374080 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.543021 139860167440192 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.543659 139860167440192 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.544033: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.551616: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.551995 139673848579904 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

2019-07-29 05:34:06.552137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b031b51a10 executing computations on platform Host. Devices:
2019-07-29 05:34:06.552170: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
W0729 05:34:06.552712 139673848579904 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.553120: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.553253: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.553274: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.554082: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2238
W0729 05:34:06.554214 140249698912064 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.554782 140249698912064 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.555145 140249698912064 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-07-29 05:34:06.555834: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
W0729 05:34:06.555847 139840264374080 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.556310 139840264374080 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-07-29 05:34:06.556583: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559d693342c0 executing computations on platform Host. Devices:
2019-07-29 05:34:06.556625: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.557976: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.558019: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.558961: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2237
W0729 05:34:06.559108 139949914994496 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.560729 139949914994496 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.561147 139949914994496 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.561209 139840264374080 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.565694 139840264374080 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.566643 139949914994496 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.571185 139840264374080 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.576147 140183310444352 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
2019-07-29 05:34:06.579516: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
W0729 05:34:06.579568 140249698912064 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2019-07-29 05:34:06.580498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557d35a85d40 executing computations on platform Host. Devices:
2019-07-29 05:34:06.580534: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.581868: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.581901: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.582833: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2223
W0729 05:34:06.582978 139860167440192 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.583117 139862653409088 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

2019-07-29 05:34:06.583620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
W0729 05:34:06.583600 139860167440192 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.583860 139862653409088 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

W0729 05:34:06.584045 139860167440192 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-07-29 05:34:06.584220: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563c81e1c800 executing computations on platform Host. Devices:
2019-07-29 05:34:06.584248: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.584256: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
W0729 05:34:06.585494 140249698912064 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
2019-07-29 05:34:06.585761: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.585792: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
W0729 05:34:06.584905 139949914994496 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
2019-07-29 05:34:06.587024: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2227
W0729 05:34:06.587167 139673848579904 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.587857 139673848579904 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.588261 139673848579904 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.589697 139860167440192 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.593330 139673848579904 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.594725 139860167440192 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.595861 140249698912064 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.596594 139949914994496 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.599466 140448530392896 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.600140 140448530392896 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.600468: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
W0729 05:34:06.603164 139672523310912 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.606369 139673848579904 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.611433 139860167440192 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.611802 140284647970624 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.612482 140284647970624 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.612879: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.614053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.614495: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5582c68fc820 executing computations on platform Host. Devices:
2019-07-29 05:34:06.614515: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.616861 140590952777536 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

2019-07-29 05:34:06.617624: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.617659: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
W0729 05:34:06.617602 140590952777536 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.618047: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.619734: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2231
W0729 05:34:06.619879 139862653409088 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.620523 139862653409088 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.620925 139862653409088 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-07-29 05:34:06.623724: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
W0729 05:34:06.623994 139673848579904 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2019-07-29 05:34:06.624321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bd27e35c10 executing computations on platform Host. Devices:
2019-07-29 05:34:06.624347: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.625614: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.625641: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
W0729 05:34:06.625736 139862653409088 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2019-07-29 05:34:06.626723: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2229
W0729 05:34:06.626855 140448530392896 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.628742 140448530392896 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.629193 140448530392896 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.633872 140448530392896 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.649615 140609202640704 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.650261 140609202640704 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.650613: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.651561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.652139: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f7c5fa0760 executing computations on platform Host. Devices:
2019-07-29 05:34:06.652167: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.653520: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.653546: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.655519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.655771: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2225
W0729 05:34:06.655664 140448530392896 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.655900 140284647970624 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

2019-07-29 05:34:06.656148: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc6c156ea0 executing computations on platform Host. Devices:
2019-07-29 05:34:06.656172: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
W0729 05:34:06.656501 140284647970624 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.656863 140284647970624 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-07-29 05:34:06.657618: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.657642: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
W0729 05:34:06.657616 139862653409088 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
2019-07-29 05:34:06.658946: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2230
W0729 05:34:06.659075 140590952777536 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.659719 140590952777536 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.660010 140448530392896 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.660161 140590952777536 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.660354 140177118873408 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.661039 140177118873408 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.661426: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
W0729 05:34:06.667375 140284647970624 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.669576 139862653409088 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.672402 140284647970624 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.679026 140284647970624 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.681898 140464643467072 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
2019-07-29 05:34:06.683498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
WARNING: Logging before flag parsing goes to stderr.
W0729 05:34:06.685716 140494089393984 deprecation_wrapper.py:119] From trainer.py:188: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0729 05:34:06.686358 140494089393984 deprecation_wrapper.py:119] From trainer.py:22: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.

2019-07-29 05:34:06.686727: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-07-29 05:34:06.687612: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.687990: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594c3f94580 executing computations on platform Host. Devices:
2019-07-29 05:34:06.688021: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.688327: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e385bb4330 executing computations on platform Host. Devices:
2019-07-29 05:34:06.688353: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-29 05:34:06.689379: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.689408: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
2019-07-29 05:34:06.689633: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.689657: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
W0729 05:34:06.690394 140590952777536 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2019-07-29 05:34:06.691603: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2222
2019-07-29 05:34:06.691811: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2236
W0729 05:34:06.691946 140177118873408 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.692642 140177118873408 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.693049 140177118873408 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.698232 140590952777536 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.698295 140177118873408 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2019-07-29 05:34:06.715807: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-07-29 05:34:06.716438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563b7cf70380 executing computations on platform Host. Devices:
2019-07-29 05:34:06.716471: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
W0729 05:34:06.718075 140590952777536 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2019-07-29 05:34:06.718370: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2019-07-29 05:34:06.718398: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226, 4 -> localhost:2227, 5 -> localhost:2228, 6 -> localhost:2229, 7 -> localhost:2230, 8 -> localhost:2231, 9 -> localhost:2232, 10 -> localhost:2233, 11 -> localhost:2234, 12 -> localhost:2235, 13 -> localhost:2236, 14 -> localhost:2237, 15 -> localhost:2238}
W0729 05:34:06.720062 140177118873408 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
2019-07-29 05:34:06.720218: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2234
W0729 05:34:06.720393 140494089393984 deprecation_wrapper.py:119] From trainer.py:30: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.

W0729 05:34:06.721058 140494089393984 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:45: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0729 05:34:06.721447 140494089393984 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:46: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0729 05:34:06.729188 140177118873408 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.750310 140494089393984 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:53: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0729 05:34:06.755496 140494089393984 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0729 05:34:06.760210 139847427397440 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.768470 140494089393984 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:06.784901 139672523310912 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:06.791087 140254835648320 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.832323 140183310444352 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:06.869311 139860167440192 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.888235 139840264374080 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.892914 139862653409088 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.897091 140249698912064 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.912911 140284647970624 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.915383 140464643467072 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:06.925103 140590952777536 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.927502 139949914994496 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.943664 139673848579904 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.989822 140448530392896 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:06.993303 139847427397440 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.003973 139860167440192 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.028362 139862653409088 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.042091 140254835648320 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.047341 140177118873408 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:07.047771 140284647970624 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.059846 140590952777536 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.073053 140494089393984 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0729 05:34:07.139644 139840264374080 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.150871 140249698912064 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.178247 139949914994496 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.194744 139673848579904 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.236726 140448530392896 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.257237 139672523310912 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.283306 139860167440192 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.290930 140177118873408 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.311152 139862653409088 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.313611 140183310444352 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.321029 140494089393984 deprecation.py:323] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0729 05:34:07.326596 140284647970624 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.340299 140590952777536 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.369000 139860167440192 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.387767 139672523310912 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.394762 140464643467072 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.398199 139862653409088 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.412424 140284647970624 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.426172 140590952777536 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.445776 140183310444352 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.468013 139847427397440 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.468830 139860167440192 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.501142 139862653409088 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.513065 140284647970624 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.517241 140254835648320 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.527541 140590952777536 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.527799 140464643467072 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.543802 139672523310912 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.599763 140183310444352 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.601930 139847427397440 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.621131 139840264374080 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.643733 140249698912064 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.653839 140254835648320 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.665669 139949914994496 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.678495 139673848579904 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.682592 140464643467072 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.720911 140448530392896 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.757320 139847427397440 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.760173 139840264374080 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.778085 140177118873408 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.781936 140249698912064 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.806462 139949914994496 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.809437 140494089393984 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/vtrace.py:57: The name tf.log is deprecated. Please use tf.math.log instead.

W0729 05:34:07.818270 140254835648320 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.818645 139673848579904 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.858721 140448530392896 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.916799 140177118873408 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.924155 139840264374080 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.944854 140249698912064 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.948836 140494089393984 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/a3c_training_thread.py:74: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0729 05:34:07.972192 139949914994496 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:07.983781 139673848579904 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:08.020132 140448530392896 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:08.080829 140177118873408 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:08.111860 140494089393984 deprecation.py:506] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0729 05:34:14.412075 139860167440192 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:14.412249 139860167440192 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:14.427814 139860167440192 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:14.485196 140284647970624 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:14.485391 140284647970624 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:14.501192 140284647970624 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:14.518559 140590952777536 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:14.518744 140590952777536 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:14.534479 140590952777536 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:14.757696 140183310444352 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:14.757868 140183310444352 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:14.757878 139860167440192 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:14.773716 140183310444352 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:14.832376 140284647970624 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:14.865157 140590952777536 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:15.014577 139860167440192 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:15.090216 140284647970624 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:15.104887 140183310444352 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:15.121717 140590952777536 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:15.361194 140183310444352 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
I0729 05:34:15.599252 140284647970624 session_manager.py:500] Running local_init_op.
I0729 05:34:15.631364 140590952777536 session_manager.py:500] Running local_init_op.
I0729 05:34:16.122112 140183310444352 session_manager.py:500] Running local_init_op.
2019-07-29 05:34:16.387021: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:16.388384 140284647970624 session_manager.py:502] Done running local_init_op.
2019-07-29 05:34:16.402598: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:16.403815 140590952777536 session_manager.py:502] Done running local_init_op.
2019-07-29 05:34:16.864573: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:16.865556 140183310444352 session_manager.py:502] Done running local_init_op.
I0729 05:34:17.504102 140590952777536 session_manager.py:436] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: net_global/impala/conv2d/kernel, net_global/impala/conv2d/bias, net_global/impala/conv2d_1/kernel, net_global/impala/conv2d_1/bias, net_global/impala/conv2d_2/kernel, net_global/impala/conv2d_2/bias, net_global/impala/dense/kernel, net_global/impala/dense/bias, net_global/impala/dense_1/kernel, net_global/impala/dense_1/bias, net_global/impala/dense_2/kernel, net_global/impala/dense_2/bias, net_global/net_global/impala/conv2d/kernel/RMSProp, net_global/net_global/impala/conv2d/kernel/RMSProp_1, net_global/net_global/impala/conv2d/bias/RMSProp, net_global/net_global/impala/conv2d/bias/RMSProp_1, net_global/net_global/impala/conv2d_1/kernel/RMSProp, net_global/net_global/impala/conv2d_1/kernel/RMSProp_1, net_global/net_global/impala/conv2d_1/bias/RMSProp, net_global/net_global/impala/conv2d_1/bias/RMSProp_1, net_global/net_global/impala/conv2d_2/kernel/RMSProp, net_global/net_global/impala/conv2d_2/kernel/RMSProp_1, net_global/net_global/impala/conv2d_2/bias/RMSProp, net_global/net_global/impala/conv2d_2/bias/RMSProp_1, net_global/net_global/impala/dense/kernel/RMSProp, net_global/net_global/impala/dense/kernel/RMSProp_1, net_global/net_global/impala/dense/bias/RMSProp, net_global/net_global/impala/dense/bias/RMSProp_1, net_global/net_global/impala/dense_1/kernel/RMSProp, net_global/net_global/impala/dense_1/kernel/RMSProp_1, net_global/net_global/impala/dense_1/bias/RMSProp, net_global/net_global/impala/dense_1/bias/RMSProp_1, net_global/net_global/impala/dense_2/kernel/RMSProp, net_global/net_global/impala/dense_2/kernel/RMSProp_1, net_global/net_global/impala/dense_2/bias/RMSProp, net_global/net_global/impala/dense_2/bias/RMSProp_1, net_0/impala/conv2d/kernel, net_0/impala/conv2d/bias, net_0/impala/conv2d_1/kernel, net_0/impala/conv2d_1/bias, net_0/impala/conv2d_2/kernel, net_0/impala/conv2d_2/bias, net_0/impala/dense/kernel, net_0/impala/dense/bias, net_0/impala/dense_1/kernel, net_0/impala/dense_1/bias, net_0/impala/dense_2/kernel, net_0/impala/dense_2/bias, net_0/net_0/impala/conv2d/kernel/RMSProp, net_0/net_0/impala/conv2d/kernel/RMSProp_1, net_0/net_0/impala/conv2d/bias/RMSProp, net_0/net_0/impala/conv2d/bias/RMSProp_1, net_0/net_0/impala/conv2d_1/kernel/RMSProp, net_0/net_0/impala/conv2d_1/kernel/RMSProp_1, net_0/net_0/impala/conv2d_1/bias/RMSProp, net_0/net_0/impala/conv2d_1/bias/RMSProp_1, net_0/net_0/impala/conv2d_2/kernel/RMSProp, net_0/net_0/impala/conv2d_2/kernel/RMSProp_1, net_0/net_0/impala/conv2d_2/bias/RMSProp, net_0/net_0/impala/conv2d_2/bias/RMSProp_1, net_0/net_0/impala/dense/kernel/RMSProp, net_0/net_0/impala/dense/kernel/RMSProp_1, net_0/net_0/impala/dense/bias/RMSProp, net_0/net_0/impala/dense/bias/RMSProp_1, net_0/net_0/impala/dense_1/kernel/RMSProp, net_0/net_0/impala/dense_1/kernel/RMSProp_1, net_0/net_0/impala/dense_1/bias/RMSProp, net_0/net_0/impala/dense_1/bias/RMSProp_1, net_0/net_0/impala/dense_2/kernel/RMSProp, net_0/net_0/impala/dense_2/kernel/RMSProp_1, net_0/net_0/impala/dense_2/bias/RMSProp, net_0/net_0/impala/dense_2/bias/RMSProp_1, net_1/impala/conv2d/kernel, net_1/impala/conv2d/bias, net_1/impala/conv2d_1/kernel, net_1/impala/conv2d_1/bias, net_1/impala/conv2d_2/kernel, net_1/impala/conv2d_2/bias, net_1/impala/dense/kernel, net_1/impala/dense/bias, net_1/impala/dense_1/kernel, net_1/impala/dense_1/bias, net_1/impala/dense_2/kernel, net_1/impala/dense_2/bias, net_1/net_1/impala/conv2d/kernel/RMSProp, net_1/net_1/impala/conv2d/kernel/RMSProp_1, net_1/net_1/impala/conv2d/bias/RMSProp, net_1/net_1/impala/conv2d/bias/RMSProp_1, net_1/net_1/impala/conv2d_1/kernel/RMSProp, net_1/net_1/impala/conv2d_1/kernel/RMSProp_1, net_1/net_1/impala/conv2d_1/bias/RMSProp, net_1/net_1/impala/conv2d_1/bias/RMSProp_1, net_1/net_1/impala/conv2d_2/kernel/RMSProp, net_1/net_1/impala/conv2d_2/kernel/RMSProp_1, net_1/net_1/impala/conv2d_2/bias/RMSProp, net_1/net_1/impala/conv2d_2/bias/RMSProp_1, net_1/net_1/impala/dense/kernel/RMSProp, net_1/net_1/impala/dense/kernel/RMSProp_1, net_1/net_1/impala/dense/bias/RMSProp, net_1/net_1/impala/dense/bias/RMSProp_1, net_1/net_1/impala/dense_1/kernel/RMSProp, net_1/net_1/impala/dense_1/kernel/RMSProp_1, net_1/net_1/impala/dense_1/bias/RMSProp, net_1/net_1/impala/dense_1/bias/RMSProp_1, net_1/net_1/impala/dense_2/kernel/RMSProp, net_1/net_1/impala/dense_2/kernel/RMSProp_1, net_1/net_1/impala/dense_2/bias/RMSProp, net_1/net_1/impala/dense_2/bias/RMSProp_1, net_2/impala/conv2d/kernel, net_2/impala/conv2d/bias, net_2/impala/conv2d_1/kernel, net_2/impala/conv2d_1/bias, net_2/impala/conv2d_2/kernel, net_2/impala/conv2d_2/bias, net_2/impala/dense/kernel, net_2/impala/dense/bias, net_2/impala/dense_1/kernel, net_2/impala/dense_1/bias, net_2/impala/dense_2/kernel, net_2/impala/dense_2/bias, net_2/net_2/impala/conv2d/kernel/RMSProp, net_2/net_2/impala/conv2d/kernel/RMSProp_1, net_2/net_2/impala/conv2d/bias/RMSProp, net_2/net_2/impala/conv2d/bias/RMSProp_1, net_2/net_2/impala/conv2d_1/kernel/RMSProp, net_2/net_2/impala/conv2d_1/kernel/RMSProp_1, net_2/net_2/impala/conv2d_1/bias/RMSProp, net_2/net_2/impala/conv2d_1/bias/RMSProp_1, net_2/net_2/impala/conv2d_2/kernel/RMSProp, net_2/net_2/impala/conv2d_2/kernel/RMSProp_1, net_2/net_2/impala/conv2d_2/bias/RMSProp, net_2/net_2/impala/conv2d_2/bias/RMSProp_1, net_2/net_2/impala/dense/kernel/RMSProp, net_2/net_2/impala/dense/kernel/RMSProp_1, net_2/net_2/impala/dense/bias/RMSProp, net_2/net_2/impala/dense/bias/RMSProp_1, net_2/net_2/impala/dense_1/kernel/RMSProp, net_2/net_2/impala/dense_1/kernel/RMSProp_1, net_2/net_2/impala/dense_1/bias/RMSProp, net_2/net_2/impala/dense_1/bias/RMSProp_1, net_2/net_2/impala/dense_2/kernel/RMSProp, net_2/net_2/impala/dense_2/kernel/RMSProp_1, net_2/net_2/impala/dense_2/bias/RMSProp, net_2/net_2/impala/dense_2/bias/RMSProp_1, net_3/impala/conv2d/kernel, net_3/impala/conv2d/bias, net_3/impala/conv2d_1/kernel, net_3/impala/conv2d_1/bias, net_3/impala/conv2d_2/kernel, net_3/impala/conv2d_2/bias, net_3/impala/dense/kernel, net_3/impala/dense/bias, net_3/impala/dense_1/kernel, net_3/impala/dense_1/bias, net_3/impala/dense_2/kernel, net_3/impala/dense_2/bias, net_3/net_3/impala/conv2d/kernel/RMSProp, net_3/net_3/impala/conv2d/kernel/RMSProp_1, net_3/net_3/impala/conv2d/bias/RMSProp, net_3/net_3/impala/conv2d/bias/RMSProp_1, net_3/net_3/impala/conv2d_1/kernel/RMSProp, net_3/net_3/impala/conv2d_1/kernel/RMSProp_1, net_3/net_3/impala/conv2d_1/bias/RMSProp, net_3/net_3/impala/conv2d_1/bias/RMSProp_1, net_3/net_3/impala/conv2d_2/kernel/RMSProp, net_3/net_3/impala/conv2d_2/kernel/RMSProp_1, net_3/net_3/impala/conv2d_2/bias/RMSProp, net_3/net_3/impala/conv2d_2/bias/RMSProp_1, net_3/net_3/impala/dense/kernel/RMSProp, net_3/net_3/impala/dense/kernel/RMSProp_1, net_3/net_3/impala/dense/bias/RMSProp, net_3/net_3/impala/dense/bias/RMSProp_1, net_3/net_3/impala/dense_1/kernel/RMSProp, net_3/net_3/impala/dense_1/kernel/RMSProp_1, net_3/net_3/impala/dense_1/bias/RMSProp, net_3/net_3/impala/dense_1/bias/RMSProp_1, net_3/net_3/impala/dense_2/kernel/RMSProp, net_3/net_3/impala/dense_2/kernel/RMSProp_1, net_3/net_3/impala/dense_2/bias/RMSProp, net_3/net_3/impala/dense_2/bias/RMSProp_1, net_4/impala/conv2d/kernel, net_4/impala/conv2d/bias, net_4/impala/conv2d_1/kernel, net_4/impala/conv2d_1/bias, net_4/impala/conv2d_2/kernel, net_4/impala/conv2d_2/bias, net_4/impala/dense/kernel, net_4/impala/dense/bias, net_4/impala/dense_1/kernel, net_4/impala/dense_1/bias, net_4/impala/dense_2/kernel, net_4/impala/dense_2/bias, net_4/net_4/impala/conv2d/kernel/RMSProp, net_4/net_4/impala/conv2d/kernel/RMSProp_1, net_4/net_4/impala/conv2d/bias/RMSProp, net_4/net_4/impala/conv2d/bias/RMSProp_1, net_4/net_4/impala/conv2d_1/kernel/RMSProp, net_4/net_4/impala/conv2d_1/kernel/RMSProp_1, net_4/net_4/impala/conv2d_1/bias/RMSProp, net_4/net_4/impala/conv2d_1/bias/RMSProp_1, net_4/net_4/impala/conv2d_2/kernel/RMSProp, net_4/net_4/impala/conv2d_2/kernel/RMSProp_1, net_4/net_4/impala/conv2d_2/bias/RMSProp, net_4/net_4/impala/conv2d_2/bias/RMSProp_1, net_4/net_4/impala/dense/kernel/RMSProp, net_4/net_4/impala/dense/kernel/RMSProp_1, net_4/net_4/impala/dense/bias/RMSProp, net_4/net_4/impala/dense/bias/RMSProp_1, net_4/net_4/impala/dense_1/kernel/RMSProp, net_4/net_4/impala/dense_1/kernel/RMSProp_1, net_4/net_4/impala/dense_1/bias/RMSProp, net_4/net_4/impala/dense_1/bias/RMSProp_1, net_4/net_4/impala/dense_2/kernel/RMSProp, net_4/net_4/impala/dense_2/kernel/RMSProp_1, net_4/net_4/impala/dense_2/bias/RMSProp, net_4/net_4/impala/dense_2/bias/RMSProp_1, net_5/impala/conv2d/kernel, net_5/impala/conv2d/bias, net_5/impala/conv2d_1/kernel, net_5/impala/conv2d_1/bias, net_5/impala/conv2d_2/kernel, net_5/impala/conv2d_2/bias, net_5/impala/dense/kernel, net_5/impala/dense/bias, net_5/impala/dense_1/kernel, net_5/impala/dense_1/bias, net_5/impala/dense_2/kernel, net_5/impala/dense_2/bias, net_5/net_5/impala/conv2d/kernel/RMSProp, net_5/net_5/impala/conv2d/kernel/RMSProp_1, net_5/net_5/impala/conv2d/bias/RMSProp, net_5/net_5/impala/conv2d/bias/RMSProp_1, net_5/net_5/impala/conv2d_1/kernel/RMSProp, net_5/net_5/impala/conv2d_1/kernel/RMSProp_1, net_5/net_5/impala/conv2d_1/bias/RMSProp, net_5/net_5/impala/conv2d_1/bias/RMSProp_1, net_5/net_5/impala/conv2d_2/kernel/RMSProp, net_5/net_5/impala/conv2d_2/kernel/RMSProp_1, net_5/net_5/impala/conv2d_2/bias/RMSProp, net_5/net_5/impala/conv2d_2/bias/RMSProp_1, net_5/net_5/impala/dense/kernel/RMSProp, net_5/net_5/impala/dense/kernel/RMSProp_1, net_5/net_5/impala/dense/bias/RMSProp, net_5/net_5/impala/dense/bias/RMSProp_1, net_5/net_5/impala/dense_1/kernel/RMSProp, net_5/net_5/impala/dense_1/kernel/RMSProp_1, net_5/net_5/impala/dense_1/bias/RMSProp, net_5/net_5/impala/dense_1/bias/RMSProp_1, net_5/net_5/impala/dense_2/kernel/RMSProp, net_5/net_5/impala/dense_2/kernel/RMSProp_1, net_5/net_5/impala/dense_2/bias/RMSProp, net_5/net_5/impala/dense_2/bias/RMSProp_1, net_6/impala/conv2d/kernel, net_6/impala/conv2d/bias, net_6/impala/conv2d_1/kernel, net_6/impala/conv2d_1/bias, net_6/impala/conv2d_2/kernel, net_6/impala/conv2d_2/bias, net_6/impala/dense/kernel, net_6/impala/dense/bias, net_6/impala/dense_1/kernel, net_6/impala/dense_1/bias, net_6/impala/dense_2/kernel, net_6/impala/dense_2/bias, net_6/net_6/impala/conv2d/kernel/RMSProp, net_6/net_6/impala/conv2d/kernel/RMSProp_1, net_6/net_6/impala/conv2d/bias/RMSProp, net_6/net_6/impala/conv2d/bias/RMSProp_1, net_6/net_6/impala/conv2d_1/kernel/RMSProp, net_6/net_6/impala/conv2d_1/kernel/RMSProp_1, net_6/net_6/impala/conv2d_1/bias/RMSProp, net_6/net_6/impala/conv2d_1/bias/RMSProp_1, net_6/net_6/impala/conv2d_2/kernel/RMSProp, net_6/net_6/impala/conv2d_2/kernel/RMSProp_1, net_6/net_6/impala/conv2d_2/bias/RMSProp, net_6/net_6/impala/conv2d_2/bias/RMSProp_1, net_6/net_6/impala/dense/kernel/RMSProp, net_6/net_6/impala/dense/kernel/RMSProp_1, net_6/net_6/impala/dense/bias/RMSProp, net_6/net_6/impala/dense/bias/RMSProp_1, net_6/net_6/impala/dense_1/kernel/RMSProp, net_6/net_6/impala/dense_1/kernel/RMSProp_1, net_6/net_6/impala/dense_1/bias/RMSProp, net_6/net_6/impala/dense_1/bias/RMSProp_1, net_6/net_6/impala/dense_2/kernel/RMSProp, net_6/net_6/impala/dense_2/kernel/RMSProp_1, net_6/net_6/impala/dense_2/bias/RMSProp, net_6/net_6/impala/dense_2/bias/RMSProp_1, net_7/impala/conv2d/kernel, net_7/impala/conv2d/bias, net_7/impala/conv2d_1/kernel, net_7/impala/conv2d_1/bias, net_7/impala/conv2d_2/kernel, net_7/impala/conv2d_2/bias, net_7/impala/dense/kernel, net_7/impala/dense/bias, net_7/impala/dense_1/kernel, net_7/impala/dense_1/bias, net_7/impala/dense_2/kernel, net_7/impala/dense_2/bias, net_7/net_7/impala/conv2d/kernel/RMSProp, net_7/net_7/impala/conv2d/kernel/RMSProp_1, net_7/net_7/impala/conv2d/bias/RMSProp, net_7/net_7/impala/conv2d/bias/RMSProp_1, net_7/net_7/impala/conv2d_1/kernel/RMSProp, net_7/net_7/impala/conv2d_1/kernel/RMSProp_1, net_7/net_7/impala/conv2d_1/bias/RMSProp, net_7/net_7/impala/conv2d_1/bias/RMSProp_1, net_7/net_7/impala/conv2d_2/kernel/RMSProp, net_7/net_7/impala/conv2d_2/kernel/RMSProp_1, net_7/net_7/impala/conv2d_2/bias/RMSProp, net_7/net_7/impala/conv2d_2/bias/RMSProp_1, net_7/net_7/impala/dense/kernel/RMSProp, net_7/net_7/impala/dense/kernel/RMSProp_1, net_7/net_7/impala/dense/bias/RMSProp, net_7/net_7/impala/dense/bias/RMSProp_1, net_7/net_7/impala/dense_1/kernel/RMSProp, net_7/net_7/impala/dense_1/kernel/RMSProp_1, net_7/net_7/impala/dense_1/bias/RMSProp, net_7/net_7/impala/dense_1/bias/RMSProp_1, net_7/net_7/impala/dense_2/kernel/RMSProp, net_7/net_7/impala/dense_2/kernel/RMSProp_1, net_7/net_7/impala/dense_2/bias/RMSProp, net_7/net_7/impala/dense_2/bias/RMSProp_1, net_8/impala/conv2d/kernel, net_8/impala/conv2d/bias, net_8/impala/conv2d_1/kernel, net_8/impala/conv2d_1/bias, net_8/impala/conv2d_2/kernel, net_8/impala/conv2d_2/bias, net_8/impala/dense/kernel, net_8/impala/dense/bias, net_8/impala/dense_1/kernel, net_8/impala/dense_1/bias, net_8/impala/dense_2/kernel, net_8/impala/dense_2/bias, net_8/net_8/impala/conv2d/kernel/RMSProp, net_8/net_8/impala/conv2d/kernel/RMSProp_1, net_8/net_8/impala/conv2d/bias/RMSProp, net_8/net_8/impala/conv2d/bias/RMSProp_1, net_8/net_8/impala/conv2d_1/kernel/RMSProp, net_8/net_8/impala/conv2d_1/kernel/RMSProp_1, net_8/net_8/impala/conv2d_1/bias/RMSProp, net_8/net_8/impala/conv2d_1/bias/RMSProp_1, net_8/net_8/impala/conv2d_2/kernel/RMSProp, net_8/net_8/impala/conv2d_2/kernel/RMSProp_1, net_8/net_8/impala/conv2d_2/bias/RMSProp, net_8/net_8/impala/conv2d_2/bias/RMSProp_1, net_8/net_8/impala/dense/kernel/RMSProp, net_8/net_8/impala/dense/kernel/RMSProp_1, net_8/net_8/impala/dense/bias/RMSProp, net_8/net_8/impala/dense/bias/RMSProp_1, net_8/net_8/impala/dense_1/kernel/RMSProp, net_8/net_8/impala/dense_1/kernel/RMSProp_1, net_8/net_8/impala/dense_1/bias/RMSProp, net_8/net_8/impala/dense_1/bias/RMSProp_1, net_8/net_8/impala/dense_2/kernel/RMSProp, net_8/net_8/impala/dense_2/kernel/RMSProp_1, net_8/net_8/impala/dense_2/bias/RMSProp, net_8/net_8/impala/dense_2/bias/RMSProp_1, net_9/impala/conv2d/kernel, net_9/impala/conv2d/bias, net_9/impala/conv2d_1/kernel, net_9/impala/conv2d_1/bias, net_9/impala/conv2d_2/kernel, net_9/impala/conv2d_2/bias, net_9/impala/dense/kernel, net_9/impala/dense/bias, net_9/impala/dense_1/kernel, net_9/impala/dense_1/bias, net_9/impala/dense_2/kernel, net_9/impala/dense_2/bias, net_9/net_9/impala/conv2d/kernel/RMSProp, net_9/net_9/impala/conv2d/kernel/RMSProp_1, net_9/net_9/impala/conv2d/bias/RMSProp, net_9/net_9/impala/conv2d/bias/RMSProp_1, net_9/net_9/impala/conv2d_1/kernel/RMSProp, net_9/net_9/impala/conv2d_1/kernel/RMSProp_1, net_9/net_9/impala/conv2d_1/bias/RMSProp, net_9/net_9/impala/conv2d_1/bias/RMSProp_1, net_9/net_9/impala/conv2d_2/kernel/RMSProp, net_9/net_9/impala/conv2d_2/kernel/RMSProp_1, net_9/net_9/impala/conv2d_2/bias/RMSProp, net_9/net_9/impala/conv2d_2/bias/RMSProp_1, net_9/net_9/impala/dense/kernel/RMSProp, net_9/net_9/impala/dense/kernel/RMSProp_1, net_9/net_9/impala/dense/bias/RMSProp, net_9/net_9/impala/dense/bias/RMSProp_1, net_9/net_9/impala/dense_1/kernel/RMSProp, net_9/net_9/impala/dense_1/kernel/RMSProp_1, net_9/net_9/impala/dense_1/bias/RMSProp, net_9/net_9/impala/dense_1/bias/RMSProp_1, net_9/net_9/impala/dense_2/kernel/RMSProp, net_9/net_9/impala/dense_2/kernel/RMSProp_1, net_9/net_9/impala/dense_2/bias/RMSProp, net_9/net_9/impala/dense_2/bias/RMSProp_1, net_10/impala/conv2d/kernel, net_10/impala/conv2d/bias, net_10/impala/conv2d_1/kernel, net_10/impala/conv2d_1/bias, net_10/impala/conv2d_2/kernel, net_10/impala/conv2d_2/bias, net_10/impala/dense/kernel, net_10/impala/dense/bias, net_10/impala/dense_1/kernel, net_10/impala/dense_1/bias, net_10/impala/dense_2/kernel, net_10/impala/dense_2/bias, net_10/net_10/impala/conv2d/kernel/RMSProp, net_10/net_10/impala/conv2d/kernel/RMSProp_1, net_10/net_10/impala/conv2d/bias/RMSProp, net_10/net_10/impala/conv2d/bias/RMSProp_1, net_10/net_10/impala/conv2d_1/kernel/RMSProp, net_10/net_10/impala/conv2d_1/kernel/RMSProp_1, net_10/net_10/impala/conv2d_1/bias/RMSProp, net_10/net_10/impala/conv2d_1/bias/RMSProp_1, net_10/net_10/impala/conv2d_2/kernel/RMSProp, net_10/net_10/impala/conv2d_2/kernel/RMSProp_1, net_10/net_10/impala/conv2d_2/bias/RMSProp, net_10/net_10/impala/conv2d_2/bias/RMSProp_1, net_10/net_10/impala/dense/kernel/RMSProp, net_10/net_10/impala/dense/kernel/RMSProp_1, net_10/net_10/impala/dense/bias/RMSProp, net_10/net_10/impala/dense/bias/RMSProp_1, net_10/net_10/impala/dense_1/kernel/RMSProp, net_10/net_10/impala/dense_1/kernel/RMSProp_1, net_10/net_10/impala/dense_1/bias/RMSProp, net_10/net_10/impala/dense_1/bias/RMSProp_1, net_10/net_10/impala/dense_2/kernel/RMSProp, net_10/net_10/impala/dense_2/kernel/RMSProp_1, net_10/net_10/impala/dense_2/bias/RMSProp, net_10/net_10/impala/dense_2/bias/RMSProp_1, net_11/impala/conv2d/kernel, net_11/impala/conv2d/bias, net_11/impala/conv2d_1/kernel, net_11/impala/conv2d_1/bias, net_11/impala/conv2d_2/kernel, net_11/impala/conv2d_2/bias, net_11/impala/dense/kernel, net_11/impala/dense/bias, net_11/impala/dense_1/kernel, net_11/impala/dense_1/bias, net_11/impala/dense_2/kernel, net_11/impala/dense_2/bias, net_11/net_11/impala/conv2d/kernel/RMSProp, net_11/net_11/impala/conv2d/kernel/RMSProp_1, net_11/net_11/impala/conv2d/bias/RMSProp, net_11/net_11/impala/conv2d/bias/RMSProp_1, net_11/net_11/impala/conv2d_1/kernel/RMSProp, net_11/net_11/impala/conv2d_1/kernel/RMSProp_1, net_11/net_11/impala/conv2d_1/bias/RMSProp, net_11/net_11/impala/conv2d_1/bias/RMSProp_1, net_11/net_11/impala/conv2d_2/kernel/RMSProp, net_11/net_11/impala/conv2d_2/kernel/RMSProp_1, net_11/net_11/impala/conv2d_2/bias/RMSProp, net_11/net_11/impala/conv2d_2/bias/RMSProp_1, net_11/net_11/impala/dense/kernel/RMSProp, net_11/net_11/impala/dense/kernel/RMSProp_1, net_11/net_11/impala/dense/bias/RMSProp, net_11/net_11/impala/dense/bias/RMSProp_1, net_11/net_11/impala/dense_1/kernel/RMSProp, net_11/net_11/impala/dense_1/kernel/RMSProp_1, net_11/net_11/impala/dense_1/bias/RMSProp, net_11/net_11/impala/dense_1/bias/RMSProp_1, net_11/net_11/impala/dense_2/kernel/RMSProp, net_11/net_11/impala/dense_2/kernel/RMSProp_1, net_11/net_11/impala/dense_2/bias/RMSProp, net_11/net_11/impala/dense_2/bias/RMSProp_1, net_12/impala/conv2d/kernel, net_12/impala/conv2d/bias, net_12/impala/conv2d_1/kernel, net_12/impala/conv2d_1/bias, net_12/impala/conv2d_2/kernel, net_12/impala/conv2d_2/bias, net_12/impala/dense/kernel, net_12/impala/dense/bias, net_12/impala/dense_1/kernel, net_12/impala/dense_1/bias, net_12/impala/dense_2/kernel, net_12/impala/dense_2/bias, net_12/net_12/impala/conv2d/kernel/RMSProp, net_12/net_12/impala/conv2d/kernel/RMSProp_1, net_12/net_12/impala/conv2d/bias/RMSProp, net_12/net_12/impala/conv2d/bias/RMSProp_1, net_12/net_12/impala/conv2d_1/kernel/RMSProp, net_12/net_12/impala/conv2d_1/kernel/RMSProp_1, net_12/net_12/impala/conv2d_1/bias/RMSProp, net_12/net_12/impala/conv2d_1/bias/RMSProp_1, net_12/net_12/impala/conv2d_2/kernel/RMSProp, net_12/net_12/impala/conv2d_2/kernel/RMSProp_1, net_12/net_12/impala/conv2d_2/bias/RMSProp, net_12/net_12/impala/conv2d_2/bias/RMSProp_1, net_12/net_12/impala/dense/kernel/RMSProp, net_12/net_12/impala/dense/kernel/RMSProp_1, net_12/net_12/impala/dense/bias/RMSProp, net_12/net_12/impala/dense/bias/RMSProp_1, net_12/net_12/impala/dense_1/kernel/RMSProp, net_12/net_12/impala/dense_1/kernel/RMSProp_1, net_12/net_12/impala/dense_1/bias/RMSProp, net_12/net_12/impala/dense_1/bias/RMSProp_1, net_12/net_12/impala/dense_2/kernel/RMSProp, net_12/net_12/impala/dense_2/kernel/RMSProp_1, net_12/net_12/impala/dense_2/bias/RMSProp, net_12/net_12/impala/dense_2/bias/RMSProp_1, net_13/impala/conv2d/kernel, net_13/impala/conv2d/bias, net_13/impala/conv2d_1/kernel, net_13/impala/conv2d_1/bias, net_13/impala/conv2d_2/kernel, net_13/impala/conv2d_2/bias, net_13/impala/dense/kernel, net_13/impala/dense/bias, net_13/impala/dense_1/kernel, net_13/impala/dense_1/bias, net_13/impala/dense_2/kernel, net_13/impala/dense_2/bias, net_13/net_13/impala/conv2d/kernel/RMSProp, net_13/net_13/impala/conv2d/kernel/RMSProp_1, net_13/net_13/impala/conv2d/bias/RMSProp, net_13/net_13/impala/conv2d/bias/RMSProp_1, net_13/net_13/impala/conv2d_1/kernel/RMSProp, net_13/net_13/impala/conv2d_1/kernel/RMSProp_1, net_13/net_13/impala/conv2d_1/bias/RMSProp, net_13/net_13/impala/conv2d_1/bias/RMSProp_1, net_13/net_13/impala/conv2d_2/kernel/RMSProp, net_13/net_13/impala/conv2d_2/kernel/RMSProp_1, net_13/net_13/impala/conv2d_2/bias/RMSProp, net_13/net_13/impala/conv2d_2/bias/RMSProp_1, net_13/net_13/impala/dense/kernel/RMSProp, net_13/net_13/impala/dense/kernel/RMSProp_1, net_13/net_13/impala/dense/bias/RMSProp, net_13/net_13/impala/dense/bias/RMSProp_1, net_13/net_13/impala/dense_1/kernel/RMSProp, net_13/net_13/impala/dense_1/kernel/RMSProp_1, net_13/net_13/impala/dense_1/bias/RMSProp, net_13/net_13/impala/dense_1/bias/RMSProp_1, net_13/net_13/impala/dense_2/kernel/RMSProp, net_13/net_13/impala/dense_2/kernel/RMSProp_1, net_13/net_13/impala/dense_2/bias/RMSProp, net_13/net_13/impala/dense_2/bias/RMSProp_1, net_14/impala/conv2d/kernel, net_14/impala/conv2d/bias, net_14/impala/conv2d_1/kernel, net_14/impala/conv2d_1/bias, net_14/impala/conv2d_2/kernel, net_14/impala/conv2d_2/bias, net_14/impala/dense/kernel, net_14/impala/dense/bias, net_14/impala/dense_1/kernel, net_14/impala/dense_1/bias, net_14/impala/dense_2/kernel, net_14/impala/dense_2/bias, net_14/net_14/impala/conv2d/kernel/RMSProp, net_14/net_14/impala/conv2d/kernel/RMSProp_1, net_14/net_14/impala/conv2d/bias/RMSProp, net_14/net_14/impala/conv2d/bias/RMSProp_1, net_14/net_14/impala/conv2d_1/kernel/RMSProp, net_14/net_14/impala/conv2d_1/kernel/RMSProp_1, net_14/net_14/impala/conv2d_1/bias/RMSProp, net_14/net_14/impala/conv2d_1/bias/RMSProp_1, net_14/net_14/impala/conv2d_2/kernel/RMSProp, net_14/net_14/impala/conv2d_2/kernel/RMSProp_1, net_14/net_14/impala/conv2d_2/bias/RMSProp, net_14/net_14/impala/conv2d_2/bias/RMSProp_1, net_14/net_14/impala/dense/kernel/RMSProp, net_14/net_14/impala/dense/kernel/RMSProp_1, net_14/net_14/impala/dense/bias/RMSProp, net_14/net_14/impala/dense/bias/RMSProp_1, net_14/net_14/impala/dense_1/kernel/RMSProp, net_14/net_14/impala/dense_1/kernel/RMSProp_1, net_14/net_14/impala/dense_1/bias/RMSProp, net_14/net_14/impala/dense_1/bias/RMSProp_1, net_14/net_14/impala/dense_2/kernel/RMSProp, net_14/net_14/impala/dense_2/kernel/RMSProp_1, net_14/net_14/impala/dense_2/bias/RMSProp, net_14/net_14/impala/dense_2/bias/RMSProp_1, net_15/impala/conv2d/kernel, net_15/impala/conv2d/bias, net_15/impala/conv2d_1/kernel, net_15/impala/conv2d_1/bias, net_15/impala/conv2d_2/kernel, net_15/impala/conv2d_2/bias, net_15/impala/dense/kernel, net_15/impala/dense/bias, net_15/impala/dense_1/kernel, net_15/impala/dense_1/bias, net_15/impala/dense_2/kernel, net_15/impala/dense_2/bias, net_15/net_15/impala/conv2d/kernel/RMSProp, net_15/net_15/impala/conv2d/kernel/RMSProp_1, net_15/net_15/impala/conv2d/bias/RMSProp, net_15/net_15/impala/conv2d/bias/RMSProp_1, net_15/net_15/impala/conv2d_1/kernel/RMSProp, net_15/net_15/impala/conv2d_1/kernel/RMSProp_1, net_15/net_15/impala/conv2d_1/bias/RMSProp, net_15/net_15/impala/conv2d_1/bias/RMSProp_1, net_15/net_15/impala/conv2d_2/kernel/RMSProp, net_15/net_15/impala/conv2d_2/kernel/RMSProp_1, net_15/net_15/impala/conv2d_2/bias/RMSProp, net_15/net_15/impala/conv2d_2/bias/RMSProp_1, net_15/net_15/impala/dense/kernel/RMSProp, net_15/net_15/impala/dense/kernel/RMSProp_1, net_15/net_15/impala/dense/bias/RMSProp, net_15/net_15/impala/dense/bias/RMSProp_1, net_15/net_15/impala/dense_1/kernel/RMSProp, net_15/net_15/impala/dense_1/kernel/RMSProp_1, net_15/net_15/impala/dense_1/bias/RMSProp, net_15/net_15/impala/dense_1/bias/RMSProp_1, net_15/net_15/impala/dense_2/kernel/RMSProp, net_15/net_15/impala/dense_2/kernel/RMSProp_1, net_15/net_15/impala/dense_2/bias/RMSProp, net_15/net_15/impala/dense_2/bias/RMSProp_1, global_step
I0729 05:34:17.517492 140284647970624 session_manager.py:436] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: net_global/impala/conv2d/kernel, net_global/impala/conv2d/bias, net_global/impala/conv2d_1/kernel, net_global/impala/conv2d_1/bias, net_global/impala/conv2d_2/kernel, net_global/impala/conv2d_2/bias, net_global/impala/dense/kernel, net_global/impala/dense/bias, net_global/impala/dense_1/kernel, net_global/impala/dense_1/bias, net_global/impala/dense_2/kernel, net_global/impala/dense_2/bias, net_global/net_global/impala/conv2d/kernel/RMSProp, net_global/net_global/impala/conv2d/kernel/RMSProp_1, net_global/net_global/impala/conv2d/bias/RMSProp, net_global/net_global/impala/conv2d/bias/RMSProp_1, net_global/net_global/impala/conv2d_1/kernel/RMSProp, net_global/net_global/impala/conv2d_1/kernel/RMSProp_1, net_global/net_global/impala/conv2d_1/bias/RMSProp, net_global/net_global/impala/conv2d_1/bias/RMSProp_1, net_global/net_global/impala/conv2d_2/kernel/RMSProp, net_global/net_global/impala/conv2d_2/kernel/RMSProp_1, net_global/net_global/impala/conv2d_2/bias/RMSProp, net_global/net_global/impala/conv2d_2/bias/RMSProp_1, net_global/net_global/impala/dense/kernel/RMSProp, net_global/net_global/impala/dense/kernel/RMSProp_1, net_global/net_global/impala/dense/bias/RMSProp, net_global/net_global/impala/dense/bias/RMSProp_1, net_global/net_global/impala/dense_1/kernel/RMSProp, net_global/net_global/impala/dense_1/kernel/RMSProp_1, net_global/net_global/impala/dense_1/bias/RMSProp, net_global/net_global/impala/dense_1/bias/RMSProp_1, net_global/net_global/impala/dense_2/kernel/RMSProp, net_global/net_global/impala/dense_2/kernel/RMSProp_1, net_global/net_global/impala/dense_2/bias/RMSProp, net_global/net_global/impala/dense_2/bias/RMSProp_1, net_0/impala/conv2d/kernel, net_0/impala/conv2d/bias, net_0/impala/conv2d_1/kernel, net_0/impala/conv2d_1/bias, net_0/impala/conv2d_2/kernel, net_0/impala/conv2d_2/bias, net_0/impala/dense/kernel, net_0/impala/dense/bias, net_0/impala/dense_1/kernel, net_0/impala/dense_1/bias, net_0/impala/dense_2/kernel, net_0/impala/dense_2/bias, net_0/net_0/impala/conv2d/kernel/RMSProp, net_0/net_0/impala/conv2d/kernel/RMSProp_1, net_0/net_0/impala/conv2d/bias/RMSProp, net_0/net_0/impala/conv2d/bias/RMSProp_1, net_0/net_0/impala/conv2d_1/kernel/RMSProp, net_0/net_0/impala/conv2d_1/kernel/RMSProp_1, net_0/net_0/impala/conv2d_1/bias/RMSProp, net_0/net_0/impala/conv2d_1/bias/RMSProp_1, net_0/net_0/impala/conv2d_2/kernel/RMSProp, net_0/net_0/impala/conv2d_2/kernel/RMSProp_1, net_0/net_0/impala/conv2d_2/bias/RMSProp, net_0/net_0/impala/conv2d_2/bias/RMSProp_1, net_0/net_0/impala/dense/kernel/RMSProp, net_0/net_0/impala/dense/kernel/RMSProp_1, net_0/net_0/impala/dense/bias/RMSProp, net_0/net_0/impala/dense/bias/RMSProp_1, net_0/net_0/impala/dense_1/kernel/RMSProp, net_0/net_0/impala/dense_1/kernel/RMSProp_1, net_0/net_0/impala/dense_1/bias/RMSProp, net_0/net_0/impala/dense_1/bias/RMSProp_1, net_0/net_0/impala/dense_2/kernel/RMSProp, net_0/net_0/impala/dense_2/kernel/RMSProp_1, net_0/net_0/impala/dense_2/bias/RMSProp, net_0/net_0/impala/dense_2/bias/RMSProp_1, net_1/impala/conv2d/kernel, net_1/impala/conv2d/bias, net_1/impala/conv2d_1/kernel, net_1/impala/conv2d_1/bias, net_1/impala/conv2d_2/kernel, net_1/impala/conv2d_2/bias, net_1/impala/dense/kernel, net_1/impala/dense/bias, net_1/impala/dense_1/kernel, net_1/impala/dense_1/bias, net_1/impala/dense_2/kernel, net_1/impala/dense_2/bias, net_1/net_1/impala/conv2d/kernel/RMSProp, net_1/net_1/impala/conv2d/kernel/RMSProp_1, net_1/net_1/impala/conv2d/bias/RMSProp, net_1/net_1/impala/conv2d/bias/RMSProp_1, net_1/net_1/impala/conv2d_1/kernel/RMSProp, net_1/net_1/impala/conv2d_1/kernel/RMSProp_1, net_1/net_1/impala/conv2d_1/bias/RMSProp, net_1/net_1/impala/conv2d_1/bias/RMSProp_1, net_1/net_1/impala/conv2d_2/kernel/RMSProp, net_1/net_1/impala/conv2d_2/kernel/RMSProp_1, net_1/net_1/impala/conv2d_2/bias/RMSProp, net_1/net_1/impala/conv2d_2/bias/RMSProp_1, net_1/net_1/impala/dense/kernel/RMSProp, net_1/net_1/impala/dense/kernel/RMSProp_1, net_1/net_1/impala/dense/bias/RMSProp, net_1/net_1/impala/dense/bias/RMSProp_1, net_1/net_1/impala/dense_1/kernel/RMSProp, net_1/net_1/impala/dense_1/kernel/RMSProp_1, net_1/net_1/impala/dense_1/bias/RMSProp, net_1/net_1/impala/dense_1/bias/RMSProp_1, net_1/net_1/impala/dense_2/kernel/RMSProp, net_1/net_1/impala/dense_2/kernel/RMSProp_1, net_1/net_1/impala/dense_2/bias/RMSProp, net_1/net_1/impala/dense_2/bias/RMSProp_1, net_2/impala/conv2d/kernel, net_2/impala/conv2d/bias, net_2/impala/conv2d_1/kernel, net_2/impala/conv2d_1/bias, net_2/impala/conv2d_2/kernel, net_2/impala/conv2d_2/bias, net_2/impala/dense/kernel, net_2/impala/dense/bias, net_2/impala/dense_1/kernel, net_2/impala/dense_1/bias, net_2/impala/dense_2/kernel, net_2/impala/dense_2/bias, net_2/net_2/impala/conv2d/kernel/RMSProp, net_2/net_2/impala/conv2d/kernel/RMSProp_1, net_2/net_2/impala/conv2d/bias/RMSProp, net_2/net_2/impala/conv2d/bias/RMSProp_1, net_2/net_2/impala/conv2d_1/kernel/RMSProp, net_2/net_2/impala/conv2d_1/kernel/RMSProp_1, net_2/net_2/impala/conv2d_1/bias/RMSProp, net_2/net_2/impala/conv2d_1/bias/RMSProp_1, net_2/net_2/impala/conv2d_2/kernel/RMSProp, net_2/net_2/impala/conv2d_2/kernel/RMSProp_1, net_2/net_2/impala/conv2d_2/bias/RMSProp, net_2/net_2/impala/conv2d_2/bias/RMSProp_1, net_2/net_2/impala/dense/kernel/RMSProp, net_2/net_2/impala/dense/kernel/RMSProp_1, net_2/net_2/impala/dense/bias/RMSProp, net_2/net_2/impala/dense/bias/RMSProp_1, net_2/net_2/impala/dense_1/kernel/RMSProp, net_2/net_2/impala/dense_1/kernel/RMSProp_1, net_2/net_2/impala/dense_1/bias/RMSProp, net_2/net_2/impala/dense_1/bias/RMSProp_1, net_2/net_2/impala/dense_2/kernel/RMSProp, net_2/net_2/impala/dense_2/kernel/RMSProp_1, net_2/net_2/impala/dense_2/bias/RMSProp, net_2/net_2/impala/dense_2/bias/RMSProp_1, net_3/impala/conv2d/kernel, net_3/impala/conv2d/bias, net_3/impala/conv2d_1/kernel, net_3/impala/conv2d_1/bias, net_3/impala/conv2d_2/kernel, net_3/impala/conv2d_2/bias, net_3/impala/dense/kernel, net_3/impala/dense/bias, net_3/impala/dense_1/kernel, net_3/impala/dense_1/bias, net_3/impala/dense_2/kernel, net_3/impala/dense_2/bias, net_3/net_3/impala/conv2d/kernel/RMSProp, net_3/net_3/impala/conv2d/kernel/RMSProp_1, net_3/net_3/impala/conv2d/bias/RMSProp, net_3/net_3/impala/conv2d/bias/RMSProp_1, net_3/net_3/impala/conv2d_1/kernel/RMSProp, net_3/net_3/impala/conv2d_1/kernel/RMSProp_1, net_3/net_3/impala/conv2d_1/bias/RMSProp, net_3/net_3/impala/conv2d_1/bias/RMSProp_1, net_3/net_3/impala/conv2d_2/kernel/RMSProp, net_3/net_3/impala/conv2d_2/kernel/RMSProp_1, net_3/net_3/impala/conv2d_2/bias/RMSProp, net_3/net_3/impala/conv2d_2/bias/RMSProp_1, net_3/net_3/impala/dense/kernel/RMSProp, net_3/net_3/impala/dense/kernel/RMSProp_1, net_3/net_3/impala/dense/bias/RMSProp, net_3/net_3/impala/dense/bias/RMSProp_1, net_3/net_3/impala/dense_1/kernel/RMSProp, net_3/net_3/impala/dense_1/kernel/RMSProp_1, net_3/net_3/impala/dense_1/bias/RMSProp, net_3/net_3/impala/dense_1/bias/RMSProp_1, net_3/net_3/impala/dense_2/kernel/RMSProp, net_3/net_3/impala/dense_2/kernel/RMSProp_1, net_3/net_3/impala/dense_2/bias/RMSProp, net_3/net_3/impala/dense_2/bias/RMSProp_1, net_4/impala/conv2d/kernel, net_4/impala/conv2d/bias, net_4/impala/conv2d_1/kernel, net_4/impala/conv2d_1/bias, net_4/impala/conv2d_2/kernel, net_4/impala/conv2d_2/bias, net_4/impala/dense/kernel, net_4/impala/dense/bias, net_4/impala/dense_1/kernel, net_4/impala/dense_1/bias, net_4/impala/dense_2/kernel, net_4/impala/dense_2/bias, net_4/net_4/impala/conv2d/kernel/RMSProp, net_4/net_4/impala/conv2d/kernel/RMSProp_1, net_4/net_4/impala/conv2d/bias/RMSProp, net_4/net_4/impala/conv2d/bias/RMSProp_1, net_4/net_4/impala/conv2d_1/kernel/RMSProp, net_4/net_4/impala/conv2d_1/kernel/RMSProp_1, net_4/net_4/impala/conv2d_1/bias/RMSProp, net_4/net_4/impala/conv2d_1/bias/RMSProp_1, net_4/net_4/impala/conv2d_2/kernel/RMSProp, net_4/net_4/impala/conv2d_2/kernel/RMSProp_1, net_4/net_4/impala/conv2d_2/bias/RMSProp, net_4/net_4/impala/conv2d_2/bias/RMSProp_1, net_4/net_4/impala/dense/kernel/RMSProp, net_4/net_4/impala/dense/kernel/RMSProp_1, net_4/net_4/impala/dense/bias/RMSProp, net_4/net_4/impala/dense/bias/RMSProp_1, net_4/net_4/impala/dense_1/kernel/RMSProp, net_4/net_4/impala/dense_1/kernel/RMSProp_1, net_4/net_4/impala/dense_1/bias/RMSProp, net_4/net_4/impala/dense_1/bias/RMSProp_1, net_4/net_4/impala/dense_2/kernel/RMSProp, net_4/net_4/impala/dense_2/kernel/RMSProp_1, net_4/net_4/impala/dense_2/bias/RMSProp, net_4/net_4/impala/dense_2/bias/RMSProp_1, net_5/impala/conv2d/kernel, net_5/impala/conv2d/bias, net_5/impala/conv2d_1/kernel, net_5/impala/conv2d_1/bias, net_5/impala/conv2d_2/kernel, net_5/impala/conv2d_2/bias, net_5/impala/dense/kernel, net_5/impala/dense/bias, net_5/impala/dense_1/kernel, net_5/impala/dense_1/bias, net_5/impala/dense_2/kernel, net_5/impala/dense_2/bias, net_5/net_5/impala/conv2d/kernel/RMSProp, net_5/net_5/impala/conv2d/kernel/RMSProp_1, net_5/net_5/impala/conv2d/bias/RMSProp, net_5/net_5/impala/conv2d/bias/RMSProp_1, net_5/net_5/impala/conv2d_1/kernel/RMSProp, net_5/net_5/impala/conv2d_1/kernel/RMSProp_1, net_5/net_5/impala/conv2d_1/bias/RMSProp, net_5/net_5/impala/conv2d_1/bias/RMSProp_1, net_5/net_5/impala/conv2d_2/kernel/RMSProp, net_5/net_5/impala/conv2d_2/kernel/RMSProp_1, net_5/net_5/impala/conv2d_2/bias/RMSProp, net_5/net_5/impala/conv2d_2/bias/RMSProp_1, net_5/net_5/impala/dense/kernel/RMSProp, net_5/net_5/impala/dense/kernel/RMSProp_1, net_5/net_5/impala/dense/bias/RMSProp, net_5/net_5/impala/dense/bias/RMSProp_1, net_5/net_5/impala/dense_1/kernel/RMSProp, net_5/net_5/impala/dense_1/kernel/RMSProp_1, net_5/net_5/impala/dense_1/bias/RMSProp, net_5/net_5/impala/dense_1/bias/RMSProp_1, net_5/net_5/impala/dense_2/kernel/RMSProp, net_5/net_5/impala/dense_2/kernel/RMSProp_1, net_5/net_5/impala/dense_2/bias/RMSProp, net_5/net_5/impala/dense_2/bias/RMSProp_1, net_6/impala/conv2d/kernel, net_6/impala/conv2d/bias, net_6/impala/conv2d_1/kernel, net_6/impala/conv2d_1/bias, net_6/impala/conv2d_2/kernel, net_6/impala/conv2d_2/bias, net_6/impala/dense/kernel, net_6/impala/dense/bias, net_6/impala/dense_1/kernel, net_6/impala/dense_1/bias, net_6/impala/dense_2/kernel, net_6/impala/dense_2/bias, net_6/net_6/impala/conv2d/kernel/RMSProp, net_6/net_6/impala/conv2d/kernel/RMSProp_1, net_6/net_6/impala/conv2d/bias/RMSProp, net_6/net_6/impala/conv2d/bias/RMSProp_1, net_6/net_6/impala/conv2d_1/kernel/RMSProp, net_6/net_6/impala/conv2d_1/kernel/RMSProp_1, net_6/net_6/impala/conv2d_1/bias/RMSProp, net_6/net_6/impala/conv2d_1/bias/RMSProp_1, net_6/net_6/impala/conv2d_2/kernel/RMSProp, net_6/net_6/impala/conv2d_2/kernel/RMSProp_1, net_6/net_6/impala/conv2d_2/bias/RMSProp, net_6/net_6/impala/conv2d_2/bias/RMSProp_1, net_6/net_6/impala/dense/kernel/RMSProp, net_6/net_6/impala/dense/kernel/RMSProp_1, net_6/net_6/impala/dense/bias/RMSProp, net_6/net_6/impala/dense/bias/RMSProp_1, net_6/net_6/impala/dense_1/kernel/RMSProp, net_6/net_6/impala/dense_1/kernel/RMSProp_1, net_6/net_6/impala/dense_1/bias/RMSProp, net_6/net_6/impala/dense_1/bias/RMSProp_1, net_6/net_6/impala/dense_2/kernel/RMSProp, net_6/net_6/impala/dense_2/kernel/RMSProp_1, net_6/net_6/impala/dense_2/bias/RMSProp, net_6/net_6/impala/dense_2/bias/RMSProp_1, net_7/impala/conv2d/kernel, net_7/impala/conv2d/bias, net_7/impala/conv2d_1/kernel, net_7/impala/conv2d_1/bias, net_7/impala/conv2d_2/kernel, net_7/impala/conv2d_2/bias, net_7/impala/dense/kernel, net_7/impala/dense/bias, net_7/impala/dense_1/kernel, net_7/impala/dense_1/bias, net_7/impala/dense_2/kernel, net_7/impala/dense_2/bias, net_7/net_7/impala/conv2d/kernel/RMSProp, net_7/net_7/impala/conv2d/kernel/RMSProp_1, net_7/net_7/impala/conv2d/bias/RMSProp, net_7/net_7/impala/conv2d/bias/RMSProp_1, net_7/net_7/impala/conv2d_1/kernel/RMSProp, net_7/net_7/impala/conv2d_1/kernel/RMSProp_1, net_7/net_7/impala/conv2d_1/bias/RMSProp, net_7/net_7/impala/conv2d_1/bias/RMSProp_1, net_7/net_7/impala/conv2d_2/kernel/RMSProp, net_7/net_7/impala/conv2d_2/kernel/RMSProp_1, net_7/net_7/impala/conv2d_2/bias/RMSProp, net_7/net_7/impala/conv2d_2/bias/RMSProp_1, net_7/net_7/impala/dense/kernel/RMSProp, net_7/net_7/impala/dense/kernel/RMSProp_1, net_7/net_7/impala/dense/bias/RMSProp, net_7/net_7/impala/dense/bias/RMSProp_1, net_7/net_7/impala/dense_1/kernel/RMSProp, net_7/net_7/impala/dense_1/kernel/RMSProp_1, net_7/net_7/impala/dense_1/bias/RMSProp, net_7/net_7/impala/dense_1/bias/RMSProp_1, net_7/net_7/impala/dense_2/kernel/RMSProp, net_7/net_7/impala/dense_2/kernel/RMSProp_1, net_7/net_7/impala/dense_2/bias/RMSProp, net_7/net_7/impala/dense_2/bias/RMSProp_1, net_8/impala/conv2d/kernel, net_8/impala/conv2d/bias, net_8/impala/conv2d_1/kernel, net_8/impala/conv2d_1/bias, net_8/impala/conv2d_2/kernel, net_8/impala/conv2d_2/bias, net_8/impala/dense/kernel, net_8/impala/dense/bias, net_8/impala/dense_1/kernel, net_8/impala/dense_1/bias, net_8/impala/dense_2/kernel, net_8/impala/dense_2/bias, net_8/net_8/impala/conv2d/kernel/RMSProp, net_8/net_8/impala/conv2d/kernel/RMSProp_1, net_8/net_8/impala/conv2d/bias/RMSProp, net_8/net_8/impala/conv2d/bias/RMSProp_1, net_8/net_8/impala/conv2d_1/kernel/RMSProp, net_8/net_8/impala/conv2d_1/kernel/RMSProp_1, net_8/net_8/impala/conv2d_1/bias/RMSProp, net_8/net_8/impala/conv2d_1/bias/RMSProp_1, net_8/net_8/impala/conv2d_2/kernel/RMSProp, net_8/net_8/impala/conv2d_2/kernel/RMSProp_1, net_8/net_8/impala/conv2d_2/bias/RMSProp, net_8/net_8/impala/conv2d_2/bias/RMSProp_1, net_8/net_8/impala/dense/kernel/RMSProp, net_8/net_8/impala/dense/kernel/RMSProp_1, net_8/net_8/impala/dense/bias/RMSProp, net_8/net_8/impala/dense/bias/RMSProp_1, net_8/net_8/impala/dense_1/kernel/RMSProp, net_8/net_8/impala/dense_1/kernel/RMSProp_1, net_8/net_8/impala/dense_1/bias/RMSProp, net_8/net_8/impala/dense_1/bias/RMSProp_1, net_8/net_8/impala/dense_2/kernel/RMSProp, net_8/net_8/impala/dense_2/kernel/RMSProp_1, net_8/net_8/impala/dense_2/bias/RMSProp, net_8/net_8/impala/dense_2/bias/RMSProp_1, net_9/impala/conv2d/kernel, net_9/impala/conv2d/bias, net_9/impala/conv2d_1/kernel, net_9/impala/conv2d_1/bias, net_9/impala/conv2d_2/kernel, net_9/impala/conv2d_2/bias, net_9/impala/dense/kernel, net_9/impala/dense/bias, net_9/impala/dense_1/kernel, net_9/impala/dense_1/bias, net_9/impala/dense_2/kernel, net_9/impala/dense_2/bias, net_9/net_9/impala/conv2d/kernel/RMSProp, net_9/net_9/impala/conv2d/kernel/RMSProp_1, net_9/net_9/impala/conv2d/bias/RMSProp, net_9/net_9/impala/conv2d/bias/RMSProp_1, net_9/net_9/impala/conv2d_1/kernel/RMSProp, net_9/net_9/impala/conv2d_1/kernel/RMSProp_1, net_9/net_9/impala/conv2d_1/bias/RMSProp, net_9/net_9/impala/conv2d_1/bias/RMSProp_1, net_9/net_9/impala/conv2d_2/kernel/RMSProp, net_9/net_9/impala/conv2d_2/kernel/RMSProp_1, net_9/net_9/impala/conv2d_2/bias/RMSProp, net_9/net_9/impala/conv2d_2/bias/RMSProp_1, net_9/net_9/impala/dense/kernel/RMSProp, net_9/net_9/impala/dense/kernel/RMSProp_1, net_9/net_9/impala/dense/bias/RMSProp, net_9/net_9/impala/dense/bias/RMSProp_1, net_9/net_9/impala/dense_1/kernel/RMSProp, net_9/net_9/impala/dense_1/kernel/RMSProp_1, net_9/net_9/impala/dense_1/bias/RMSProp, net_9/net_9/impala/dense_1/bias/RMSProp_1, net_9/net_9/impala/dense_2/kernel/RMSProp, net_9/net_9/impala/dense_2/kernel/RMSProp_1, net_9/net_9/impala/dense_2/bias/RMSProp, net_9/net_9/impala/dense_2/bias/RMSProp_1, net_10/impala/conv2d/kernel, net_10/impala/conv2d/bias, net_10/impala/conv2d_1/kernel, net_10/impala/conv2d_1/bias, net_10/impala/conv2d_2/kernel, net_10/impala/conv2d_2/bias, net_10/impala/dense/kernel, net_10/impala/dense/bias, net_10/impala/dense_1/kernel, net_10/impala/dense_1/bias, net_10/impala/dense_2/kernel, net_10/impala/dense_2/bias, net_10/net_10/impala/conv2d/kernel/RMSProp, net_10/net_10/impala/conv2d/kernel/RMSProp_1, net_10/net_10/impala/conv2d/bias/RMSProp, net_10/net_10/impala/conv2d/bias/RMSProp_1, net_10/net_10/impala/conv2d_1/kernel/RMSProp, net_10/net_10/impala/conv2d_1/kernel/RMSProp_1, net_10/net_10/impala/conv2d_1/bias/RMSProp, net_10/net_10/impala/conv2d_1/bias/RMSProp_1, net_10/net_10/impala/conv2d_2/kernel/RMSProp, net_10/net_10/impala/conv2d_2/kernel/RMSProp_1, net_10/net_10/impala/conv2d_2/bias/RMSProp, net_10/net_10/impala/conv2d_2/bias/RMSProp_1, net_10/net_10/impala/dense/kernel/RMSProp, net_10/net_10/impala/dense/kernel/RMSProp_1, net_10/net_10/impala/dense/bias/RMSProp, net_10/net_10/impala/dense/bias/RMSProp_1, net_10/net_10/impala/dense_1/kernel/RMSProp, net_10/net_10/impala/dense_1/kernel/RMSProp_1, net_10/net_10/impala/dense_1/bias/RMSProp, net_10/net_10/impala/dense_1/bias/RMSProp_1, net_10/net_10/impala/dense_2/kernel/RMSProp, net_10/net_10/impala/dense_2/kernel/RMSProp_1, net_10/net_10/impala/dense_2/bias/RMSProp, net_10/net_10/impala/dense_2/bias/RMSProp_1, net_11/impala/conv2d/kernel, net_11/impala/conv2d/bias, net_11/impala/conv2d_1/kernel, net_11/impala/conv2d_1/bias, net_11/impala/conv2d_2/kernel, net_11/impala/conv2d_2/bias, net_11/impala/dense/kernel, net_11/impala/dense/bias, net_11/impala/dense_1/kernel, net_11/impala/dense_1/bias, net_11/impala/dense_2/kernel, net_11/impala/dense_2/bias, net_11/net_11/impala/conv2d/kernel/RMSProp, net_11/net_11/impala/conv2d/kernel/RMSProp_1, net_11/net_11/impala/conv2d/bias/RMSProp, net_11/net_11/impala/conv2d/bias/RMSProp_1, net_11/net_11/impala/conv2d_1/kernel/RMSProp, net_11/net_11/impala/conv2d_1/kernel/RMSProp_1, net_11/net_11/impala/conv2d_1/bias/RMSProp, net_11/net_11/impala/conv2d_1/bias/RMSProp_1, net_11/net_11/impala/conv2d_2/kernel/RMSProp, net_11/net_11/impala/conv2d_2/kernel/RMSProp_1, net_11/net_11/impala/conv2d_2/bias/RMSProp, net_11/net_11/impala/conv2d_2/bias/RMSProp_1, net_11/net_11/impala/dense/kernel/RMSProp, net_11/net_11/impala/dense/kernel/RMSProp_1, net_11/net_11/impala/dense/bias/RMSProp, net_11/net_11/impala/dense/bias/RMSProp_1, net_11/net_11/impala/dense_1/kernel/RMSProp, net_11/net_11/impala/dense_1/kernel/RMSProp_1, net_11/net_11/impala/dense_1/bias/RMSProp, net_11/net_11/impala/dense_1/bias/RMSProp_1, net_11/net_11/impala/dense_2/kernel/RMSProp, net_11/net_11/impala/dense_2/kernel/RMSProp_1, net_11/net_11/impala/dense_2/bias/RMSProp, net_11/net_11/impala/dense_2/bias/RMSProp_1, net_12/impala/conv2d/kernel, net_12/impala/conv2d/bias, net_12/impala/conv2d_1/kernel, net_12/impala/conv2d_1/bias, net_12/impala/conv2d_2/kernel, net_12/impala/conv2d_2/bias, net_12/impala/dense/kernel, net_12/impala/dense/bias, net_12/impala/dense_1/kernel, net_12/impala/dense_1/bias, net_12/impala/dense_2/kernel, net_12/impala/dense_2/bias, net_12/net_12/impala/conv2d/kernel/RMSProp, net_12/net_12/impala/conv2d/kernel/RMSProp_1, net_12/net_12/impala/conv2d/bias/RMSProp, net_12/net_12/impala/conv2d/bias/RMSProp_1, net_12/net_12/impala/conv2d_1/kernel/RMSProp, net_12/net_12/impala/conv2d_1/kernel/RMSProp_1, net_12/net_12/impala/conv2d_1/bias/RMSProp, net_12/net_12/impala/conv2d_1/bias/RMSProp_1, net_12/net_12/impala/conv2d_2/kernel/RMSProp, net_12/net_12/impala/conv2d_2/kernel/RMSProp_1, net_12/net_12/impala/conv2d_2/bias/RMSProp, net_12/net_12/impala/conv2d_2/bias/RMSProp_1, net_12/net_12/impala/dense/kernel/RMSProp, net_12/net_12/impala/dense/kernel/RMSProp_1, net_12/net_12/impala/dense/bias/RMSProp, net_12/net_12/impala/dense/bias/RMSProp_1, net_12/net_12/impala/dense_1/kernel/RMSProp, net_12/net_12/impala/dense_1/kernel/RMSProp_1, net_12/net_12/impala/dense_1/bias/RMSProp, net_12/net_12/impala/dense_1/bias/RMSProp_1, net_12/net_12/impala/dense_2/kernel/RMSProp, net_12/net_12/impala/dense_2/kernel/RMSProp_1, net_12/net_12/impala/dense_2/bias/RMSProp, net_12/net_12/impala/dense_2/bias/RMSProp_1, net_13/impala/conv2d/kernel, net_13/impala/conv2d/bias, net_13/impala/conv2d_1/kernel, net_13/impala/conv2d_1/bias, net_13/impala/conv2d_2/kernel, net_13/impala/conv2d_2/bias, net_13/impala/dense/kernel, net_13/impala/dense/bias, net_13/impala/dense_1/kernel, net_13/impala/dense_1/bias, net_13/impala/dense_2/kernel, net_13/impala/dense_2/bias, net_13/net_13/impala/conv2d/kernel/RMSProp, net_13/net_13/impala/conv2d/kernel/RMSProp_1, net_13/net_13/impala/conv2d/bias/RMSProp, net_13/net_13/impala/conv2d/bias/RMSProp_1, net_13/net_13/impala/conv2d_1/kernel/RMSProp, net_13/net_13/impala/conv2d_1/kernel/RMSProp_1, net_13/net_13/impala/conv2d_1/bias/RMSProp, net_13/net_13/impala/conv2d_1/bias/RMSProp_1, net_13/net_13/impala/conv2d_2/kernel/RMSProp, net_13/net_13/impala/conv2d_2/kernel/RMSProp_1, net_13/net_13/impala/conv2d_2/bias/RMSProp, net_13/net_13/impala/conv2d_2/bias/RMSProp_1, net_13/net_13/impala/dense/kernel/RMSProp, net_13/net_13/impala/dense/kernel/RMSProp_1, net_13/net_13/impala/dense/bias/RMSProp, net_13/net_13/impala/dense/bias/RMSProp_1, net_13/net_13/impala/dense_1/kernel/RMSProp, net_13/net_13/impala/dense_1/kernel/RMSProp_1, net_13/net_13/impala/dense_1/bias/RMSProp, net_13/net_13/impala/dense_1/bias/RMSProp_1, net_13/net_13/impala/dense_2/kernel/RMSProp, net_13/net_13/impala/dense_2/kernel/RMSProp_1, net_13/net_13/impala/dense_2/bias/RMSProp, net_13/net_13/impala/dense_2/bias/RMSProp_1, net_14/impala/conv2d/kernel, net_14/impala/conv2d/bias, net_14/impala/conv2d_1/kernel, net_14/impala/conv2d_1/bias, net_14/impala/conv2d_2/kernel, net_14/impala/conv2d_2/bias, net_14/impala/dense/kernel, net_14/impala/dense/bias, net_14/impala/dense_1/kernel, net_14/impala/dense_1/bias, net_14/impala/dense_2/kernel, net_14/impala/dense_2/bias, net_14/net_14/impala/conv2d/kernel/RMSProp, net_14/net_14/impala/conv2d/kernel/RMSProp_1, net_14/net_14/impala/conv2d/bias/RMSProp, net_14/net_14/impala/conv2d/bias/RMSProp_1, net_14/net_14/impala/conv2d_1/kernel/RMSProp, net_14/net_14/impala/conv2d_1/kernel/RMSProp_1, net_14/net_14/impala/conv2d_1/bias/RMSProp, net_14/net_14/impala/conv2d_1/bias/RMSProp_1, net_14/net_14/impala/conv2d_2/kernel/RMSProp, net_14/net_14/impala/conv2d_2/kernel/RMSProp_1, net_14/net_14/impala/conv2d_2/bias/RMSProp, net_14/net_14/impala/conv2d_2/bias/RMSProp_1, net_14/net_14/impala/dense/kernel/RMSProp, net_14/net_14/impala/dense/kernel/RMSProp_1, net_14/net_14/impala/dense/bias/RMSProp, net_14/net_14/impala/dense/bias/RMSProp_1, net_14/net_14/impala/dense_1/kernel/RMSProp, net_14/net_14/impala/dense_1/kernel/RMSProp_1, net_14/net_14/impala/dense_1/bias/RMSProp, net_14/net_14/impala/dense_1/bias/RMSProp_1, net_14/net_14/impala/dense_2/kernel/RMSProp, net_14/net_14/impala/dense_2/kernel/RMSProp_1, net_14/net_14/impala/dense_2/bias/RMSProp, net_14/net_14/impala/dense_2/bias/RMSProp_1, net_15/impala/conv2d/kernel, net_15/impala/conv2d/bias, net_15/impala/conv2d_1/kernel, net_15/impala/conv2d_1/bias, net_15/impala/conv2d_2/kernel, net_15/impala/conv2d_2/bias, net_15/impala/dense/kernel, net_15/impala/dense/bias, net_15/impala/dense_1/kernel, net_15/impala/dense_1/bias, net_15/impala/dense_2/kernel, net_15/impala/dense_2/bias, net_15/net_15/impala/conv2d/kernel/RMSProp, net_15/net_15/impala/conv2d/kernel/RMSProp_1, net_15/net_15/impala/conv2d/bias/RMSProp, net_15/net_15/impala/conv2d/bias/RMSProp_1, net_15/net_15/impala/conv2d_1/kernel/RMSProp, net_15/net_15/impala/conv2d_1/kernel/RMSProp_1, net_15/net_15/impala/conv2d_1/bias/RMSProp, net_15/net_15/impala/conv2d_1/bias/RMSProp_1, net_15/net_15/impala/conv2d_2/kernel/RMSProp, net_15/net_15/impala/conv2d_2/kernel/RMSProp_1, net_15/net_15/impala/conv2d_2/bias/RMSProp, net_15/net_15/impala/conv2d_2/bias/RMSProp_1, net_15/net_15/impala/dense/kernel/RMSProp, net_15/net_15/impala/dense/kernel/RMSProp_1, net_15/net_15/impala/dense/bias/RMSProp, net_15/net_15/impala/dense/bias/RMSProp_1, net_15/net_15/impala/dense_1/kernel/RMSProp, net_15/net_15/impala/dense_1/kernel/RMSProp_1, net_15/net_15/impala/dense_1/bias/RMSProp, net_15/net_15/impala/dense_1/bias/RMSProp_1, net_15/net_15/impala/dense_2/kernel/RMSProp, net_15/net_15/impala/dense_2/kernel/RMSProp_1, net_15/net_15/impala/dense_2/bias/RMSProp, net_15/net_15/impala/dense_2/bias/RMSProp_1, global_step
I0729 05:34:17.660743 140183310444352 session_manager.py:436] Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: net_global/impala/conv2d/kernel, net_global/impala/conv2d/bias, net_global/impala/conv2d_1/kernel, net_global/impala/conv2d_1/bias, net_global/impala/conv2d_2/kernel, net_global/impala/conv2d_2/bias, net_global/impala/dense/kernel, net_global/impala/dense/bias, net_global/impala/dense_1/kernel, net_global/impala/dense_1/bias, net_global/impala/dense_2/kernel, net_global/impala/dense_2/bias, net_global/net_global/impala/conv2d/kernel/RMSProp, net_global/net_global/impala/conv2d/kernel/RMSProp_1, net_global/net_global/impala/conv2d/bias/RMSProp, net_global/net_global/impala/conv2d/bias/RMSProp_1, net_global/net_global/impala/conv2d_1/kernel/RMSProp, net_global/net_global/impala/conv2d_1/kernel/RMSProp_1, net_global/net_global/impala/conv2d_1/bias/RMSProp, net_global/net_global/impala/conv2d_1/bias/RMSProp_1, net_global/net_global/impala/conv2d_2/kernel/RMSProp, net_global/net_global/impala/conv2d_2/kernel/RMSProp_1, net_global/net_global/impala/conv2d_2/bias/RMSProp, net_global/net_global/impala/conv2d_2/bias/RMSProp_1, net_global/net_global/impala/dense/kernel/RMSProp, net_global/net_global/impala/dense/kernel/RMSProp_1, net_global/net_global/impala/dense/bias/RMSProp, net_global/net_global/impala/dense/bias/RMSProp_1, net_global/net_global/impala/dense_1/kernel/RMSProp, net_global/net_global/impala/dense_1/kernel/RMSProp_1, net_global/net_global/impala/dense_1/bias/RMSProp, net_global/net_global/impala/dense_1/bias/RMSProp_1, net_global/net_global/impala/dense_2/kernel/RMSProp, net_global/net_global/impala/dense_2/kernel/RMSProp_1, net_global/net_global/impala/dense_2/bias/RMSProp, net_global/net_global/impala/dense_2/bias/RMSProp_1, net_0/impala/conv2d/kernel, net_0/impala/conv2d/bias, net_0/impala/conv2d_1/kernel, net_0/impala/conv2d_1/bias, net_0/impala/conv2d_2/kernel, net_0/impala/conv2d_2/bias, net_0/impala/dense/kernel, net_0/impala/dense/bias, net_0/impala/dense_1/kernel, net_0/impala/dense_1/bias, net_0/impala/dense_2/kernel, net_0/impala/dense_2/bias, net_0/net_0/impala/conv2d/kernel/RMSProp, net_0/net_0/impala/conv2d/kernel/RMSProp_1, net_0/net_0/impala/conv2d/bias/RMSProp, net_0/net_0/impala/conv2d/bias/RMSProp_1, net_0/net_0/impala/conv2d_1/kernel/RMSProp, net_0/net_0/impala/conv2d_1/kernel/RMSProp_1, net_0/net_0/impala/conv2d_1/bias/RMSProp, net_0/net_0/impala/conv2d_1/bias/RMSProp_1, net_0/net_0/impala/conv2d_2/kernel/RMSProp, net_0/net_0/impala/conv2d_2/kernel/RMSProp_1, net_0/net_0/impala/conv2d_2/bias/RMSProp, net_0/net_0/impala/conv2d_2/bias/RMSProp_1, net_0/net_0/impala/dense/kernel/RMSProp, net_0/net_0/impala/dense/kernel/RMSProp_1, net_0/net_0/impala/dense/bias/RMSProp, net_0/net_0/impala/dense/bias/RMSProp_1, net_0/net_0/impala/dense_1/kernel/RMSProp, net_0/net_0/impala/dense_1/kernel/RMSProp_1, net_0/net_0/impala/dense_1/bias/RMSProp, net_0/net_0/impala/dense_1/bias/RMSProp_1, net_0/net_0/impala/dense_2/kernel/RMSProp, net_0/net_0/impala/dense_2/kernel/RMSProp_1, net_0/net_0/impala/dense_2/bias/RMSProp, net_0/net_0/impala/dense_2/bias/RMSProp_1, net_1/impala/conv2d/kernel, net_1/impala/conv2d/bias, net_1/impala/conv2d_1/kernel, net_1/impala/conv2d_1/bias, net_1/impala/conv2d_2/kernel, net_1/impala/conv2d_2/bias, net_1/impala/dense/kernel, net_1/impala/dense/bias, net_1/impala/dense_1/kernel, net_1/impala/dense_1/bias, net_1/impala/dense_2/kernel, net_1/impala/dense_2/bias, net_1/net_1/impala/conv2d/kernel/RMSProp, net_1/net_1/impala/conv2d/kernel/RMSProp_1, net_1/net_1/impala/conv2d/bias/RMSProp, net_1/net_1/impala/conv2d/bias/RMSProp_1, net_1/net_1/impala/conv2d_1/kernel/RMSProp, net_1/net_1/impala/conv2d_1/kernel/RMSProp_1, net_1/net_1/impala/conv2d_1/bias/RMSProp, net_1/net_1/impala/conv2d_1/bias/RMSProp_1, net_1/net_1/impala/conv2d_2/kernel/RMSProp, net_1/net_1/impala/conv2d_2/kernel/RMSProp_1, net_1/net_1/impala/conv2d_2/bias/RMSProp, net_1/net_1/impala/conv2d_2/bias/RMSProp_1, net_1/net_1/impala/dense/kernel/RMSProp, net_1/net_1/impala/dense/kernel/RMSProp_1, net_1/net_1/impala/dense/bias/RMSProp, net_1/net_1/impala/dense/bias/RMSProp_1, net_1/net_1/impala/dense_1/kernel/RMSProp, net_1/net_1/impala/dense_1/kernel/RMSProp_1, net_1/net_1/impala/dense_1/bias/RMSProp, net_1/net_1/impala/dense_1/bias/RMSProp_1, net_1/net_1/impala/dense_2/kernel/RMSProp, net_1/net_1/impala/dense_2/kernel/RMSProp_1, net_1/net_1/impala/dense_2/bias/RMSProp, net_1/net_1/impala/dense_2/bias/RMSProp_1, net_2/impala/conv2d/kernel, net_2/impala/conv2d/bias, net_2/impala/conv2d_1/kernel, net_2/impala/conv2d_1/bias, net_2/impala/conv2d_2/kernel, net_2/impala/conv2d_2/bias, net_2/impala/dense/kernel, net_2/impala/dense/bias, net_2/impala/dense_1/kernel, net_2/impala/dense_1/bias, net_2/impala/dense_2/kernel, net_2/impala/dense_2/bias, net_2/net_2/impala/conv2d/kernel/RMSProp, net_2/net_2/impala/conv2d/kernel/RMSProp_1, net_2/net_2/impala/conv2d/bias/RMSProp, net_2/net_2/impala/conv2d/bias/RMSProp_1, net_2/net_2/impala/conv2d_1/kernel/RMSProp, net_2/net_2/impala/conv2d_1/kernel/RMSProp_1, net_2/net_2/impala/conv2d_1/bias/RMSProp, net_2/net_2/impala/conv2d_1/bias/RMSProp_1, net_2/net_2/impala/conv2d_2/kernel/RMSProp, net_2/net_2/impala/conv2d_2/kernel/RMSProp_1, net_2/net_2/impala/conv2d_2/bias/RMSProp, net_2/net_2/impala/conv2d_2/bias/RMSProp_1, net_2/net_2/impala/dense/kernel/RMSProp, net_2/net_2/impala/dense/kernel/RMSProp_1, net_2/net_2/impala/dense/bias/RMSProp, net_2/net_2/impala/dense/bias/RMSProp_1, net_2/net_2/impala/dense_1/kernel/RMSProp, net_2/net_2/impala/dense_1/kernel/RMSProp_1, net_2/net_2/impala/dense_1/bias/RMSProp, net_2/net_2/impala/dense_1/bias/RMSProp_1, net_2/net_2/impala/dense_2/kernel/RMSProp, net_2/net_2/impala/dense_2/kernel/RMSProp_1, net_2/net_2/impala/dense_2/bias/RMSProp, net_2/net_2/impala/dense_2/bias/RMSProp_1, net_3/impala/conv2d/kernel, net_3/impala/conv2d/bias, net_3/impala/conv2d_1/kernel, net_3/impala/conv2d_1/bias, net_3/impala/conv2d_2/kernel, net_3/impala/conv2d_2/bias, net_3/impala/dense/kernel, net_3/impala/dense/bias, net_3/impala/dense_1/kernel, net_3/impala/dense_1/bias, net_3/impala/dense_2/kernel, net_3/impala/dense_2/bias, net_3/net_3/impala/conv2d/kernel/RMSProp, net_3/net_3/impala/conv2d/kernel/RMSProp_1, net_3/net_3/impala/conv2d/bias/RMSProp, net_3/net_3/impala/conv2d/bias/RMSProp_1, net_3/net_3/impala/conv2d_1/kernel/RMSProp, net_3/net_3/impala/conv2d_1/kernel/RMSProp_1, net_3/net_3/impala/conv2d_1/bias/RMSProp, net_3/net_3/impala/conv2d_1/bias/RMSProp_1, net_3/net_3/impala/conv2d_2/kernel/RMSProp, net_3/net_3/impala/conv2d_2/kernel/RMSProp_1, net_3/net_3/impala/conv2d_2/bias/RMSProp, net_3/net_3/impala/conv2d_2/bias/RMSProp_1, net_3/net_3/impala/dense/kernel/RMSProp, net_3/net_3/impala/dense/kernel/RMSProp_1, net_3/net_3/impala/dense/bias/RMSProp, net_3/net_3/impala/dense/bias/RMSProp_1, net_3/net_3/impala/dense_1/kernel/RMSProp, net_3/net_3/impala/dense_1/kernel/RMSProp_1, net_3/net_3/impala/dense_1/bias/RMSProp, net_3/net_3/impala/dense_1/bias/RMSProp_1, net_3/net_3/impala/dense_2/kernel/RMSProp, net_3/net_3/impala/dense_2/kernel/RMSProp_1, net_3/net_3/impala/dense_2/bias/RMSProp, net_3/net_3/impala/dense_2/bias/RMSProp_1, net_4/impala/conv2d/kernel, net_4/impala/conv2d/bias, net_4/impala/conv2d_1/kernel, net_4/impala/conv2d_1/bias, net_4/impala/conv2d_2/kernel, net_4/impala/conv2d_2/bias, net_4/impala/dense/kernel, net_4/impala/dense/bias, net_4/impala/dense_1/kernel, net_4/impala/dense_1/bias, net_4/impala/dense_2/kernel, net_4/impala/dense_2/bias, net_4/net_4/impala/conv2d/kernel/RMSProp, net_4/net_4/impala/conv2d/kernel/RMSProp_1, net_4/net_4/impala/conv2d/bias/RMSProp, net_4/net_4/impala/conv2d/bias/RMSProp_1, net_4/net_4/impala/conv2d_1/kernel/RMSProp, net_4/net_4/impala/conv2d_1/kernel/RMSProp_1, net_4/net_4/impala/conv2d_1/bias/RMSProp, net_4/net_4/impala/conv2d_1/bias/RMSProp_1, net_4/net_4/impala/conv2d_2/kernel/RMSProp, net_4/net_4/impala/conv2d_2/kernel/RMSProp_1, net_4/net_4/impala/conv2d_2/bias/RMSProp, net_4/net_4/impala/conv2d_2/bias/RMSProp_1, net_4/net_4/impala/dense/kernel/RMSProp, net_4/net_4/impala/dense/kernel/RMSProp_1, net_4/net_4/impala/dense/bias/RMSProp, net_4/net_4/impala/dense/bias/RMSProp_1, net_4/net_4/impala/dense_1/kernel/RMSProp, net_4/net_4/impala/dense_1/kernel/RMSProp_1, net_4/net_4/impala/dense_1/bias/RMSProp, net_4/net_4/impala/dense_1/bias/RMSProp_1, net_4/net_4/impala/dense_2/kernel/RMSProp, net_4/net_4/impala/dense_2/kernel/RMSProp_1, net_4/net_4/impala/dense_2/bias/RMSProp, net_4/net_4/impala/dense_2/bias/RMSProp_1, net_5/impala/conv2d/kernel, net_5/impala/conv2d/bias, net_5/impala/conv2d_1/kernel, net_5/impala/conv2d_1/bias, net_5/impala/conv2d_2/kernel, net_5/impala/conv2d_2/bias, net_5/impala/dense/kernel, net_5/impala/dense/bias, net_5/impala/dense_1/kernel, net_5/impala/dense_1/bias, net_5/impala/dense_2/kernel, net_5/impala/dense_2/bias, net_5/net_5/impala/conv2d/kernel/RMSProp, net_5/net_5/impala/conv2d/kernel/RMSProp_1, net_5/net_5/impala/conv2d/bias/RMSProp, net_5/net_5/impala/conv2d/bias/RMSProp_1, net_5/net_5/impala/conv2d_1/kernel/RMSProp, net_5/net_5/impala/conv2d_1/kernel/RMSProp_1, net_5/net_5/impala/conv2d_1/bias/RMSProp, net_5/net_5/impala/conv2d_1/bias/RMSProp_1, net_5/net_5/impala/conv2d_2/kernel/RMSProp, net_5/net_5/impala/conv2d_2/kernel/RMSProp_1, net_5/net_5/impala/conv2d_2/bias/RMSProp, net_5/net_5/impala/conv2d_2/bias/RMSProp_1, net_5/net_5/impala/dense/kernel/RMSProp, net_5/net_5/impala/dense/kernel/RMSProp_1, net_5/net_5/impala/dense/bias/RMSProp, net_5/net_5/impala/dense/bias/RMSProp_1, net_5/net_5/impala/dense_1/kernel/RMSProp, net_5/net_5/impala/dense_1/kernel/RMSProp_1, net_5/net_5/impala/dense_1/bias/RMSProp, net_5/net_5/impala/dense_1/bias/RMSProp_1, net_5/net_5/impala/dense_2/kernel/RMSProp, net_5/net_5/impala/dense_2/kernel/RMSProp_1, net_5/net_5/impala/dense_2/bias/RMSProp, net_5/net_5/impala/dense_2/bias/RMSProp_1, net_6/impala/conv2d/kernel, net_6/impala/conv2d/bias, net_6/impala/conv2d_1/kernel, net_6/impala/conv2d_1/bias, net_6/impala/conv2d_2/kernel, net_6/impala/conv2d_2/bias, net_6/impala/dense/kernel, net_6/impala/dense/bias, net_6/impala/dense_1/kernel, net_6/impala/dense_1/bias, net_6/impala/dense_2/kernel, net_6/impala/dense_2/bias, net_6/net_6/impala/conv2d/kernel/RMSProp, net_6/net_6/impala/conv2d/kernel/RMSProp_1, net_6/net_6/impala/conv2d/bias/RMSProp, net_6/net_6/impala/conv2d/bias/RMSProp_1, net_6/net_6/impala/conv2d_1/kernel/RMSProp, net_6/net_6/impala/conv2d_1/kernel/RMSProp_1, net_6/net_6/impala/conv2d_1/bias/RMSProp, net_6/net_6/impala/conv2d_1/bias/RMSProp_1, net_6/net_6/impala/conv2d_2/kernel/RMSProp, net_6/net_6/impala/conv2d_2/kernel/RMSProp_1, net_6/net_6/impala/conv2d_2/bias/RMSProp, net_6/net_6/impala/conv2d_2/bias/RMSProp_1, net_6/net_6/impala/dense/kernel/RMSProp, net_6/net_6/impala/dense/kernel/RMSProp_1, net_6/net_6/impala/dense/bias/RMSProp, net_6/net_6/impala/dense/bias/RMSProp_1, net_6/net_6/impala/dense_1/kernel/RMSProp, net_6/net_6/impala/dense_1/kernel/RMSProp_1, net_6/net_6/impala/dense_1/bias/RMSProp, net_6/net_6/impala/dense_1/bias/RMSProp_1, net_6/net_6/impala/dense_2/kernel/RMSProp, net_6/net_6/impala/dense_2/kernel/RMSProp_1, net_6/net_6/impala/dense_2/bias/RMSProp, net_6/net_6/impala/dense_2/bias/RMSProp_1, net_7/impala/conv2d/kernel, net_7/impala/conv2d/bias, net_7/impala/conv2d_1/kernel, net_7/impala/conv2d_1/bias, net_7/impala/conv2d_2/kernel, net_7/impala/conv2d_2/bias, net_7/impala/dense/kernel, net_7/impala/dense/bias, net_7/impala/dense_1/kernel, net_7/impala/dense_1/bias, net_7/impala/dense_2/kernel, net_7/impala/dense_2/bias, net_7/net_7/impala/conv2d/kernel/RMSProp, net_7/net_7/impala/conv2d/kernel/RMSProp_1, net_7/net_7/impala/conv2d/bias/RMSProp, net_7/net_7/impala/conv2d/bias/RMSProp_1, net_7/net_7/impala/conv2d_1/kernel/RMSProp, net_7/net_7/impala/conv2d_1/kernel/RMSProp_1, net_7/net_7/impala/conv2d_1/bias/RMSProp, net_7/net_7/impala/conv2d_1/bias/RMSProp_1, net_7/net_7/impala/conv2d_2/kernel/RMSProp, net_7/net_7/impala/conv2d_2/kernel/RMSProp_1, net_7/net_7/impala/conv2d_2/bias/RMSProp, net_7/net_7/impala/conv2d_2/bias/RMSProp_1, net_7/net_7/impala/dense/kernel/RMSProp, net_7/net_7/impala/dense/kernel/RMSProp_1, net_7/net_7/impala/dense/bias/RMSProp, net_7/net_7/impala/dense/bias/RMSProp_1, net_7/net_7/impala/dense_1/kernel/RMSProp, net_7/net_7/impala/dense_1/kernel/RMSProp_1, net_7/net_7/impala/dense_1/bias/RMSProp, net_7/net_7/impala/dense_1/bias/RMSProp_1, net_7/net_7/impala/dense_2/kernel/RMSProp, net_7/net_7/impala/dense_2/kernel/RMSProp_1, net_7/net_7/impala/dense_2/bias/RMSProp, net_7/net_7/impala/dense_2/bias/RMSProp_1, net_8/impala/conv2d/kernel, net_8/impala/conv2d/bias, net_8/impala/conv2d_1/kernel, net_8/impala/conv2d_1/bias, net_8/impala/conv2d_2/kernel, net_8/impala/conv2d_2/bias, net_8/impala/dense/kernel, net_8/impala/dense/bias, net_8/impala/dense_1/kernel, net_8/impala/dense_1/bias, net_8/impala/dense_2/kernel, net_8/impala/dense_2/bias, net_8/net_8/impala/conv2d/kernel/RMSProp, net_8/net_8/impala/conv2d/kernel/RMSProp_1, net_8/net_8/impala/conv2d/bias/RMSProp, net_8/net_8/impala/conv2d/bias/RMSProp_1, net_8/net_8/impala/conv2d_1/kernel/RMSProp, net_8/net_8/impala/conv2d_1/kernel/RMSProp_1, net_8/net_8/impala/conv2d_1/bias/RMSProp, net_8/net_8/impala/conv2d_1/bias/RMSProp_1, net_8/net_8/impala/conv2d_2/kernel/RMSProp, net_8/net_8/impala/conv2d_2/kernel/RMSProp_1, net_8/net_8/impala/conv2d_2/bias/RMSProp, net_8/net_8/impala/conv2d_2/bias/RMSProp_1, net_8/net_8/impala/dense/kernel/RMSProp, net_8/net_8/impala/dense/kernel/RMSProp_1, net_8/net_8/impala/dense/bias/RMSProp, net_8/net_8/impala/dense/bias/RMSProp_1, net_8/net_8/impala/dense_1/kernel/RMSProp, net_8/net_8/impala/dense_1/kernel/RMSProp_1, net_8/net_8/impala/dense_1/bias/RMSProp, net_8/net_8/impala/dense_1/bias/RMSProp_1, net_8/net_8/impala/dense_2/kernel/RMSProp, net_8/net_8/impala/dense_2/kernel/RMSProp_1, net_8/net_8/impala/dense_2/bias/RMSProp, net_8/net_8/impala/dense_2/bias/RMSProp_1, net_9/impala/conv2d/kernel, net_9/impala/conv2d/bias, net_9/impala/conv2d_1/kernel, net_9/impala/conv2d_1/bias, net_9/impala/conv2d_2/kernel, net_9/impala/conv2d_2/bias, net_9/impala/dense/kernel, net_9/impala/dense/bias, net_9/impala/dense_1/kernel, net_9/impala/dense_1/bias, net_9/impala/dense_2/kernel, net_9/impala/dense_2/bias, net_9/net_9/impala/conv2d/kernel/RMSProp, net_9/net_9/impala/conv2d/kernel/RMSProp_1, net_9/net_9/impala/conv2d/bias/RMSProp, net_9/net_9/impala/conv2d/bias/RMSProp_1, net_9/net_9/impala/conv2d_1/kernel/RMSProp, net_9/net_9/impala/conv2d_1/kernel/RMSProp_1, net_9/net_9/impala/conv2d_1/bias/RMSProp, net_9/net_9/impala/conv2d_1/bias/RMSProp_1, net_9/net_9/impala/conv2d_2/kernel/RMSProp, net_9/net_9/impala/conv2d_2/kernel/RMSProp_1, net_9/net_9/impala/conv2d_2/bias/RMSProp, net_9/net_9/impala/conv2d_2/bias/RMSProp_1, net_9/net_9/impala/dense/kernel/RMSProp, net_9/net_9/impala/dense/kernel/RMSProp_1, net_9/net_9/impala/dense/bias/RMSProp, net_9/net_9/impala/dense/bias/RMSProp_1, net_9/net_9/impala/dense_1/kernel/RMSProp, net_9/net_9/impala/dense_1/kernel/RMSProp_1, net_9/net_9/impala/dense_1/bias/RMSProp, net_9/net_9/impala/dense_1/bias/RMSProp_1, net_9/net_9/impala/dense_2/kernel/RMSProp, net_9/net_9/impala/dense_2/kernel/RMSProp_1, net_9/net_9/impala/dense_2/bias/RMSProp, net_9/net_9/impala/dense_2/bias/RMSProp_1, net_10/impala/conv2d/kernel, net_10/impala/conv2d/bias, net_10/impala/conv2d_1/kernel, net_10/impala/conv2d_1/bias, net_10/impala/conv2d_2/kernel, net_10/impala/conv2d_2/bias, net_10/impala/dense/kernel, net_10/impala/dense/bias, net_10/impala/dense_1/kernel, net_10/impala/dense_1/bias, net_10/impala/dense_2/kernel, net_10/impala/dense_2/bias, net_10/net_10/impala/conv2d/kernel/RMSProp, net_10/net_10/impala/conv2d/kernel/RMSProp_1, net_10/net_10/impala/conv2d/bias/RMSProp, net_10/net_10/impala/conv2d/bias/RMSProp_1, net_10/net_10/impala/conv2d_1/kernel/RMSProp, net_10/net_10/impala/conv2d_1/kernel/RMSProp_1, net_10/net_10/impala/conv2d_1/bias/RMSProp, net_10/net_10/impala/conv2d_1/bias/RMSProp_1, net_10/net_10/impala/conv2d_2/kernel/RMSProp, net_10/net_10/impala/conv2d_2/kernel/RMSProp_1, net_10/net_10/impala/conv2d_2/bias/RMSProp, net_10/net_10/impala/conv2d_2/bias/RMSProp_1, net_10/net_10/impala/dense/kernel/RMSProp, net_10/net_10/impala/dense/kernel/RMSProp_1, net_10/net_10/impala/dense/bias/RMSProp, net_10/net_10/impala/dense/bias/RMSProp_1, net_10/net_10/impala/dense_1/kernel/RMSProp, net_10/net_10/impala/dense_1/kernel/RMSProp_1, net_10/net_10/impala/dense_1/bias/RMSProp, net_10/net_10/impala/dense_1/bias/RMSProp_1, net_10/net_10/impala/dense_2/kernel/RMSProp, net_10/net_10/impala/dense_2/kernel/RMSProp_1, net_10/net_10/impala/dense_2/bias/RMSProp, net_10/net_10/impala/dense_2/bias/RMSProp_1, net_11/impala/conv2d/kernel, net_11/impala/conv2d/bias, net_11/impala/conv2d_1/kernel, net_11/impala/conv2d_1/bias, net_11/impala/conv2d_2/kernel, net_11/impala/conv2d_2/bias, net_11/impala/dense/kernel, net_11/impala/dense/bias, net_11/impala/dense_1/kernel, net_11/impala/dense_1/bias, net_11/impala/dense_2/kernel, net_11/impala/dense_2/bias, net_11/net_11/impala/conv2d/kernel/RMSProp, net_11/net_11/impala/conv2d/kernel/RMSProp_1, net_11/net_11/impala/conv2d/bias/RMSProp, net_11/net_11/impala/conv2d/bias/RMSProp_1, net_11/net_11/impala/conv2d_1/kernel/RMSProp, net_11/net_11/impala/conv2d_1/kernel/RMSProp_1, net_11/net_11/impala/conv2d_1/bias/RMSProp, net_11/net_11/impala/conv2d_1/bias/RMSProp_1, net_11/net_11/impala/conv2d_2/kernel/RMSProp, net_11/net_11/impala/conv2d_2/kernel/RMSProp_1, net_11/net_11/impala/conv2d_2/bias/RMSProp, net_11/net_11/impala/conv2d_2/bias/RMSProp_1, net_11/net_11/impala/dense/kernel/RMSProp, net_11/net_11/impala/dense/kernel/RMSProp_1, net_11/net_11/impala/dense/bias/RMSProp, net_11/net_11/impala/dense/bias/RMSProp_1, net_11/net_11/impala/dense_1/kernel/RMSProp, net_11/net_11/impala/dense_1/kernel/RMSProp_1, net_11/net_11/impala/dense_1/bias/RMSProp, net_11/net_11/impala/dense_1/bias/RMSProp_1, net_11/net_11/impala/dense_2/kernel/RMSProp, net_11/net_11/impala/dense_2/kernel/RMSProp_1, net_11/net_11/impala/dense_2/bias/RMSProp, net_11/net_11/impala/dense_2/bias/RMSProp_1, net_12/impala/conv2d/kernel, net_12/impala/conv2d/bias, net_12/impala/conv2d_1/kernel, net_12/impala/conv2d_1/bias, net_12/impala/conv2d_2/kernel, net_12/impala/conv2d_2/bias, net_12/impala/dense/kernel, net_12/impala/dense/bias, net_12/impala/dense_1/kernel, net_12/impala/dense_1/bias, net_12/impala/dense_2/kernel, net_12/impala/dense_2/bias, net_12/net_12/impala/conv2d/kernel/RMSProp, net_12/net_12/impala/conv2d/kernel/RMSProp_1, net_12/net_12/impala/conv2d/bias/RMSProp, net_12/net_12/impala/conv2d/bias/RMSProp_1, net_12/net_12/impala/conv2d_1/kernel/RMSProp, net_12/net_12/impala/conv2d_1/kernel/RMSProp_1, net_12/net_12/impala/conv2d_1/bias/RMSProp, net_12/net_12/impala/conv2d_1/bias/RMSProp_1, net_12/net_12/impala/conv2d_2/kernel/RMSProp, net_12/net_12/impala/conv2d_2/kernel/RMSProp_1, net_12/net_12/impala/conv2d_2/bias/RMSProp, net_12/net_12/impala/conv2d_2/bias/RMSProp_1, net_12/net_12/impala/dense/kernel/RMSProp, net_12/net_12/impala/dense/kernel/RMSProp_1, net_12/net_12/impala/dense/bias/RMSProp, net_12/net_12/impala/dense/bias/RMSProp_1, net_12/net_12/impala/dense_1/kernel/RMSProp, net_12/net_12/impala/dense_1/kernel/RMSProp_1, net_12/net_12/impala/dense_1/bias/RMSProp, net_12/net_12/impala/dense_1/bias/RMSProp_1, net_12/net_12/impala/dense_2/kernel/RMSProp, net_12/net_12/impala/dense_2/kernel/RMSProp_1, net_12/net_12/impala/dense_2/bias/RMSProp, net_12/net_12/impala/dense_2/bias/RMSProp_1, net_13/impala/conv2d/kernel, net_13/impala/conv2d/bias, net_13/impala/conv2d_1/kernel, net_13/impala/conv2d_1/bias, net_13/impala/conv2d_2/kernel, net_13/impala/conv2d_2/bias, net_13/impala/dense/kernel, net_13/impala/dense/bias, net_13/impala/dense_1/kernel, net_13/impala/dense_1/bias, net_13/impala/dense_2/kernel, net_13/impala/dense_2/bias, net_13/net_13/impala/conv2d/kernel/RMSProp, net_13/net_13/impala/conv2d/kernel/RMSProp_1, net_13/net_13/impala/conv2d/bias/RMSProp, net_13/net_13/impala/conv2d/bias/RMSProp_1, net_13/net_13/impala/conv2d_1/kernel/RMSProp, net_13/net_13/impala/conv2d_1/kernel/RMSProp_1, net_13/net_13/impala/conv2d_1/bias/RMSProp, net_13/net_13/impala/conv2d_1/bias/RMSProp_1, net_13/net_13/impala/conv2d_2/kernel/RMSProp, net_13/net_13/impala/conv2d_2/kernel/RMSProp_1, net_13/net_13/impala/conv2d_2/bias/RMSProp, net_13/net_13/impala/conv2d_2/bias/RMSProp_1, net_13/net_13/impala/dense/kernel/RMSProp, net_13/net_13/impala/dense/kernel/RMSProp_1, net_13/net_13/impala/dense/bias/RMSProp, net_13/net_13/impala/dense/bias/RMSProp_1, net_13/net_13/impala/dense_1/kernel/RMSProp, net_13/net_13/impala/dense_1/kernel/RMSProp_1, net_13/net_13/impala/dense_1/bias/RMSProp, net_13/net_13/impala/dense_1/bias/RMSProp_1, net_13/net_13/impala/dense_2/kernel/RMSProp, net_13/net_13/impala/dense_2/kernel/RMSProp_1, net_13/net_13/impala/dense_2/bias/RMSProp, net_13/net_13/impala/dense_2/bias/RMSProp_1, net_14/impala/conv2d/kernel, net_14/impala/conv2d/bias, net_14/impala/conv2d_1/kernel, net_14/impala/conv2d_1/bias, net_14/impala/conv2d_2/kernel, net_14/impala/conv2d_2/bias, net_14/impala/dense/kernel, net_14/impala/dense/bias, net_14/impala/dense_1/kernel, net_14/impala/dense_1/bias, net_14/impala/dense_2/kernel, net_14/impala/dense_2/bias, net_14/net_14/impala/conv2d/kernel/RMSProp, net_14/net_14/impala/conv2d/kernel/RMSProp_1, net_14/net_14/impala/conv2d/bias/RMSProp, net_14/net_14/impala/conv2d/bias/RMSProp_1, net_14/net_14/impala/conv2d_1/kernel/RMSProp, net_14/net_14/impala/conv2d_1/kernel/RMSProp_1, net_14/net_14/impala/conv2d_1/bias/RMSProp, net_14/net_14/impala/conv2d_1/bias/RMSProp_1, net_14/net_14/impala/conv2d_2/kernel/RMSProp, net_14/net_14/impala/conv2d_2/kernel/RMSProp_1, net_14/net_14/impala/conv2d_2/bias/RMSProp, net_14/net_14/impala/conv2d_2/bias/RMSProp_1, net_14/net_14/impala/dense/kernel/RMSProp, net_14/net_14/impala/dense/kernel/RMSProp_1, net_14/net_14/impala/dense/bias/RMSProp, net_14/net_14/impala/dense/bias/RMSProp_1, net_14/net_14/impala/dense_1/kernel/RMSProp, net_14/net_14/impala/dense_1/kernel/RMSProp_1, net_14/net_14/impala/dense_1/bias/RMSProp, net_14/net_14/impala/dense_1/bias/RMSProp_1, net_14/net_14/impala/dense_2/kernel/RMSProp, net_14/net_14/impala/dense_2/kernel/RMSProp_1, net_14/net_14/impala/dense_2/bias/RMSProp, net_14/net_14/impala/dense_2/bias/RMSProp_1, net_15/impala/conv2d/kernel, net_15/impala/conv2d/bias, net_15/impala/conv2d_1/kernel, net_15/impala/conv2d_1/bias, net_15/impala/conv2d_2/kernel, net_15/impala/conv2d_2/bias, net_15/impala/dense/kernel, net_15/impala/dense/bias, net_15/impala/dense_1/kernel, net_15/impala/dense_1/bias, net_15/impala/dense_2/kernel, net_15/impala/dense_2/bias, net_15/net_15/impala/conv2d/kernel/RMSProp, net_15/net_15/impala/conv2d/kernel/RMSProp_1, net_15/net_15/impala/conv2d/bias/RMSProp, net_15/net_15/impala/conv2d/bias/RMSProp_1, net_15/net_15/impala/conv2d_1/kernel/RMSProp, net_15/net_15/impala/conv2d_1/kernel/RMSProp_1, net_15/net_15/impala/conv2d_1/bias/RMSProp, net_15/net_15/impala/conv2d_1/bias/RMSProp_1, net_15/net_15/impala/conv2d_2/kernel/RMSProp, net_15/net_15/impala/conv2d_2/kernel/RMSProp_1, net_15/net_15/impala/conv2d_2/bias/RMSProp, net_15/net_15/impala/conv2d_2/bias/RMSProp_1, net_15/net_15/impala/dense/kernel/RMSProp, net_15/net_15/impala/dense/kernel/RMSProp_1, net_15/net_15/impala/dense/bias/RMSProp, net_15/net_15/impala/dense/bias/RMSProp_1, net_15/net_15/impala/dense_1/kernel/RMSProp, net_15/net_15/impala/dense_1/kernel/RMSProp_1, net_15/net_15/impala/dense_1/bias/RMSProp, net_15/net_15/impala/dense_1/bias/RMSProp_1, net_15/net_15/impala/dense_2/kernel/RMSProp, net_15/net_15/impala/dense_2/kernel/RMSProp_1, net_15/net_15/impala/dense_2/bias/RMSProp, net_15/net_15/impala/dense_2/bias/RMSProp_1, global_step
W0729 05:34:17.782346 139672523310912 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:17.782537 139672523310912 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:17.798762 139672523310912 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.025177 139840264374080 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.025356 139840264374080 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.041241 139840264374080 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.131323 139672523310912 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.139014 140177118873408 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.139199 140177118873408 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.155515 140177118873408 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.277806 139673848579904 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.277982 139673848579904 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.293535 139673848579904 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.342436 139862653409088 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.342691 139862653409088 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.368701 139862653409088 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.378694 139840264374080 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.391169 139672523310912 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:18.393251 139949914994496 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.393435 139949914994496 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

2019-07-29 05:34:18.405779: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0729 05:34:18.406458 140464643467072 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.406636 140464643467072 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.409496 139949914994496 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.422244 140464643467072 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.486411 140177118873408 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.601429 140448530392896 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.601600 140448530392896 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.617153 140448530392896 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.622369 139673848579904 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.636646 139840264374080 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:18.655548 140254835648320 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.655720 140254835648320 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:18.671257 140254835648320 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.741404 140177118873408 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:18.748495 139949914994496 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.873193 139862653409088 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.877306 139673848579904 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:18.884528 139847427397440 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:18.884761 139847427397440 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

I0729 05:34:18.887322 139672523310912 session_manager.py:500] Running local_init_op.
W0729 05:34:18.895839 140464643467072 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:18.907578 139847427397440 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:18.946537 140448530392896 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:19.012775 140254835648320 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0729 05:34:19.028470 139949914994496 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
I0729 05:34:19.044634 139860167440192 session_manager.py:500] Running local_init_op.
W0729 05:34:19.137467 140249698912064 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:19.137723 140249698912064 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0729 05:34:19.163263 140249698912064 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

I0729 05:34:19.177504 139840264374080 session_manager.py:500] Running local_init_op.
W0729 05:34:19.192706 140464643467072 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
I0729 05:34:19.221879 139860167440192 session_manager.py:502] Done running local_init_op.
W0729 05:34:19.222034 140448530392896 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:19.243370 140494089393984 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0729 05:34:19.243670 140494089393984 deprecation_wrapper.py:119] From /home/nerdfactory/impala_distributed_tensorflow/utils.py:19: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

I0729 05:34:19.258006 140177118873408 session_manager.py:500] Running local_init_op.
W0729 05:34:19.269127 140494089393984 deprecation_wrapper.py:119] From trainer.py:64: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0729 05:34:19.272383 139862653409088 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:19.278933 140254835648320 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0729 05:34:19.430921 139847427397440 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
I0729 05:34:19.461761 139673848579904 session_manager.py:500] Running local_init_op.
2019-07-29 05:34:19.477705: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:19.478736 139672523310912 session_manager.py:502] Done running local_init_op.
I0729 05:34:19.535486 139949914994496 session_manager.py:500] Running local_init_op.
W0729 05:34:19.667241 140249698912064 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
I0729 05:34:19.730295 140448530392896 session_manager.py:500] Running local_init_op.
2019-07-29 05:34:19.749287: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:19.750306 139840264374080 session_manager.py:502] Done running local_init_op.
2019-07-29 05:34:19.801422: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0729 05:34:19.801319 140494089393984 deprecation.py:323] From trainer.py:71: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
I0729 05:34:19.802370 140177118873408 session_manager.py:502] Done running local_init_op.
I0729 05:34:19.804311 140254835648320 session_manager.py:500] Running local_init_op.
W0729 05:34:19.845031 139847427397440 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
I0729 05:34:19.969614 140464643467072 session_manager.py:500] Running local_init_op.
W0729 05:34:20.095169 140249698912064 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-07-29 05:34:20.111534: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:20.112820 139673848579904 session_manager.py:502] Done running local_init_op.
I0729 05:34:20.146826 139860167440192 supervisor.py:737] Starting standard services.
W0729 05:34:20.147032 139860167440192 supervisor.py:666] Standard services need a 'logdir' passed to the SessionManager
I0729 05:34:20.147096 139860167440192 supervisor.py:743] Starting queue runners.
I0729 05:34:20.159420 139862653409088 session_manager.py:500] Running local_init_op.
I0729 05:34:20.174567 139672523310912 supervisor.py:743] Starting queue runners.
2019-07-29 05:34:20.181999: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:20.183112 139949914994496 session_manager.py:502] Done running local_init_op.
W0729 05:34:20.225336 140494089393984 deprecation.py:323] From /home/nerdfactory/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-07-29 05:34:20.395282: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:20.396523 140448530392896 session_manager.py:502] Done running local_init_op.
I0729 05:34:20.493168 139840264374080 supervisor.py:743] Starting queue runners.
2019-07-29 05:34:20.532874: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:20.534056 140254835648320 session_manager.py:502] Done running local_init_op.
I0729 05:34:20.573211 140177118873408 supervisor.py:743] Starting queue runners.
2019-07-29 05:34:20.626410: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:20.627491 140464643467072 session_manager.py:502] Done running local_init_op.
I0729 05:34:20.708221 140249698912064 session_manager.py:500] Running local_init_op.
I0729 05:34:20.719113 139847427397440 session_manager.py:500] Running local_init_op.
2019-07-29 05:34:20.876865: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:20.878164 139862653409088 session_manager.py:502] Done running local_init_op.
I0729 05:34:20.884409 139673848579904 supervisor.py:743] Starting queue runners.
I0729 05:34:21.006938 140494089393984 session_manager.py:500] Running local_init_op.
I0729 05:34:21.038103 139949914994496 supervisor.py:743] Starting queue runners.
I0729 05:34:21.350706 140448530392896 supervisor.py:743] Starting queue runners.
2019-07-29 05:34:21.532214: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:21.537764 139847427397440 session_manager.py:502] Done running local_init_op.
I0729 05:34:21.551877 140464643467072 supervisor.py:743] Starting queue runners.
2019-07-29 05:34:21.562244: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:21.563624 140249698912064 session_manager.py:502] Done running local_init_op.
I0729 05:34:21.624461 140254835648320 supervisor.py:743] Starting queue runners.
I0729 05:34:21.902641 139862653409088 supervisor.py:743] Starting queue runners.
2019-07-29 05:34:21.916264: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
I0729 05:34:21.917618 140494089393984 session_manager.py:502] Done running local_init_op.
I0729 05:34:22.694059 140249698912064 supervisor.py:743] Starting queue runners.
I0729 05:34:22.720280 139847427397440 supervisor.py:743] Starting queue runners.
I0729 05:34:23.111362 140494089393984 supervisor.py:743] Starting queue runners.
I0729 05:34:47.535701 140590952777536 session_manager.py:500] Running local_init_op.
I0729 05:34:47.547708 140284647970624 session_manager.py:500] Running local_init_op.
I0729 05:34:47.692337 140183310444352 session_manager.py:500] Running local_init_op.
I0729 05:34:48.832156 140590952777536 session_manager.py:502] Done running local_init_op.
I0729 05:34:48.837371 140284647970624 session_manager.py:502] Done running local_init_op.
I0729 05:34:49.014326 140183310444352 session_manager.py:502] Done running local_init_op.
I0729 05:34:52.331709 140284647970624 supervisor.py:743] Starting queue runners.
I0729 05:34:52.399547 140590952777536 supervisor.py:743] Starting queue runners.
I0729 05:34:52.516124 140183310444352 supervisor.py:743] Starting queue runners.
14 0 -21.0 764 0.4044829761872741
14 1 -17.0 1215 0.38281217087443475
14 2 -19.0 1027 0.41780898569853653
14 3 -20.0 949 0.3939863167020116
14 4 -19.0 1117 0.35741815635319146
14 5 -20.0 919 0.38755894352614034
14 6 -20.0 903 0.389801845433044
14 7 -21.0 972 0.38891017673069556
14 8 -21.0 824 0.3871283604609735
14 9 -21.0 945 0.363123777335283
14 10 -21.0 852 0.3594352300737945
14 11 -20.0 964 0.3770865347870158
14 12 -21.0 824 0.3686023268450811
14 13 -20.0 1102 0.3893146166026917
14 14 -20.0 1011 0.3853942712383855
14 15 -21.0 824 0.37989566829598065
14 16 -20.0 964 0.40592208288269915
14 17 -21.0 871 0.36500340765160344
14 18 -21.0 974 0.3657228996560314
14 19 -21.0 1124 0.36776007719841713
14 20 -21.0 886 0.3811852721745489
14 21 -21.0 824 0.4037754495167038
14 22 -18.0 1095 0.4008810236573764
14 23 -21.0 925 0.37734280599130166
14 24 -20.0 1082 0.39832070723258634
14 25 -21.0 916 0.39966593360666625
14 26 -21.0 1087 0.36177318918123746
14 27 -20.0 1043 0.3488196222288382
14 28 -20.0 902 0.3518361680523519
14 29 -21.0 886 0.3656487974167946
14 30 -21.0 852 0.34443114551020343
14 31 -21.0 872 0.3433368995854067
14 32 -21.0 1008 0.3431957547390272
14 33 -21.0 976 0.3495309928767994
14 34 -20.0 991 0.365869972557882
14 35 -20.0 978 0.3573667054771158
14 36 -19.0 1018 0.36510415214218184
14 37 -21.0 764 0.36174999700166793
14 38 -21.0 764 0.37278550847662684
14 39 -21.0 946 0.3786006109596055
14 40 -21.0 916 0.3713535187546343
14 41 -21.0 764 0.3742282494356495
14 42 -21.0 826 0.39590751183090717
14 43 -21.0 1100 0.37307820452885193
14 44 -21.0 793 0.3653943031312238
14 45 -21.0 824 0.35543406747498557
14 46 -21.0 873 0.3608684019534449
14 47 -21.0 912 0.36274902166373896
14 48 -21.0 946 0.37332642828183243
14 49 -21.0 884 0.36906336979493837
14 50 -18.0 1035 0.36369457319738785
14 51 -21.0 792 0.38328563019332257
14 52 -20.0 947 0.39166218684366666
14 53 -21.0 1004 0.4167560624530116
14 54 -20.0 842 0.4217887971364404
14 55 -20.0 842 0.44533402959411333
14 56 -21.0 824 0.42511945087643505
14 57 -21.0 1069 0.40172214609535084
14 58 -19.0 991 0.37154079740632073
14 59 -21.0 976 0.3637431260564777
14 60 -20.0 1045 0.3631128598628432
14 61 -21.0 1123 0.3575378049194866
14 62 -21.0 884 0.36058988044569396
14 63 -21.0 934 0.3671649427689628
14 64 -20.0 993 0.36580943668116733
14 65 -19.0 1235 0.36705149250474534
14 66 -20.0 1008 0.3660032086015221
14 67 -21.0 945 0.38445742082974266
14 68 -20.0 981 0.3748692395915557
14 69 -20.0 842 0.34964311406051746
14 70 -21.0 931 0.34762209352950146
14 71 -20.0 927 0.3518398502497997
14 72 -20.0 1036 0.3479080797392429
14 73 -20.0 1304 0.3562523104661813
14 74 -20.0 983 0.36500237192409085
14 75 -19.0 1057 0.3789178387613486
14 76 -21.0 964 0.399493356865224
14 77 -21.0 826 0.3754275148197756
14 78 -20.0 964 0.37123852665246276
14 79 -21.0 826 0.3562892833431466
14 80 -20.0 904 0.3609908487878542
14 81 -21.0 852 0.35949140612228375
14 82 -21.0 962 0.36807343642577806
14 83 -21.0 853 0.38499904754991965
14 84 -20.0 887 0.37435769480406367
14 85 -21.0 975 0.3841259745756785
14 86 -21.0 1006 0.390750399699979
14 87 -20.0 983 0.37989029382276873
14 88 -21.0 811 0.3705557389265218
14 89 -20.0 962 0.34942020206342367
14 90 -21.0 764 0.34443064946778784
14 91 -19.0 1226 0.35229878081388616
14 92 -21.0 941 0.3759579931511509
14 93 -20.0 902 0.37827531091389793
14 94 -20.0 964 0.3686007051052394
14 95 -20.0 1283 0.3863982727354797
14 96 -21.0 972 0.3818507293246901
14 97 -20.0 903 0.3755455892347418
14 98 -20.0 965 0.38712713684442746
14 99 -21.0 976 0.4024268684939283
14 100 -21.0 872 0.38350788579074613
14 101 -20.0 899 0.39382524203272895
14 102 -18.0 1156 0.4086682068177573
14 103 -20.0 842 0.413077936461306
14 104 -21.0 824 0.42824282602054403
14 105 -21.0 884 0.40203535057840306
14 106 -21.0 826 0.42188494116717334
14 107 -20.0 843 0.41206421871909327
14 108 -21.0 826 0.4180172377651598
14 109 -20.0 966 0.428760209007046
14 110 -21.0 826 0.4028584009293494
14 111 -20.0 1053 0.37727126948967055
14 112 -21.0 1095 0.3868178684689683
14 113 -20.0 1111 0.41645515914654324
14 114 -20.0 902 0.39609545717086075
14 115 -21.0 783 0.36752138276362023
14 116 -21.0 973 0.39339312071790433
14 117 -20.0 842 0.40805865176499884
14 118 -21.0 972 0.3976298167136471
14 119 -21.0 852 0.3819286152370659
14 120 -21.0 1065 0.3686962750316226
14 121 -19.0 1015 0.36974110318522146
14 122 -20.0 964 0.360556050207605
14 123 -21.0 940 0.3505106453565841
14 124 -20.0 870 0.3612828124871199
14 125 -20.0 958 0.3518595886504227
14 126 -20.0 931 0.3520948153817436
14 127 -21.0 1000 0.3618682008385658
14 128 -20.0 1057 0.3640913988411596
14 129 -20.0 979 0.3731038452595077
14 130 -21.0 1189 0.3854863915351181
14 131 -19.0 1016 0.37807910874720635
14 132 -21.0 826 0.43131540394579815
14 133 -21.0 905 0.41779237850594914
14 134 -21.0 974 0.4036982075083672
14 135 -19.0 1018 0.3628957508706391
14 136 -20.0 978 0.3665250767715626
14 137 -21.0 914 0.36382564325170913
14 138 -21.0 825 0.38698018417213903
14 139 -21.0 884 0.37643169739801957
14 140 -21.0 992 0.35516114992600295
14 141 -20.0 932 0.37467879191232856
14 142 -19.0 937 0.3671514732542516
14 143 -21.0 853 0.3719450773066401
14 144 -21.0 824 0.37118145074803854
14 145 -20.0 1191 0.3804892814779962
14 146 -20.0 967 0.3850268442357092
14 147 -21.0 1004 0.4029697200572823
14 148 -20.0 919 0.36008743032148277
14 149 -21.0 824 0.37391664890699017
14 150 -21.0 912 0.3801497239946273
14 151 -21.0 855 0.36428779321804383
14 152 -21.0 783 0.3683139767454959
14 153 -18.0 1171 0.3806390850896208
14 154 -20.0 1196 0.3660294535666405
14 155 -21.0 1035 0.35452953038584206
14 156 -20.0 1211 0.35870935112656294
14 157 -20.0 1194 0.35438622147393983
14 158 -20.0 964 0.3570190760542743
14 159 -21.0 949 0.3612469008900971
14 160 -21.0 911 0.3705923660984416
14 161 -20.0 962 0.36236596020740186
14 162 -19.0 921 0.3677417314272621
14 163 -20.0 940 0.378303913233128
14 164 -20.0 1050 0.38230810301644463
14 165 -20.0 861 0.36578327088544316
14 166 -21.0 975 0.36393237792528593
14 167 -21.0 946 0.37071796467263907
14 168 -20.0 960 0.37901866479466356
14 169 -20.0 931 0.36084491971612104
14 170 -21.0 960 0.3825483717645208
14 171 -20.0 1257 0.3705675683755579
14 172 -21.0 942 0.38171679401600184
14 173 -20.0 842 0.3830468410763208
14 174 -20.0 1011 0.37696525127314673
14 175 -21.0 873 0.3662774893972609
14 176 -21.0 904 0.37329919781305093
14 177 -19.0 1042 0.372779016388355
14 178 -18.0 1337 0.37015922642859755
14 179 -20.0 859 0.3595245590518045
14 180 -21.0 792 0.36763654314357824
14 181 -17.0 1369 0.35908996862943715
14 182 -21.0 824 0.3639460110910309
14 183 -21.0 886 0.3842970786056992
14 184 -21.0 824 0.3718565634804443
14 185 -20.0 1128 0.3686229258987075
14 186 -20.0 1053 0.3702414294197122
14 187 -20.0 871 0.3670798586307245
14 188 -20.0 963 0.3654860152881341
14 189 -20.0 971 0.36333457230907756
14 190 -20.0 980 0.3680445645840801
14 191 -20.0 981 0.3820993918222997
14 192 -21.0 824 0.37149595686243575
14 193 -20.0 993 0.40842042039528353
14 194 -20.0 889 0.38924831795611986
14 195 -19.0 1245 0.37690796768330187
14 196 -21.0 942 0.3638709230534337
14 197 -20.0 1027 0.37518041792027323
14 198 -21.0 783 0.39017680892542406
14 199 -19.0 1146 0.3842563760478251
14 200 -20.0 999 0.38326375677182273
14 201 -20.0 921 0.36971739756426775
14 202 -19.0 1201 0.3795501135668092
14 203 -19.0 937 0.3688586925811422
14 204 -20.0 1011 0.36996594089075086
14 205 -21.0 854 0.3686366773251907
14 206 -20.0 1172 0.3980696855856697
14 207 -21.0 948 0.3865890216852542
14 208 -19.0 1054 0.3845656778543226
14 209 -20.0 931 0.39964242873335243
14 210 -21.0 979 0.38364824637451017
14 211 -21.0 913 0.3713858354130815
14 212 -21.0 1007 0.3763398867851454
14 213 -20.0 1008 0.3771390877959747
14 214 -19.0 956 0.36989406190781415
14 215 -19.0 1114 0.38276207888468805
14 216 -20.0 1025 0.3881223649804185
14 217 -18.0 1174 0.37438058751608283
14 218 -21.0 888 0.38020309228617866
14 219 -20.0 968 0.3785270032249699
14 220 -18.0 1137 0.3805202861679366
14 221 -19.0 1332 0.4025373166208869
14 222 -19.0 1016 0.3859283238590702
14 223 -19.0 1027 0.41944305576971697
14 224 -21.0 811 0.3929634081009137
14 225 -20.0 1110 0.4240869177085859
1415 0 -21.0 783 0.396534887157942
15 1 -21.0 888 0.376865529497196
15 2 -21.0 884 0.40852677710860025
15 3 -21.0 854 0.41258557699184506
15 4 -20.0 950 0.35286488071868294
15 5 -21.0 792 0.3669426998481004
15 6 -20.0 964 0.3917944909873345
15 7 -21.0 792 0.3788123782912288
15 8 -20.0 843 0.3993312940266633
15 9 -21.0 1124 0.37423511345297417
15 10 -20.0 1035 0.35224455410731587
15 11 -21.0 903 0.37222060653590416
15 12 -19.0 1040 0.37187791985387986
15 13 -21.0 783 0.3732052267282859
15 14 -20.0 921 0.39431065020033124
15 15 -20.0 888 0.384659403683366
15 16 -21.0 884 0.39588465292124725
15 17 -20.0 981 0.3952069166178125
15 18 -21.0 852 0.35736732580152475
15 19 -21.0 1004 0.36956664070902595
15 20 -20.0 1040 0.3663945888957152
15 21 -21.0 824 0.3838153983493453
15 22 -21.0 1002 0.41196894586205246
15 23 -21.0 792 0.39606954480963524
15 24 -21.0 824 0.37579086459088096
15 25 -21.0 973 0.39570955707014893
15 26 -21.0 853 0.397490365598853
15 27 -21.0 1103 0.3730327078729787
15 28 -20.0 1065 0.3512876944083003
15 29 -21.0 884 0.3486379017185302
15 30 -20.0 982 0.3671187036149128
15 31 -21.0 1005 0.3443820740156506
15 32 -21.0 793 0.34223087983203565
15 33 -21.0 843 0.3451362398595572
15 34 -19.0 937 0.34900535558814555
15 35 -18.0 1265 0.3637302842771583
15 36 -20.0 930 0.35615787108739216
15 37 -21.0 824 0.36537779610857224
15 38 -19.0 998 0.36054512413446316
15 39 -21.0 880 0.3761046402833679
15 40 -20.0 903 0.37406297778898434
15 41 -21.0 852 0.37291867142551943
15 42 -21.0 884 0.37995721409898
15 43 -20.0 889 0.38899707405317757
15 44 -21.0 885 0.3717206044048913
15 45 -20.0 1042 0.359648561580625
15 46 -21.0 915 0.35663837510379937
15 47 -20.0 979 0.35960711786890664
15 48 -21.0 764 0.36503613221395703
15 49 -21.0 1189 0.37408326106276
15 50 -20.0 1026 0.3672317190941779
15 51 -21.0 794 0.3718328622711696
15 52 -21.0 896 0.3907357986484255
15 53 -20.0 923 0.40772298721037603
15 54 -21.0 884 0.41803294120196305
15 55 -21.0 852 0.4370662770081014
15 56 -20.0 887 0.4279909945327238
15 57 -21.0 854 0.40733015317408766
15 58 -21.0 884 0.3920570483507074
15 59 -21.0 940 0.3646128743886948
15 60 -21.0 824 0.3678891091309126
15 61 -21.0 793 0.3628197919676012
15 62 -20.0 990 0.35883980525864495
15 63 -21.0 915 0.35630690315382074
15 64 -21.0 944 0.36873588000692553
15 65 -20.0 1021 0.363990444482015
15 66 -21.0 948 0.3708424563146342
15 67 -21.0 1064 0.368315538573534
15 68 -21.0 824 0.3750958701649916
15 69 -20.0 964 0.38355683204544033
15 70 -21.0 945 0.3596574113482521
15 71 -21.0 882 0.35129853515397935
15 72 -20.0 1191 0.3496774897717509
15 73 -21.0 946 0.34939551337702834
15 74 -20.0 964 0.35843093547954596
15 75 -19.0 1086 0.3558356084656759
15 76 -21.0 824 0.3735491646435654
15 77 -21.0 945 0.38331591234636053
15 78 -20.0 888 0.3971246008400445
15 79 -21.0 826 0.37511656164545704
15 80 -20.0 1024 0.3658911866368726
15 81 -20.0 919 0.36081432089841925
15 82 -21.0 855 0.35486462151097975
15 83 -21.0 885 0.35810774477188195
15 84 -21.0 903 0.381337094577576
15 85 -20.0 921 0.3813530469756173
15 86 -21.0 910 0.38036912005026263
15 87 -21.0 825 0.3900792891690225
15 88 -21.0 825 0.3875206644968553
15 89 -20.0 1024 0.37559106876142323
15 90 -20.0 1103 0.36581363263501976
15 91 -19.0 1045 0.34188744585479847
15 92 -20.0 1104 0.3507544063841519
15 93 -19.0 1099 0.36257092205907565
15 94 -20.0 842 0.38343186566778714
15 95 -21.0 975 0.3702484338405805
15 96 -21.0 1005 0.38027868226392947
15 97 -21.0 824 0.388530820897482
15 98 -20.0 1039 0.3822422497426236
15 99 -18.0 1212 0.3720580878430861
15 100 -20.0 1008 0.3966855073850306
15 101 -20.0 981 0.38514906407982324
15 102 -21.0 946 0.39585342228286613
15 103 -18.0 1086 0.4086224987252202
15 104 -20.0 981 0.4071357567375953
15 105 -21.0 824 0.42968529404945743
15 106 -21.0 824 0.39951451549541606
15 107 -20.0 904 0.42089267384953205
15 108 -20.0 842 0.4127792716026306
15 109 -20.0 994 0.4198099031774571
15 110 -20.0 870 0.42985396052914104
15 111 -20.0 948 0.39891728582764474
15 112 -21.0 1124 0.37674722327350296
15 113 -21.0 852 0.3913006936440445
15 114 -21.0 965 0.42262946228289233
15 115 -20.0 929 0.40085977546878726
15 116 -18.0 1110 0.36592247542497275
15 117 -21.0 794 0.3945020760787224
15 118 -21.0 824 0.41347805848254743
15 119 -21.0 826 0.39662293454780995
15 120 -20.0 842 0.3736213671835471
15 121 -18.0 1187 0.3684013724929662
15 122 -21.0 944 0.3701923627216937
15 123 -21.0 1153 0.3573912194988982
15 124 -20.0 930 0.3479735655810243
15 125 -21.0 824 0.3551508927157203
15 126 -21.0 904 0.35329331701571964
15 127 -20.0 871 0.3538425702999435
15 128 -20.0 982 0.3543927619146475
15 129 -21.0 1122 0.3618890454265523
15 130 -21.0 941 0.38067158838134263
15 131 -21.0 944 0.3914861014207541
15 132 -21.0 946 0.37595577733335234
15 133 -21.0 976 0.4201606595736058
15 134 -18.0 1120 0.4124612973470773
15 135 -21.0 843 0.4028758988190942
15 136 -20.0 1027 0.36706836380884267
15 137 -21.0 1265 0.36687450109734365
15 138 -20.0 1024 0.3720081975625362
15 139 -21.0 972 0.3920141988943634
15 140 -21.0 783 0.36254058570849634
15 141 -20.0 921 0.35264423321305605
15 142 -18.0 1035 0.37961769440899723
15 143 -19.0 1059 0.36795652061841533
15 144 -21.0 942 0.36198143689495743
15 145 -21.0 946 0.3861340355545471
15 146 -21.0 912 0.3754544279685146
15 147 -21.0 826 0.38145874419021836
15 148 -21.0 975 0.3929211074878008
15 149 -20.0 902 0.3618109359709492
15 150 -21.0 881 0.3626461963377529
15 151 -19.0 998 0.3719196974753378
15 152 -20.0 842 0.3723590583883385
15 153 -20.0 1193 0.38593648435284084
15 154 -20.0 949 0.37421415217055914
15 155 -21.0 905 0.35921863771933876
15 156 -20.0 1041 0.3546506891046775
15 157 -19.0 938 0.3570265582184802
15 158 -20.0 902 0.3581489036788962
15 159 -20.0 993 0.35984100820074627
15 160 -21.0 942 0.3670395853792786
15 161 -20.0 938 0.3760329987258037
15 162 -21.0 1187 0.3749332681561882
15 163 -21.0 912 0.37170896754322347
15 164 -20.0 1110 0.37815136930964016
15 165 -21.0 811 0.3821218356986228
15 166 -21.0 852 0.3628500908823081
15 167 -20.0 940 0.3638281121532968
15 168 -21.0 873 0.36921130771079835
15 169 -21.0 904 0.3860510771978745
15 170 -21.0 975 0.3669281524572617
15 171 -21.0 886 0.3765789564051424
15 172 -21.0 1006 0.36936056465799244
15 173 -20.0 920 0.3810486822348574
15 174 -20.0 1008 0.3826950762775682
15 175 -21.0 946 0.378294212936599
15 176 -19.0 1014 0.3670020754461928
15 177 -20.0 990 0.3714396968935475
15 178 -19.0 1134 0.36840658717685276
15 179 -21.0 853 0.36174537124415773
15 180 -20.0 1099 0.3736553516737215
15 181 -20.0 1172 0.36333181195393355
15 182 -21.0 824 0.3557176123762015
15 183 -20.0 1227 0.3640351168926693
15 184 -20.0 984 0.3784581088438267
15 185 -20.0 930 0.3767329853388571
15 186 -19.0 1057 0.3838753223193628
15 187 -19.0 1034 0.3628172751090974
15 188 -20.0 1166 0.3645443437081054
15 189 -20.0 1023 0.3679202973900885
15 190 -21.0 1034 0.3586258051819681
15 191 -19.0 1375 0.3827383660619909
15 192 -18.0 1190 0.3855475431981207
15 193 -21.0 783 0.4053322732981442
15 194 -21.0 1004 0.3872724101244216
15 195 -21.0 884 0.364628149407212
15 196 -20.0 951 0.3636377629609514
15 197 -20.0 1194 0.37600954281325316
15 198 -20.0 964 0.3874189152200687
15 199 -21.0 1002 0.3835360414670137
15 200 -19.0 1210 0.3803971188373802
15 201 -20.0 1055 0.389493685932521
15 202 -21.0 764 0.3945901745354942
15 203 -19.0 1062 0.37582862141442164
15 204 -21.0 945 0.372152728031552
15 205 -19.0 1190 0.37907613946610136
15 206 -20.0 1132 0.4002252897188436
15 207 -21.0 946 0.3828091360549846
15 208 -18.0 1051 0.413896323639818
15 209 -21.0 852 0.3879136723321928
15 210 -21.0 1003 0.37308377449438795
15 211 -21.0 783 0.37218163235738666
15 212 -20.0 982 0.37679877516087107
15 213 -21.0 871 0.386377132240037
15 214 -21.0 826 0.3713111686215851
15 215 -19.0 1002 0.3836225130541358
15 216 -20.0 1011 0.37673519971816405
15 217 -20.0 1207 0.38594453645424104
15 218 -21.0 1008 0.39808593489347943
15 219 -21.0 977 0.39848487025761675
15 220 -19.0 1077 0.3861674348457942
15 221 -21.0 1046 0.4154211864530698
15 222 -20.0 923 0.3819921148430358
15 223 -20.0 986 0.4415025390971747
15 224 -20.0 1342 0.41745785798116875
15 225 -21.0 843 0.3954769574803955
15 226 -20.0 1131 13 0 -21.0 764 0.3977256267092615
13 1 -21.0 764 0.3890438231186093
13 2 -20.0 904 0.38535348599595304
13 3 -21.0 824 0.4331693912232385
13 4 -21.0 1000 0.36691927164793015
13 5 -20.0 1158 0.3663803628792211
13 6 -21.0 842 0.40313952265754166
13 7 -20.0 948 0.37828616175470475
13 8 -20.0 842 0.4025283580437975
13 9 -21.0 824 0.37337487292231863
13 10 -21.0 824 0.3615121848302559
13 11 -19.0 998 0.361561683650485
13 12 -20.0 1049 0.37249737029080165
13 13 -20.0 902 0.3743741980148789
13 14 -21.0 914 0.3909084503773266
13 15 -20.0 979 0.38375127260726366
13 16 -21.0 792 0.3991445162230068
13 17 -20.0 966 0.3951696362924872
13 18 -21.0 916 0.3503699531721756
13 19 -19.0 1016 0.37296856127268685
13 20 -19.0 1148 0.3681235261754707
13 21 -21.0 764 0.3909592944446034
13 22 -21.0 764 0.4137898886000923
13 23 -21.0 824 0.3861639674355104
13 24 -20.0 981 0.3723674644388555
13 25 -21.0 946 0.40051704786922665
13 26 -21.0 886 0.4022782838169662
13 27 -20.0 887 0.35867228475740554
13 28 -21.0 903 0.3504492473496683
13 29 -19.0 922 0.34562086671138276
13 30 -21.0 961 0.3675865761385252
13 31 -21.0 824 0.346711981860758
13 32 -21.0 899 0.34076780833312215
13 33 -21.0 944 0.34274921140049475
13 34 -21.0 930 0.34864629580769485
13 35 -21.0 884 0.36002457924018616
13 36 -19.0 921 0.35908444156217006
13 37 -20.0 1156 0.3622936991310862
13 38 -21.0 920 0.36084356408404267
13 39 -19.0 997 0.37771998688115277
13 40 -21.0 764 0.37366382137955173
13 41 -20.0 965 0.37329181713761445
13 42 -21.0 824 0.38215549062322646
13 43 -20.0 905 0.3877136377669171
13 44 -21.0 880 0.37070195197381756
13 45 -20.0 1039 0.3596652257717837
13 46 -20.0 870 0.3587735164439541
13 47 -21.0 824 0.36122986620056974
13 48 -21.0 825 0.36316811175057384
13 49 -21.0 1022 0.3735389555212103
13 50 -20.0 983 0.36902004271169647
13 51 -21.0 764 0.36546519582028164
13 52 -20.0 921 0.38771713019452836
13 53 -20.0 1191 0.407255506660636
13 54 -20.0 960 0.420924960821867
13 55 -20.0 873 0.4416191353625858
13 56 -21.0 854 0.4259770297264327
13 57 -20.0 981 0.3994162390720589
13 58 -18.0 1368 0.36846362522732445
13 59 -21.0 887 0.3698355677162781
13 60 -21.0 885 0.3591285425390901
13 61 -20.0 842 0.3615571455476969
13 62 -19.0 1016 0.3584603982002247
13 63 -18.0 1136 0.36561695932292604
13 64 -21.0 912 0.3780236377854619
13 65 -20.0 982 0.3648745677075415
13 66 -20.0 1070 0.36624246518188547
13 67 -21.0 940 0.38366841474112046
13 68 -21.0 1034 0.3752204472310769
13 69 -19.0 1009 0.34969631413402125
13 70 -18.0 1153 0.3484972473960903
13 71 -21.0 854 0.3531657104539648
13 72 -21.0 872 0.35233330354094505
13 73 -20.0 1102 0.3582047324107044
13 74 -20.0 1154 0.36940632455786965
13 75 -21.0 825 0.38045381195617445
13 76 -21.0 967 0.397458550417189
13 77 -21.0 903 0.37043808511193277
13 78 -20.0 1012 0.36379100994865887
13 79 -21.0 912 0.36124971123379573
13 80 -21.0 884 0.3555919310558436
13 81 -21.0 914 0.36646125014031744
13 82 -20.0 1087 0.38044278223578165
13 83 -21.0 974 0.38297066615714676
13 84 -20.0 1142 0.3866077820442604
13 85 -21.0 826 0.3924292417256653
13 86 -20.0 1084 0.3776253887977987
13 87 -20.0 1052 0.3644873938972959
13 88 -21.0 852 0.3438768074126311
13 89 -21.0 764 0.34612929200782827
13 90 -21.0 826 0.3515626402801809
13 91 -21.0 1218 0.3766968276210998
13 92 -20.0 1052 0.37861441271273355
13 93 -20.0 983 0.3785287872153891
13 94 -20.0 932 0.3899471311482237
13 95 -20.0 1041 0.38161551794905024
13 96 -21.0 886 0.3735936575361084
13 97 -20.0 1252 0.3900856090525088
13 98 -20.0 1141 0.38955073328941775
13 99 -21.0 888 0.38540080847503905
13 100 -21.0 884 0.41104682460764413
13 101 -20.0 1026 0.40697565451119144
13 102 -21.0 887 0.43365572344221953
13 103 -19.0 973 0.40247606502162464
13 104 -21.0 1004 0.4240350555851165
13 105 -21.0 972 0.4146103895434136
13 106 -21.0 886 0.4154477261393657
13 107 -21.0 976 0.42217922277870723
13 108 -21.0 912 0.3913119488902259
13 109 -21.0 1036 0.3737461126506559
13 110 -19.0 1012 0.39819847754103394
13 111 -21.0 886 0.4163670381762373
13 112 -21.0 949 0.3821023719579578
13 113 -19.0 1072 0.3746223973471727
13 114 -20.0 861 0.40876306754371433
13 115 -21.0 913 0.39453489179156825
13 116 -21.0 1036 0.38847650967279457
13 117 -20.0 1069 0.3698379890008771
13 118 -21.0 1020 0.3724297769221605
13 119 -18.0 1060 0.3586582842300523
13 120 -20.0 932 0.34796528300758084
13 121 -21.0 994 0.3556871181522577
13 122 -21.0 840 0.3519510326286157
13 123 -21.0 904 0.3527279572347097
13 124 -20.0 1040 0.3544636311152807
13 125 -20.0 1135 0.3627040809209126
13 126 -20.0 1067 0.37914006500011754
13 127 -19.0 950 0.38321561581210084
13 128 -20.0 902 0.39072643590475664
13 129 -21.0 913 0.4195688646633549
13 130 -21.0 792 0.4111189438839151
13 131 -21.0 792 0.4126994388196806
13 132 -20.0 919 0.3748105623646841
13 133 -19.0 1145 0.36066552421411574
13 134 -20.0 981 0.3622548583207631
13 135 -21.0 994 0.3942859076877955
13 136 -21.0 912 0.3709434690770873
13 137 -21.0 1064 0.3565432523426257
13 138 -21.0 933 0.39172602527139017
13 139 -20.0 842 0.37240895558139775
13 140 -21.0 852 0.3591223488531202
13 141 -18.0 1123 0.37122398641421556
13 142 -21.0 988 0.37370139417740017
13 143 -21.0 824 0.3817873115750771
13 144 -21.0 1004 0.38910695744225704
13 145 -21.0 912 0.3564589042870099
13 146 -21.0 947 0.3706179715323222
13 147 -20.0 1175 0.3821893889092384
13 148 -21.0 764 0.37263163811093225
13 149 -21.0 792 0.3792746753027343
13 150 -21.0 853 0.3769808018542957
13 151 -20.0 1008 0.354787888419297
13 152 -19.0 1138 0.3607627585765976
13 153 -19.0 1000 0.36388097137212755
13 154 -19.0 1019 0.35383954208428303
13 155 -21.0 824 0.36324301651380597
13 156 -20.0 842 0.3616644740812569
13 157 -21.0 1001 0.37434129329113575
13 158 -20.0 991 0.37816246754586635
13 159 -21.0 933 0.3740918789645867
13 160 -21.0 991 0.37708422168713407
13 161 -19.0 1087 0.379377675089358
13 162 -20.0 1043 0.36713483558176574
13 163 -21.0 854 0.35851864747057477
13 164 -21.0 824 0.36714088316391974
13 165 -21.0 826 0.38373602190693124
13 166 -20.0 1019 0.3612282112957334
13 167 -21.0 811 0.3720096842501813
13 168 -19.0 1125 0.3653743768533071
13 169 -21.0 1002 0.38322398961780074
13 170 -21.0 1013 0.38466668693828676
13 171 -21.0 825 0.3793116887410482
13 172 -21.0 820 0.36912291115377005
13 173 -20.0 920 0.3738999961834887
13 174 -21.0 1086 0.37464110034605413
13 175 -19.0 1105 0.3734307300720819
13 176 -20.0 980 0.3637264355408902
13 177 -21.0 1053 0.36335796364012607
13 178 -17.0 1205 0.35948489065981504
13 179 -21.0 842 0.3659134382236032
13 180 -19.0 1018 0.3716851899689448
13 181 -20.0 1010 0.3850351017300445
13 182 -21.0 976 0.37415823993868513
13 183 -20.0 1020 0.37090107339854334
13 184 -20.0 1103 0.36406280312447364
13 185 -20.0 992 0.3591560454017693
13 186 -21.0 994 0.3641138623058196
13 187 -20.0 980 0.38593959796185395
13 188 -21.0 918 0.37370909620603965
13 189 -20.0 994 0.39993560694952607
13 190 -19.0 1096 0.3937867163632908
13 191 -20.0 1131 0.3744327385377083
13 192 -20.0 962 0.3658591879380716
13 193 -20.0 1024 0.3738338829425629
13 194 -21.0 943 0.3878288230170374
13 195 -19.0 1150 0.38974144217760665
13 196 -21.0 884 0.395319719019249
13 197 -21.0 852 0.3717315878386789
13 198 -21.0 905 0.3777611876390257
13 199 -21.0 1006 0.38273427319929565
13 200 -20.0 1035 0.373918720835073
13 201 -20.0 1182 0.3687092042614764
13 202 -18.0 1214 0.39299295508782983
13 203 -21.0 1020 0.4014253082228642
13 204 -20.0 930 0.40230201639795815
13 205 -20.0 1224 0.40381858583077107
13 206 -21.0 963 0.38941642236610563
13 207 -21.0 826 0.3711715114390879
13 208 -20.0 879 0.3743208282975749
13 209 -21.0 792 0.3742329966690805
13 210 -19.0 1351 0.38676733199884766
13 211 -18.0 1226 0.384703368070075
13 212 -21.0 931 0.3912200195000584
13 213 -21.0 910 0.38367293837306266
13 214 -18.0 1324 0.37820400950411653
13 215 -21.0 1062 0.3849911512403614
13 216 -21.0 888 0.38685171682018415
13 217 -19.0 1136 0.4221318028342556
13 218 -20.0 1071 0.4085933102223497
13 219 -20.0 1023 0.408550302216734
13 220 -21.0 909 0.39587273869183986
13 221 -21.0 1457 0.4205643696660609
13 222 -20.0 979 0.3968411430153345
13 223 -21.0 1218 0.41759257549527046
13 224 -21.0 783 0.3878676436489417
13 225 -20.0 1129 0.386944294556566211 0 -18.0 1122 0.3993441492000366
11 1 -21.0 888 0.37375586496682855
11 2 -20.0 870 0.41744988495591046
11 3 -19.0 983 0.3712366183315871
11 4 -21.0 1092 0.3652251358706873
11 5 -20.0 919 0.39867950812128083
11 6 -21.0 825 0.37812728152130587
11 7 -21.0 886 0.39896327590162006
11 8 -19.0 982 0.3697091694579833
11 9 -20.0 1039 0.3540885695708957
11 10 -20.0 887 0.3664535375095677
11 11 -20.0 843 0.3723950871439874
11 12 -21.0 792 0.37849502423495957
11 13 -19.0 1077 0.3901261854968695
11 14 -21.0 852 0.37875534538092187
11 15 -21.0 903 0.4035246793349848
11 16 -21.0 811 0.36761656642401114
11 17 -21.0 853 0.36136310164143026
11 18 -21.0 824 0.36998368405456683
11 19 -20.0 999 0.36999538866010634
11 20 -19.0 920 0.4015463399174421
11 21 -18.0 1100 0.40435577525333927
11 22 -20.0 1101 0.3747242527804951
11 23 -21.0 824 0.39965503930466845
11 24 -21.0 825 0.3979150932124167
11 25 -21.0 1008 0.3612492054346062
11 26 -20.0 842 0.3494244418206521
11 27 -20.0 979 0.35089425515836303
11 28 -20.0 1114 0.3603296423835857
11 29 -20.0 1103 0.3413328957471216
11 30 -21.0 845 0.34519528326903576
11 31 -20.0 870 0.34515473359617693
11 32 -20.0 1071 0.36039807479811203
11 33 -20.0 1011 0.3602254332055206
11 34 -21.0 912 0.35860925108978625
11 35 -21.0 814 0.36437991561702193
11 36 -19.0 1147 0.37374479604889854
11 37 -21.0 1066 0.37231623936325703
11 38 -20.0 932 0.37151246319640857
11 39 -21.0 946 0.3926921669259888
11 40 -20.0 980 0.37530203832655534
11 41 -20.0 978 0.36571756559890717
11 42 -21.0 961 0.35470893548008803
11 43 -21.0 825 0.3633038234710693
11 44 -21.0 885 0.36320596034243957
11 45 -21.0 848 0.37522896583069043
11 46 -21.0 943 0.3689260772278301
11 47 -21.0 824 0.3634917934615057
11 48 -21.0 944 0.3808467803933358
11 49 -21.0 826 0.388963936965633
11 50 -21.0 1002 0.41726289157144086
11 51 -21.0 914 0.42471349268695197
11 52 -20.0 861 0.4394524948591416
11 53 -21.0 824 0.422344646009716
11 54 -21.0 783 0.39737286292121177
11 55 -20.0 919 0.3741586069547053
11 56 -21.0 854 0.365716491182459
11 57 -21.0 1034 0.3661174410719936
11 58 -21.0 864 0.35964980590398665
11 59 -21.0 764 0.35289449666027
11 60 -21.0 852 0.3634593015265577
11 61 -21.0 853 0.3655952773507846
11 62 -20.0 1099 0.3723176835720055
11 63 -20.0 906 0.363889581024252
11 64 -21.0 764 0.36637359475278103
11 65 -21.0 824 0.37892186970820707
11 66 -20.0 1048 0.3787386171121634
11 67 -21.0 888 0.35654029246788843
11 68 -21.0 973 0.34839705811987676
11 69 -21.0 884 0.35145783299639216
11 70 -20.0 921 0.34900559285952915
11 71 -21.0 764 0.35378576830731634
11 72 -19.0 1014 0.35486349578087145
11 73 -19.0 1070 0.3696649469783373
11 74 -20.0 981 0.38409757018696883
11 75 -20.0 1025 0.3950909656431617
11 76 -21.0 945 0.37457914967385547
11 77 -20.0 931 0.35764636664334226
11 78 -20.0 1085 0.36027041810998167
11 79 -21.0 1002 0.35597004454411907
11 80 -20.0 977 0.36884947095215015
11 81 -20.0 870 0.3805861226786142
11 82 -20.0 950 0.3773064155955064
11 83 -21.0 792 0.3845267192733408
11 84 -20.0 951 0.39157872762213747
11 85 -21.0 944 0.3825655343105732
11 86 -20.0 963 0.37105203139076354
11 87 -21.0 1036 0.34417920162663956
11 88 -21.0 764 0.3454678995993125
11 89 -21.0 826 0.351810067206549
11 90 -19.0 1015 0.3697810586743754
11 91 -20.0 1028 0.38264887678484044
11 92 -21.0 965 0.36947837017978413
11 93 -21.0 822 0.39093960107388
11 94 -20.0 919 0.38538200694406904
11 95 -21.0 884 0.38104384635233773
11 96 -21.0 904 0.3686214250932753
11 97 -21.0 887 0.40359318763723234
11 98 -21.0 1021 0.3911917120889632
11 99 -19.0 1210 0.3912717967979179
11 100 -21.0 824 0.4042796718625768
11 101 -21.0 884 0.4089924185726438
11 102 -21.0 1062 0.4269928181800016
11 103 -20.0 962 0.40622060716523944
11 104 -21.0 1009 0.4222607656028509
11 105 -21.0 854 0.41724928295724006
11 106 -21.0 886 0.4203884861942877
11 107 -21.0 824 0.41617770811307775
11 108 -21.0 839 0.3967945325289352
11 109 -19.0 1027 0.3759432455058688
11 110 -21.0 914 0.3914905420995646
11 111 -20.0 1158 0.4161051794346132
11 112 -21.0 824 0.377325241354484
11 113 -20.0 1009 0.37011713318238765
11 114 -21.0 882 0.41002747011022506
11 115 -21.0 826 0.3915950931229834
11 116 -20.0 902 0.3945838036201481
11 117 -20.0 982 0.368811659105198
11 118 -20.0 919 0.37199128150810223
11 119 -19.0 1042 0.3571907655405678
11 120 -21.0 826 0.35442349192016637
11 121 -19.0 1028 0.3542234317221994
11 122 -21.0 944 0.35293509748022434
11 123 -21.0 824 0.3533788535346105
11 124 -20.0 1055 0.35261665376441736
11 125 -20.0 1042 0.35842149674663615
11 126 -21.0 871 0.3685828376856518
11 127 -20.0 921 0.38606719923459487
11 128 -20.0 980 0.3835796459292879
11 129 -21.0 912 0.39055157995276285
11 130 -20.0 902 0.4298279033003255
11 131 -21.0 826 0.4074009370067795
11 132 -21.0 1156 0.3954977507358191
11 133 -21.0 1008 0.3624173344837295
11 134 -20.0 968 0.3609950008286425
11 135 -21.0 884 0.38453101464526146
11 136 -21.0 852 0.39319785894222664
11 137 -20.0 922 0.36006381852378555
11 138 -21.0 820 0.35095258202494645
11 139 -21.0 994 0.3861340607855641
11 140 -21.0 941 0.37360795771784283
11 141 -21.0 883 0.3618676102849932
11 142 -21.0 1086 0.38162707944930585
11 143 -20.0 964 0.3789545281546739
11 144 -21.0 935 0.3860826601637876
11 145 -21.0 884 0.3898573244723799
11 146 -20.0 878 0.35967773592825086
11 147 -21.0 993 0.3669967866556162
11 148 -21.0 820 0.39321862502795896
11 149 -20.0 964 0.366460818070841
11 150 -21.0 995 0.387589036160378
11 151 -21.0 1127 0.3796511551079331
11 152 -20.0 1220 0.3658632694697771
11 153 -18.0 1163 0.36063149445854376
11 154 -21.0 913 0.35363830043347744
11 155 -21.0 853 0.3594650890315683
11 156 -21.0 824 0.3658375188852977
11 157 -21.0 914 0.35914143055873055
11 158 -21.0 783 0.35973829967308774
11 159 -20.0 1079 0.3692408939331521
11 160 -17.0 1270 0.3734054000593546
11 161 -21.0 1007 0.3790841215653595
11 162 -20.0 1071 0.372097419534856
11 163 -21.0 824 0.36308551102297976
11 164 -21.0 792 0.35393803002256335
11 165 -20.0 922 0.37864791480682936
11 166 -21.0 987 0.36861648319219265
11 167 -21.0 945 0.3720471832487318
11 168 -21.0 962 0.3731591598965274
11 169 -19.0 1198 0.3699691371249038
11 170 -20.0 902 0.37912019446260914
11 171 -21.0 825 0.3769430900342537
11 172 -20.0 887 0.37345338821948715
11 173 -21.0 848 0.36944250512938454
11 174 -20.0 919 0.3748336420744106
11 175 -20.0 1250 0.3817509964466095
11 176 -21.0 1034 0.371956519768132
11 177 -21.0 1010 0.37178407349798936
11 178 -21.0 1086 0.3636053868639755
11 179 -19.0 1223 0.36509160932613416
11 180 -20.0 963 0.37206858569835455
11 181 -20.0 1209 0.389590622646144
11 182 -20.0 904 0.3738459497690201
11 183 -21.0 824 0.3637422579657106
11 184 -21.0 944 0.3722892290896783
11 185 -21.0 912 0.3689162487392886
11 186 -21.0 884 0.3575349091404703
11 187 -20.0 1101 0.3662422743036355
11 188 -19.0 1206 0.38099334755940223
11 189 -21.0 1008 0.38625597669964745
11 190 -21.0 854 0.4039672613492894
11 191 -21.0 1159 0.3895957719107143
11 192 -20.0 1022 0.3719072812865625
11 193 -19.0 1188 0.37444964753658283
11 194 -20.0 888 0.38132749652271875
11 195 -20.0 1070 0.3823014282177542
11 196 -19.0 1104 0.38063583633713965
11 197 -21.0 882 0.37359229020791257
11 198 -21.0 1159 0.3893069252050365
11 199 -21.0 1005 0.38795662240602485
11 200 -20.0 963 0.3803706734846438
11 201 -18.0 1296 0.36842808805774024
11 202 -21.0 1155 0.40186508971375307
11 203 -20.0 902 0.38262592021483277
11 204 -19.0 1185 0.4030845154689837
11 205 -21.0 824 0.3808349527201606
11 206 -20.0 1140 0.37985362136050277
11 207 -21.0 825 0.37746724020351063
11 208 -21.0 845 0.36734710057106246
11 209 -21.0 1068 0.40400140244192845
11 210 -19.0 1044 0.3824250817413074
11 211 -21.0 1036 0.4014910089866075
11 212 -19.0 1113 0.39468556805869426
11 213 -20.0 1183 0.37934419218000476
11 214 -21.0 783 0.3667104836472454
11 215 -20.0 981 0.3712623962082508
11 216 -20.0 1105 0.39153023955509136
11 217 -21.0 1035 0.4190574523907353
11 218 -19.0 1466 0.4098484424663273
11 219 -20.0 983 0.41685975107268664
11 220 -20.0 1043 0.4041883039394481
11 221 -21.0 948 0.4143525036641314
11 222 -18.0 1092 0.39220022508403757
11 223 -21.0 1070 0.41894150635349414
11 224 -20.0 1219 0.41451813254911846
11 225 -19.0 1270 0.38732256612439794 0 -21.0 764 0.4009588148191337
4 1 -21.0 946 0.38782941019182227
4 2 -21.0 940 0.4079631932555361
4 3 -20.0 1284 0.39450528356609316
4 4 -20.0 1083 0.3648136211619373
4 5 -21.0 884 0.38921851776034583
4 6 -20.0 1035 0.3834235648314158
4 7 -21.0 792 0.38958437801009477
4 8 -21.0 843 0.38807163844470594
4 9 -21.0 880 0.36311676163565026
4 10 -21.0 794 0.3596453474886171
4 11 -20.0 1019 0.36951566669611047
4 12 -20.0 919 0.36737191884639603
4 13 -21.0 1008 0.38812411446419975
4 14 -19.0 1076 0.38560708265987026
4 15 -20.0 889 0.38582853035932185
4 16 -21.0 783 0.39985678482938697
4 17 -21.0 940 0.36519480683702105
4 18 -20.0 889 0.3650927069283712
4 19 -20.0 921 0.36919938252751394
4 20 -21.0 915 0.3783645099303761
4 21 -21.0 884 0.3984444590108427
4 22 -20.0 981 0.404781705043853
4 23 -21.0 965 0.37415058742533075
4 24 -20.0 963 0.39889445622390673
4 25 -21.0 854 0.4009797122914004
4 26 -20.0 978 0.3716117626928357
4 27 -21.0 858 0.3552572142272007
4 28 -21.0 947 0.3461600493289601
4 29 -21.0 824 0.3650723786536351
4 30 -21.0 884 0.3507298790424118
4 31 -21.0 824 0.342474327829567
4 32 -21.0 824 0.34199631478167275
4 33 -21.0 764 0.34425442186013566
4 34 -21.0 824 0.3507072985967965
4 35 -21.0 914 0.3678937567402028
4 36 -21.0 934 0.3572200570869752
4 37 -21.0 764 0.36275815967645947
4 38 -21.0 882 0.36354839413209294
4 39 -21.0 946 0.37139514013022246
4 40 -21.0 764 0.37966174874162173
4 41 -21.0 824 0.37083563241131096
4 42 -21.0 1008 0.3742926739865825
4 43 -21.0 870 0.39349489667634857
4 44 -20.0 900 0.3725237193372514
4 45 -21.0 914 0.36502128506906706
4 46 -21.0 1006 0.35751656331788473
4 47 -20.0 842 0.3617953154791562
4 48 -21.0 1066 0.3650528451403355
4 49 -21.0 826 0.372746600005009
4 50 -21.0 884 0.3696975296371663
4 51 -21.0 783 0.3639978271639058
4 52 -21.0 873 0.3865087606516354
4 53 -21.0 945 0.39748999479586483
4 54 -21.0 1007 0.4219790016113232
4 55 -21.0 886 0.42934881325634555
4 56 -21.0 833 0.43439571854590225
4 57 -21.0 1033 0.4112814815150572
4 58 -21.0 1036 0.38615072541600487
4 59 -21.0 1022 0.36401967876344743
4 60 -21.0 886 0.3646833713652049
4 61 -19.0 997 0.3567746251731842
4 62 -21.0 884 0.35540460485004194
4 63 -21.0 825 0.36293151505065685
4 64 -21.0 824 0.3670609839332914
4 65 -20.0 985 0.36805284216924367
4 66 -20.0 1024 0.36675115712569095
4 67 -20.0 1175 0.3683489386578824
4 68 -21.0 885 0.3825548112729175
4 69 -17.0 1189 0.3647457125610018
4 70 -21.0 874 0.351552409390563
4 71 -20.0 998 0.34796430884238955
4 72 -20.0 919 0.3490538769305336
4 73 -20.0 965 0.3502814494575244
4 74 -21.0 820 0.3580335928536043
4 75 -21.0 824 0.37056125711324145
4 76 -21.0 884 0.3718210228495468
4 77 -21.0 853 0.3989916558072827
4 78 -20.0 1067 0.38090258892608114
4 79 -21.0 1035 0.3720062009954222
4 80 -20.0 930 0.3580541136123801
4 81 -21.0 843 0.3583595181062977
4 82 -21.0 824 0.3573413419636708
4 83 -19.0 965 0.3692304306079687
4 84 -18.0 1044 0.3820823442433529
4 85 -21.0 944 0.37899061425004976
4 86 -21.0 938 0.38758496987794255
4 87 -20.0 979 0.3855240572704358
4 88 -21.0 854 0.3738381993854353
4 89 -21.0 845 0.36517380976818015
4 90 -21.0 885 0.34364589671630646
4 91 -21.0 1000 0.34664762941002847
4 92 -20.0 1045 0.3588621965435703
4 93 -21.0 885 0.3787335670600503
4 94 -21.0 826 0.37471536119394094
4 95 -20.0 931 0.3736656625083899
4 96 -21.0 852 0.38837112843150823
4 97 -20.0 899 0.38442549268581444
4 98 -21.0 944 0.38172734247804696
4 99 -21.0 824 0.38053510370619087
4 100 -21.0 1000 0.3985850595235825
4 101 -20.0 920 0.38783727353033814
4 102 -21.0 855 0.3919579497554846
4 103 -20.0 888 0.411779228128023
4 104 -21.0 824 0.40976187395094665
4 105 -21.0 824 0.42652834510629617
4 106 -20.0 1008 0.41011353996064925
4 107 -21.0 884 0.42092787508106877
4 108 -21.0 1007 0.4140232689863639
4 109 -20.0 963 0.41765230355604416
4 110 -21.0 912 0.42364281190461234
4 111 -21.0 948 0.39591641425457685
4 112 -21.0 1034 0.3738494995311335
4 113 -21.0 854 0.3825262509268955
4 114 -21.0 945 0.4181050767974248
4 115 -21.0 852 0.4040735967702149
4 116 -21.0 1004 0.37094559615470496
4 117 -20.0 842 0.39290405275419604
4 118 -20.0 902 0.4030543166623676
4 119 -21.0 945 0.3935459230627332
4 120 -21.0 794 0.37744820410718843
4 121 -20.0 921 0.3689480830999203
4 122 -19.0 1198 0.364335845751635
4 123 -20.0 844 0.36086151815986184
4 124 -21.0 812 0.3474653169439344
4 125 -21.0 792 0.3575105866548991
4 126 -21.0 764 0.3500573029302802
4 127 -21.0 853 0.35276279311107445
4 128 -21.0 852 0.35719062758723336
4 129 -20.0 1069 0.35811431397892135
4 130 -20.0 922 0.3661889678873364
4 131 -20.0 842 0.3869155674394123
4 132 -21.0 910 0.3854831569142394
4 133 -21.0 1059 0.3877896876465723
4 134 -21.0 824 0.4429900991251168
4 135 -21.0 1089 0.4106349787983575
4 136 -21.0 948 0.39555324441144235
4 137 -19.0 1025 0.35365037042920183
4 138 -21.0 824 0.3614921257695527
4 139 -20.0 1024 0.37384736991953105
4 140 -21.0 946 0.38894171061399874
4 141 -21.0 886 0.35985185619670707
4 142 -20.0 919 0.3648530118029577
4 143 -20.0 879 0.38236024043394573
4 144 -21.0 944 0.3750533469147601
4 145 -20.0 1054 0.36601558240020976
4 146 -21.0 826 0.3875919768798727
4 147 -21.0 792 0.3744360415848217
4 148 -20.0 1023 0.38205483200379947
4 149 -20.0 870 0.38835248854653587
4 150 -21.0 824 0.359398293770054
4 151 -21.0 886 0.3649780965887397
4 152 -20.0 1025 0.3735631938096954
4 153 -21.0 1036 0.36918094219158054
4 154 -20.0 983 0.3832863015961186
4 155 -21.0 1009 0.37561632227614095
4 156 -19.0 1070 0.3506154874774897
4 157 -21.0 873 0.36467645869495396
4 158 -21.0 885 0.3748671250828242
4 159 -21.0 992 0.35774982363105784
4 160 -21.0 856 0.3580274147756189
4 161 -20.0 1051 0.3657974490770037
4 162 -21.0 884 0.37820165607724254
4 163 -20.0 1106 0.3671644068378652
4 164 -18.0 1241 0.37178778629164655
4 165 -18.0 1078 0.3804357768432108
4 166 -19.0 994 0.36831622965019234
4 167 -21.0 1006 0.3750104808487428
4 168 -20.0 1050 0.3688678017968223
4 169 -21.0 845 0.3830494491658973
4 170 -21.0 1033 0.36349789133261157
4 171 -21.0 884 0.37165720976585714
4 172 -19.0 1000 0.3643269440829754
4 173 -21.0 1048 0.38206454582569255
4 174 -20.0 948 0.3792716054410874
4 175 -20.0 991 0.37783977395350227
4 176 -20.0 1067 0.38350600113126865
4 177 -20.0 1041 0.3701071557119188
4 178 -21.0 884 0.3684789479385674
4 179 -18.0 1061 0.369110989638031
4 180 -20.0 991 0.3742794741535283
4 181 -18.0 1337 0.3620907656274452
4 182 -20.0 930 0.364625388864548
4 183 -21.0 1193 0.37981532585291133
4 184 -19.0 1027 0.37899533062157637
4 185 -20.0 1101 0.37334615395461074
4 186 -20.0 922 0.370407407978093
4 187 -21.0 824 0.3905453792619474
4 188 -18.0 1103 0.36632764185436834
4 189 -20.0 1072 0.3605416084069814
4 190 -21.0 1080 0.37518461881964293
4 191 -21.0 886 0.37433223776166114
4 192 -21.0 884 0.38839285433022686
4 193 -21.0 886 0.4040419782930249
4 194 -19.0 1136 0.3882580298248311
4 195 -20.0 1004 0.36876824872189784
4 196 -20.0 931 0.36574908700460523
4 197 -18.0 1111 0.3819489568391434
4 198 -20.0 1045 0.38716165854029677
4 199 -20.0 948 0.3797886831850945
4 200 -19.0 1057 0.3792456209152063
4 201 -21.0 931 0.3836004815027358
4 202 -21.0 824 0.3784301723308355
4 203 -21.0 933 0.37193573351713877
4 204 -21.0 764 0.37853961519857976
4 205 -21.0 944 0.36421623475597065
4 206 -21.0 888 0.3781500730227243
4 207 -20.0 1408 0.3941610959485512
4 208 -20.0 1054 0.39597773998693
4 209 -20.0 1134 0.3914079468243967
4 210 -18.0 1348 0.38301388649629203
4 211 -21.0 899 0.3726006034881838
4 212 -21.0 824 0.3650145598334595
4 213 -21.0 946 0.3852089016243469
4 214 -18.0 1120 0.3997074477640646
4 215 -20.0 1323 0.4096416541102792
4 216 -19.0 1250 0.3788228995323181
4 217 -20.0 1009 0.3682163123214918
4 218 -21.0 948 0.3894286655549762
4 219 -21.0 993 0.3929053359821604
4 220 -20.0 982 0.39084404263865435
4 221 -21.0 1038 0.3961992022906195
4 222 -21.0 948 0.408178742927841
4 223 -20.0 1104 0.42275172301932523
4 224 -20.0 1372 0.42424499836503243
4 225 -21.0 977 0.3930124305226786
4 226 -21.0 1070 0.42853062540014214
4 227 -19.0 1124 0.4092966052720131
4 228 -19.0 1042 0.4016602137152842
4 229 -21.0 967 0.3930784033952356
4 230 -17.0 1492 0.4010750658150972
4 231 -20.0 1193 0.3916012083944511
4 232 -20.0 878 10 0 -21.0 764 0.3978602991132212
10 1 -21.0 974 0.3777582181858576
10 2 -21.0 892 0.406788901162789
10 3 -20.0 1070 0.3941892290226767
10 4 -20.0 919 0.36018466375468217
10 5 -20.0 919 0.37786530699252563
10 6 -21.0 824 0.39612913334253924
10 7 -21.0 899 0.3875440776149211
10 8 -21.0 824 0.40003748342973516
10 9 -20.0 1154 0.364472975841428
10 10 -21.0 783 0.35559376450029523
10 11 -20.0 1150 0.37108164103134816
10 12 -21.0 1002 0.3688696474134327
10 13 -21.0 783 0.3931178813693167
10 14 -19.0 1043 0.3862380632560982
10 15 -21.0 931 0.39005266915842746
10 16 -21.0 853 0.3924761581882083
10 17 -19.0 982 0.3673480234418042
10 18 -21.0 884 0.3684133780757766
10 19 -20.0 1082 0.3687972930464859
10 20 -18.0 1033 0.3860810659573362
10 21 -20.0 902 0.41761922459644646
10 22 -21.0 764 0.3795203255655254
10 23 -20.0 900 0.3766938155889511
10 24 -21.0 783 0.40077081509172385
10 25 -20.0 947 0.39860974858026194
10 26 -21.0 945 0.36334032542491085
10 27 -19.0 1101 0.34967741443285827
10 28 -21.0 946 0.3556516847827218
10 29 -21.0 887 0.35986304273062386
10 30 -21.0 764 0.3435319165518771
10 31 -21.0 852 0.34440899832707617
10 32 -21.0 764 0.34306827507406007
10 33 -21.0 764 0.3481956034586692
10 34 -19.0 1039 0.3604666757916349
10 35 -17.0 1328 0.35776907575866546
10 36 -19.0 1015 0.3638565826004949
10 37 -19.0 1106 0.3659200363575227
10 38 -21.0 764 0.38278659078151145
10 39 -21.0 884 0.37019370324336565
10 40 -21.0 1308 0.37781592898230304
10 41 -21.0 933 0.38505954946224585
10 42 -20.0 900 0.36870327171352174
10 43 -20.0 1024 0.35772281148820184
10 44 -21.0 888 0.3609811561937268
10 45 -21.0 854 0.3637544686188463
10 46 -20.0 1012 0.3704689362126848
10 47 -20.0 1122 0.37005845782697305
10 48 -20.0 1045 0.3649468294741434
10 49 -21.0 1157 0.38749257327671593
10 50 -21.0 1062 0.40990591520643505
10 51 -21.0 783 0.4184654836529821
10 52 -20.0 902 0.43885723037228086
10 53 -20.0 1202 0.4193496918321251
10 54 -20.0 1054 0.39388270218073757
10 55 -21.0 916 0.3665529859443419
10 56 -21.0 852 0.36641135874768377
10 57 -19.0 983 0.36014865112935296
10 58 -21.0 826 0.3626365537144081
10 59 -21.0 853 0.3581731590548266
10 60 -20.0 878 0.3672364060862461
10 61 -21.0 792 0.3610168658196926
10 62 -21.0 881 0.37227472141977064
10 63 -21.0 1022 0.36454443242801843
10 64 -21.0 974 0.3742260690893236
10 65 -20.0 1011 0.38359231747222583
10 66 -20.0 1078 0.3585472398874711
10 67 -21.0 820 0.3543393143793432
10 68 -20.0 919 0.3511201867730366
10 69 -20.0 991 0.3485945441227267
10 70 -20.0 1007 0.35556527152435546
10 71 -21.0 945 0.3524064064025879
10 72 -20.0 1043 0.37187643379173024
10 73 -19.0 1097 0.39658109546251047
10 74 -21.0 977 0.3778242413926881
10 75 -20.0 966 0.37299457371358297
10 76 -21.0 824 0.35451388369920184
10 77 -20.0 1171 0.35946167955838343
10 78 -21.0 1006 0.36089623818696137
10 79 -21.0 946 0.3764144110377193
10 80 -21.0 873 0.38039573665200505
10 81 -21.0 825 0.3800091817162254
10 82 -21.0 884 0.38622568436472665
10 83 -21.0 948 0.3897019609305929
10 84 -21.0 792 0.3718857577051779
10 85 -21.0 824 0.36765023418566556
10 86 -21.0 944 0.3422674347914882
10 87 -21.0 1034 0.34813964205507614
10 88 -21.0 839 0.3588355168327245
10 89 -19.0 1102 0.37776531311539685
10 90 -21.0 882 0.3706077208189197
10 91 -21.0 976 0.37825662722108794
10 92 -20.0 921 0.386798070418071
10 93 -20.0 1038 0.3829681458156233
10 94 -21.0 880 0.37073204730722037
10 95 -21.0 944 0.3984299203286232
10 96 -19.0 1042 0.3920151288701568
10 97 -20.0 1052 0.38579964773736525
10 98 -20.0 921 0.4061066297961886
10 99 -21.0 904 0.40587231009143643
10 100 -21.0 824 0.4264130796332961
10 101 -20.0 1025 0.4070567267115523
10 102 -21.0 944 0.4214761289373293
10 103 -20.0 842 0.4131714264528202
10 104 -21.0 974 0.42146369199855616
10 105 -20.0 842 0.43164476699189164
10 106 -21.0 826 0.4031450942555582
10 107 -20.0 1008 0.37502291423106004
10 108 -21.0 884 0.3793267843680144
10 109 -20.0 1295 0.4140081579160506
10 110 -20.0 947 0.38767360854174043
10 111 -21.0 942 0.36581172526768563
10 112 -21.0 792 0.4037170491811603
10 113 -20.0 1040 0.3982427578132886
10 114 -21.0 884 0.3981009505655431
10 115 -20.0 962 0.3726743312858494
10 116 -21.0 885 0.3689525272886632
10 117 -20.0 1043 0.3567227058305493
10 118 -21.0 856 0.35323297054828884
10 119 -21.0 1033 0.35445790888609985
10 120 -21.0 822 0.35030423916894443
10 121 -20.0 936 0.3552292615939409
10 122 -19.0 1086 0.3542206452586594
10 123 -21.0 853 0.36476941859177103
10 124 -20.0 1058 0.3670606119646242
10 125 -21.0 886 0.38800147872073387
10 126 -20.0 842 0.3770517531667356
10 127 -21.0 944 0.388253400260109
10 128 -21.0 811 0.4327724271726079
10 129 -21.0 914 0.41037640679847753
10 130 -20.0 903 0.39609538053357324
10 131 -21.0 864 0.3587351420687305
10 132 -21.0 905 0.37051776048228224
10 133 -20.0 958 0.3630160308581056
10 134 -20.0 921 0.38314713600792405
10 135 -21.0 824 0.3691413971116242
10 136 -21.0 914 0.35802033194697397
10 137 -21.0 1092 0.39046303376610025
10 138 -21.0 892 0.37234858219666334
10 139 -20.0 1268 0.3652359112063041
10 140 -19.0 1027 0.38017430451735784
10 141 -20.0 982 0.38009454136953336
10 142 -19.0 1068 0.38818827131937506
10 143 -20.0 958 0.37204271953140766
10 144 -21.0 967 0.3700352930295307
10 145 -21.0 853 0.3741563976439893
10 146 -20.0 1041 0.3665915025070696
10 147 -21.0 966 0.37639546597966494
10 148 -21.0 912 0.3928057663142681
10 149 -20.0 1021 0.36441229349485693
10 150 -21.0 944 0.36307347954203517
10 151 -20.0 1052 0.35997961911978377
10 152 -21.0 963 0.3553519550080364
10 153 -19.0 1134 0.3581742354170986
10 154 -20.0 1044 0.37189659795998614
10 155 -21.0 843 0.3615928082986517
10 156 -20.0 843 0.37136550316606975
10 157 -21.0 822 0.3685677204181388
10 158 -21.0 884 0.37815745977255016
10 159 -21.0 1098 0.3782391389373873
10 160 -21.0 913 0.3643069932194425
10 161 -21.0 853 0.35806133008506347
10 162 -21.0 826 0.37855826044053775
10 163 -21.0 880 0.380767814273184
10 164 -21.0 1038 0.36877298699638056
10 165 -21.0 783 0.37228161442934476
10 166 -21.0 852 0.3691164529379545
10 167 -21.0 1005 0.3787107483961096
10 168 -21.0 1029 0.38339262937201934
10 169 -20.0 920 0.3780521003772383
10 170 -20.0 981 0.36888715898225066
10 171 -19.0 980 0.3784135421623989
10 172 -16.0 1491 0.37400105071899314
10 173 -21.0 1110 0.37047374562637225
10 174 -20.0 1116 0.3660337220757238
10 175 -21.0 854 0.361031492190562
10 176 -21.0 903 0.3556773921976058
10 177 -21.0 1004 0.3737674303263782
10 178 -21.0 867 0.39806368991715413
10 179 -21.0 971 0.37499658636035194
10 180 -21.0 903 0.38733332137992876
10 181 -20.0 1180 0.37992527944556737
10 182 -20.0 942 0.3679412905514367
10 183 -21.0 1103 0.3651606343274536
10 184 -19.0 1096 0.36994418610621543
10 185 -21.0 783 0.38012838626273293
10 186 -20.0 966 0.37358865036974287
10 187 -21.0 947 0.40559690935810616
10 188 -21.0 886 0.39113687554008536
10 189 -18.0 1110 0.3721524096555538
10 190 -19.0 1023 0.36529257777033197
10 191 -21.0 953 0.3750217712688546
10 192 -20.0 1174 0.3888718509186675
10 193 -19.0 1076 0.38432005889796855
10 194 -19.0 1240 0.3859278448647068
10 195 -20.0 1098 0.3879592296529989
10 196 -21.0 974 0.3842911983111556
10 197 -21.0 886 0.37466850163705195
10 198 -21.0 997 0.36953337638524014
10 199 -20.0 1089 0.3899503235317787
10 200 -21.0 1006 0.3945141715510465
10 201 -20.0 1003 0.3908736554242797
10 202 -19.0 1119 0.39853070821476577
10 203 -21.0 915 0.37160853932464055
10 204 -21.0 1206 0.3935461038874947
10 205 -21.0 824 0.36778540851421726
10 206 -18.0 1494 0.39478152377937376
10 207 -21.0 1115 0.4027382967183408
10 208 -20.0 1167 0.39597875040723607
10 209 -19.0 1130 0.37869097521874756
10 210 -20.0 1070 0.38740321052408666
10 211 -20.0 1071 0.38307671467351867
10 212 -17.0 1218 0.3832550255829478
10 213 -19.0 1035 0.40024213030718375
10 214 -20.0 878 0.38856121025351564
10 215 -20.0 1043 0.4215330581537029
10 216 -20.0 1099 0.3995893159923605
10 217 -20.0 1131 0.4109231134255727
10 218 -21.0 903 0.3875222491927585
10 219 -18.0 1294 0.4068413568657738
10 220 -21.0 1089 0.4013670541968665
10 221 -20.0 1028 0.4015413724494815
10 222 -21.0 1113 0.39816263561728615
10 223 -21.0 946 0.3864785268997289
10 224 -17.0 1201 0.3860496562486088
10 225 -18.012 0 -21.0 783 0.39500873375060763
12 1 -21.0 824 0.375783686173483
12 2 -21.0 824 0.41061887720111506
12 3 -20.0 919 0.41125664786233995
12 4 -21.0 884 0.3563323030374708
12 5 -20.0 902 0.37508768969919626
12 6 -19.0 1205 0.392222411924378
12 7 -21.0 871 0.3863686566443175
12 8 -21.0 824 0.38648487421349415
12 9 -21.0 852 0.36062376858762735
12 10 -20.0 1040 0.36025608382545987
12 11 -21.0 854 0.3734060487507099
12 12 -21.0 932 0.3726142209998528
12 13 -20.0 938 0.38507758208048115
12 14 -21.0 794 0.3902582107698287
12 15 -20.0 843 0.38450618097083566
12 16 -18.0 1049 0.39760625288529666
12 17 -19.0 1041 0.35347275474573076
12 18 -20.0 1130 0.3710853330856931
12 19 -17.0 1131 0.3734081658138626
12 20 -20.0 878 0.3977822258491451
12 21 -19.0 1014 0.40072147703970207
12 22 -21.0 885 0.3737489547096403
12 23 -21.0 944 0.39809503750402037
12 24 -21.0 852 0.40005932013753437
12 25 -21.0 843 0.36476414964433806
12 26 -20.0 923 0.350915258360839
12 27 -21.0 794 0.3468090174555478
12 28 -21.0 824 0.36834667966637796
12 29 -21.0 972 0.3467146412396627
12 30 -20.0 871 0.3426902388595686
12 31 -20.0 990 0.34326362655018317
12 32 -20.0 982 0.3512247686412815
12 33 -21.0 886 0.366476951818703
12 34 -21.0 764 0.35751177756730174
12 35 -21.0 764 0.36484463345161905
12 36 -20.0 999 0.3633341995087472
12 37 -21.0 973 0.3781500549073822
12 38 -19.0 1034 0.37054410360652656
12 39 -20.0 903 0.3705960943519343
12 40 -21.0 974 0.39565052933516687
12 41 -21.0 914 0.3732889546998481
12 42 -20.0 1264 0.36064782979179033
12 43 -20.0 904 0.36005015127294887
12 44 -21.0 825 0.3641621101986278
12 45 -19.0 1017 0.3678145785774805
12 46 -18.0 1270 0.37055885780045367
12 47 -19.0 1180 0.3698630835545265
12 48 -20.0 1020 0.3911219516805574
12 49 -20.0 981 0.4162885355596999
12 50 -21.0 944 0.42301313815859415
12 51 -21.0 886 0.44211154378967416
12 52 -21.0 794 0.42085232835272396
12 53 -21.0 822 0.39755674112597233
12 54 -21.0 792 0.3684506870128892
12 55 -20.0 1043 0.3650224811735912
12 56 -19.0 1017 0.35985638407830994
12 57 -21.0 944 0.35914078228554486
12 58 -21.0 824 0.3584073083203973
12 59 -20.0 902 0.36919879209572354
12 60 -20.0 964 0.36632023068508174
12 61 -21.0 912 0.36824787679340754
12 62 -20.0 890 0.36533149855860164
12 63 -21.0 884 0.37978484842302573
12 64 -21.0 945 0.38131544211554147
12 65 -20.0 1058 0.3523402171234102
12 66 -20.0 923 0.3478188714575535
12 67 -19.0 1141 0.3533571945482132
12 68 -21.0 888 0.347679906902281
12 69 -21.0 1003 0.35818462473445256
12 70 -20.0 1017 0.36849467246816103
12 71 -20.0 979 0.3832812843819561
12 72 -21.0 974 0.3954666159909364
12 73 -20.0 1132 0.37108858253530397
12 74 -20.0 931 0.35448500305958386
12 75 -19.0 1072 0.36125723684012
12 76 -21.0 981 0.3588857813894931
12 77 -21.0 884 0.3789773776924988
12 78 -21.0 792 0.3839486419703021
12 79 -21.0 845 0.38097952847650063
12 80 -20.0 979 0.3864085212182463
12 81 -21.0 854 0.39247731644599165
12 82 -19.0 1000 0.3725570599734783
12 83 -21.0 1033 0.3554364113932311
12 84 -20.0 963 0.3442055478088581
12 85 -19.0 1137 0.3530297971600069
12 86 -21.0 946 0.37371171188656926
12 87 -21.0 974 0.38071078582221235
12 88 -21.0 820 0.3664000559143904
12 89 -20.0 1041 0.38462744322565173
12 90 -20.0 1008 0.3840684901390757
12 91 -20.0 979 0.37545197495888155
12 92 -20.0 1102 0.3852169390382438
12 93 -21.0 997 0.3969134491389111
12 94 -20.0 931 0.380714769778267
12 95 -21.0 886 0.3988588196698484
12 96 -21.0 1065 0.41274303379752825
12 97 -21.0 887 0.4137267435752821
12 98 -20.0 991 0.4187179463422142
12 99 -20.0 919 0.41080630740092033
12 100 -19.0 1121 0.41704752124068356
12 101 -21.0 905 0.4175703238387134
12 102 -21.0 824 0.4297241723725518
12 103 -21.0 825 0.4047977571776419
12 104 -20.0 963 0.38350349769909187
12 105 -20.0 983 0.3777236299378947
12 106 -21.0 794 0.40278010486955906
12 107 -21.0 783 0.4176784408199072
12 108 -21.0 1054 0.3863013728293794
12 109 -21.0 852 0.36993517062053993
12 110 -20.0 995 0.41441118522505066
12 111 -21.0 825 0.39379990743868276
12 112 -21.0 852 0.39639438905626395
12 113 -21.0 783 0.37184316091153813
12 114 -21.0 974 0.36925692091365125
12 115 -21.0 1055 0.35904080932739224
12 116 -19.0 965 0.353651270656388
12 117 -21.0 913 0.3509489271753067
12 118 -21.0 944 0.35338560595982155
12 119 -20.0 981 0.3540727668702906
12 120 -21.0 948 0.3538076046712791
12 121 -21.0 826 0.36775915050477725
12 122 -20.0 921 0.3677994105054812
12 123 -20.0 995 0.38272141397897924
12 124 -20.0 842 0.38102627377470427
12 125 -20.0 931 0.37857677159324754
12 126 -21.0 824 0.42697580198495133
12 127 -20.0 887 0.40888970737527164
12 128 -21.0 824 0.4080280077833574
12 129 -20.0 902 0.37305648053300355
12 130 -21.0 945 0.3669338014706102
12 131 -20.0 1041 0.35787226361339763
12 132 -20.0 1161 0.3863904686655904
12 133 -21.0 886 0.36814967712753244
12 134 -20.0 899 0.3530453119978093
12 135 -18.0 1172 0.3798340946537643
12 136 -21.0 824 0.37242767945366
12 137 -21.0 886 0.3629800561588451
12 138 -21.0 1004 0.38267770608464086
12 139 -20.0 982 0.379163122134636
12 140 -21.0 824 0.38536797087748076
12 141 -20.0 1072 0.386249231786203
12 142 -21.0 922 0.36843916518439956
12 143 -20.0 1041 0.36425101891603756
12 144 -20.0 842 0.37959413616221194
12 145 -20.0 1028 0.3591487724551431
12 146 -21.0 843 0.3813586261207381
12 147 -20.0 1066 0.3746512737160105
12 148 -20.0 932 0.3551404077096047
12 149 -21.0 826 0.3678810164945755
12 150 -20.0 889 0.36008480073898796
12 151 -21.0 764 0.35757384960251953
12 152 -20.0 905 0.36255851378098375
12 153 -18.0 1218 0.3578823189478985
12 154 -21.0 944 0.3686161369590436
12 155 -20.0 905 0.36896638201745174
12 156 -21.0 880 0.3637472250244834
12 157 -20.0 1172 0.378019600191214
12 158 -21.0 764 0.3797701376036824
12 159 -20.0 981 0.3672562256744027
12 160 -21.0 845 0.3616300916530677
12 161 -20.0 1083 0.36815178432843254
12 162 -21.0 1007 0.38874626766368675
12 163 -20.0 1109 0.3675079702309814
12 164 -21.0 946 0.36702284487811004
12 165 -19.0 1103 0.37300810325934686
12 166 -20.0 964 0.3799523452134548
12 167 -19.0 1016 0.37929088396467564
12 168 -20.0 992 0.37462491385879054
12 169 -21.0 852 0.3738325734583425
12 170 -21.0 826 0.3771182026254063
12 171 -19.0 1090 0.3639146539049411
12 172 -21.0 1158 0.37596519311989735
12 173 -20.0 992 0.3666243873716843
12 174 -21.0 854 0.3691007167589469
12 175 -21.0 783 0.3550010043770874
12 176 -20.0 1250 0.3624464961051941
12 177 -21.0 824 0.3805967652898969
12 178 -20.0 1085 0.3748670471428726
12 179 -21.0 1124 0.3788840440350495
12 180 -21.0 1060 0.3685277796860011
12 181 -20.0 1263 0.36894488879733867
12 182 -19.0 1118 0.3632547944410969
12 183 -20.0 860 0.3732982682627301
12 184 -20.0 1201 0.37895928011845786
12 185 -19.0 1128 0.3988275615141747
12 186 -21.0 914 0.39649250157813276
12 187 -21.0 941 0.38209514074447176
12 188 -20.0 949 0.3675015874921459
12 189 -20.0 965 0.3672948276131882
12 190 -21.0 978 0.38567444420055863
12 191 -19.0 1340 0.3864679363458904
12 192 -20.0 963 0.37718461053146135
12 193 -21.0 845 0.3735497082126211
12 194 -21.0 882 0.37874800845338646
12 195 -20.0 1103 0.3752122921286554
12 196 -21.0 825 0.3845550440296982
12 197 -21.0 792 0.37316978256208727
12 198 -20.0 950 0.3788729087302559
12 199 -20.0 986 0.3921556797097711
12 200 -21.0 914 0.40115839174461576
12 201 -21.0 948 0.3921466208837203
12 202 -21.0 905 0.39939647037021364
12 203 -20.0 1051 0.37362273279878777
12 204 -20.0 951 0.37744175836240207
12 205 -19.0 1077 0.3718885463094313
12 206 -20.0 920 0.37522417196761004
12 207 -21.0 946 0.38018547209574355
12 208 -19.0 1057 0.3855342124584382
12 209 -19.0 1092 0.3809772551660136
12 210 -21.0 852 0.3701189428637845
12 211 -20.0 1095 0.376882737140133
12 212 -20.0 1010 0.3808265000876814
12 213 -18.0 1390 0.3899249730135897
12 214 -18.0 1242 0.3966812899339218
12 215 -21.0 1096 0.42060662811472466
12 216 -19.0 1242 0.4213935903928898
12 217 -19.0 1303 0.41627770122526614
12 218 -19.0 1329 0.42614796197082516
12 219 -21.0 992 0.4095067668766264
12 220 -20.0 1167 0.41409971107247556
12 221 -18.0 1256 0.39097885889517275
12 222 -19.0 1193 0.38588543517291796
12 223 -18.0 1280 0.39037784829270095
12 224 -18.0 1159 0.39946015936429385
12 225 -20.0 1088 0.403342063319595431 0 -21.0 972 0.3981556592838754
1 1 -21.0 764 0.38319407625816254
1 2 -21.0 944 0.39857025930689555
1 3 -19.0 1019 0.4223111450555163
1 4 -21.0 944 0.355541703622725
1 5 -19.0 975 0.3774577315342732
1 6 -21.0 905 0.39079788221838724
1 7 -21.0 884 0.3795471993776468
1 8 -20.0 1009 0.4055195914210366
1 9 -21.0 946 0.36801980360239805
1 10 -21.0 1004 0.35532174621563983
1 11 -20.0 905 0.3743957148401777
1 12 -20.0 921 0.37216900685452226
1 13 -21.0 826 0.3755745768330576
1 14 -21.0 945 0.3939223713029629
1 15 -21.0 824 0.3818622996795525
1 16 -21.0 972 0.3947773169833446
1 17 -21.0 825 0.3905860970598279
1 18 -20.0 1101 0.35606305562399604
1 19 -21.0 887 0.37064355853714026
1 20 -21.0 764 0.3663071980261054
1 21 -21.0 852 0.38681819485806523
1 22 -20.0 950 0.40455807234111585
1 23 -21.0 792 0.39954299099668106
1 24 -19.0 1251 0.37205127601047977
1 25 -21.0 974 0.3991882814212991
1 26 -20.0 983 0.3942883181729613
1 27 -21.0 975 0.35479814712817853
1 28 -20.0 968 0.3485762680118734
1 29 -16.0 1288 0.356165291105183
1 30 -21.0 764 0.35349148968283417
1 31 -21.0 912 0.3433992229402065
1 32 -19.0 1041 0.3419578933406632
1 33 -21.0 1054 0.34762204083591075
1 34 -20.0 979 0.35995209101393466
1 35 -21.0 843 0.36078047851367917
1 36 -20.0 981 0.35931156847576606
1 37 -20.0 1041 0.365062837584676
1 38 -21.0 973 0.37008810377194484
1 39 -21.0 813 0.37917906757063824
1 40 -21.0 872 0.3697924309435788
1 41 -21.0 1008 0.37452037528985077
1 42 -20.0 1098 0.3912958421070936
1 43 -21.0 1097 0.36853280087547513
1 44 -21.0 915 0.35813849861504604
1 45 -20.0 951 0.35931242135922364
1 46 -19.0 1208 0.36119898687431357
1 47 -21.0 856 0.3760987127843861
1 48 -20.0 1005 0.36850928655311244
1 49 -21.0 884 0.3656706426680358
1 50 -21.0 884 0.3830585783153638
1 51 -21.0 993 0.39364937842192366
1 52 -20.0 931 0.41894222714335017
1 53 -21.0 972 0.4246000986346983
1 54 -20.0 1146 0.43954576809368834
1 55 -21.0 824 0.4104783427585097
1 56 -21.0 871 0.3921184667079238
1 57 -21.0 1065 0.3661386213671993
1 58 -18.0 1132 0.3658766704924115
1 59 -19.0 1085 0.35724704930309875
1 60 -21.0 882 0.3554708100432982
1 61 -21.0 764 0.3630214118988726
1 62 -21.0 886 0.36715604919881367
1 63 -21.0 794 0.3710030446424893
1 64 -21.0 914 0.3645354753902235
1 65 -20.0 951 0.3659923201041016
1 66 -21.0 905 0.3767693268989331
1 67 -20.0 938 0.3832443100430055
1 68 -21.0 885 0.35966524515448317
1 69 -20.0 1172 0.3475389936017095
1 70 -21.0 884 0.35277873345090255
1 71 -21.0 914 0.3480443517214882
1 72 -21.0 912 0.3547969501661627
1 73 -20.0 903 0.35425086103272463
1 74 -18.0 1226 0.3687041272784524
1 75 -21.0 1114 0.3955441893645206
1 76 -21.0 853 0.38268972700953063
1 77 -21.0 824 0.37382069917269123
1 78 -21.0 916 0.36149749263925846
1 79 -21.0 825 0.36297728274807783
1 80 -21.0 792 0.3555463001583562
1 81 -20.0 930 0.36006924449115674
1 82 -21.0 946 0.38061729045171316
1 83 -21.0 824 0.38255787506988903
1 84 -21.0 991 0.3810046678174035
1 85 -19.0 1089 0.3890080299806551
1 86 -21.0 1009 0.3860148070352401
1 87 -21.0 826 0.37247247319244586
1 88 -20.0 1022 0.35670670759071343
1 89 -21.0 961 0.34460566542523213
1 90 -21.0 972 0.3530554504674158
1 91 -21.0 822 0.36207597487019216
1 92 -20.0 860 0.3806571044201075
1 93 -20.0 1030 0.3710687166278802
1 94 -21.0 887 0.3789366699058012
1 95 -21.0 792 0.3884206396160704
1 96 -20.0 1112 0.3818706676310344
1 97 -21.0 1036 0.373964632483753
1 98 -20.0 963 0.3965283834674277
1 99 -20.0 1277 0.38966716017308606
1 100 -20.0 1008 0.3889486414513418
1 101 -20.0 920 0.40863899015214133
1 102 -19.0 995 0.408452706091368
1 103 -20.0 842 0.43208932869507977
1 104 -19.0 998 0.40374580285472716
1 105 -21.0 947 0.4258825558669464
1 106 -21.0 1073 0.4150057394762297
1 107 -19.0 982 0.4217861370314406
1 108 -20.0 1054 0.41670759768707705
1 109 -21.0 932 0.38339865006218654
1 110 -20.0 871 0.3722634706239886
1 111 -20.0 932 0.40045637675748874
1 112 -21.0 884 0.41846913844347
1 113 -21.0 792 0.3847364439356207
1 114 -19.0 938 0.36530464506352633
1 115 -19.0 955 0.40370312548432674
1 116 -21.0 824 0.40188773272974976
1 117 -21.0 872 0.3941649042001558
1 118 -21.0 974 0.37375413643261246
1 119 -20.0 1069 0.3695493677824429
1 120 -21.0 1040 0.3610186164482282
1 121 -21.0 844 0.3547419888007132
1 122 -21.0 1056 0.3510487519035285
1 123 -21.0 871 0.3503167564573299
1 124 -19.0 1008 0.3554452860520946
1 125 -21.0 945 0.354685352372114
1 126 -21.0 885 0.36488183659348783
1 127 -21.0 993 0.3693641056527064
1 128 -20.0 878 0.3801768635291445
1 129 -21.0 1008 0.3872259168161286
1 130 -21.0 975 0.38404438639298466
1 131 -19.0 1059 0.4263008791000017
1 132 -20.0 981 0.40810026664374194
1 133 -19.0 1113 0.38930241561428663
1 134 -21.0 885 0.3547145743828035
1 135 -20.0 1230 0.36659054741626834
1 136 -21.0 952 0.39166298136115074
1 137 -20.0 1211 0.37820287219853954
1 138 -21.0 1094 0.360745132241868
1 139 -20.0 1011 0.3805679082280922
1 140 -21.0 783 0.37160039507566284
1 141 -21.0 825 0.36250135772155995
1 142 -19.0 937 0.37211820037922205
1 143 -21.0 826 0.37985213111734273
1 144 -21.0 1082 0.38951107586928524
1 145 -21.0 783 0.3881531087146408
1 146 -20.0 968 0.37488590051566273
1 147 -19.0 1158 0.3677112480982598
1 148 -21.0 887 0.37509539763715116
1 149 -21.0 908 0.36153327663827045
1 150 -20.0 1083 0.38076914196089257
1 151 -21.0 824 0.3801554071816426
1 152 -20.0 870 0.3639087082325727
1 153 -21.0 884 0.3540784637043379
1 154 -20.0 1007 0.37117155033876786
1 155 -20.0 1112 0.3525955523196742
1 156 -21.0 1193 0.3628843794424596
1 157 -20.0 976 0.35752198426816306
1 158 -21.0 852 0.36840839124341523
1 159 -20.0 949 0.3649008248641192
1 160 -20.0 979 0.36580184363856133
1 161 -21.0 826 0.3788470205902765
1 162 -21.0 783 0.3756071374029644
1 163 -20.0 1062 0.3743201045498336
1 164 -21.0 974 0.37368080818555194
1 165 -19.0 1141 0.36848275565871225
1 166 -20.0 889 0.3854303797466012
1 167 -20.0 1101 0.36066631716993264
1 168 -21.0 825 0.37445445216063294
1 169 -19.0 1122 0.36587587875478406
1 170 -21.0 886 0.3742853521829803
1 171 -21.0 811 0.37999940954801037
1 172 -21.0 1051 0.37672470182492324
1 173 -21.0 908 0.3673041250212077
1 174 -20.0 1043 0.3815451807852331
1 175 -20.0 1070 0.3815152108112228
1 176 -20.0 1022 0.37040168239412474
1 177 -20.0 842 0.3631653658638657
1 178 -19.0 1162 0.36773872878178054
1 179 -20.0 1039 0.36122279102923893
1 180 -20.0 1016 0.36579094161316167
1 181 -20.0 980 0.37119169323420037
1 182 -19.0 1119 0.38068090463132065
1 183 -21.0 886 0.3879197574563274
1 184 -21.0 1008 0.3771201671943778
1 185 -20.0 987 0.36837333301884306
1 186 -19.0 1299 0.3674351090509401
1 187 -20.0 1085 0.36155825869828323
1 188 -21.0 811 0.3874685498627429
1 189 -20.0 1086 0.3744434340004543
1 190 -19.0 997 0.40516265900945714
1 191 -21.0 854 0.39266109463063004
1 192 -18.0 1034 0.3782503307153916
1 193 -21.0 854 0.3690578464322682
1 194 -20.0 1011 0.3700789463154522
1 195 -21.0 916 0.38408933830443426
1 196 -20.0 1024 0.3845599145570304
1 197 -20.0 842 0.3773969121259635
1 198 -20.0 1061 0.38343173588479496
1 199 -21.0 1081 0.383299861596096
1 200 -21.0 886 0.38096107286874115
1 201 -19.0 937 0.3697037233105337
1 202 -20.0 1133 0.37364261779549474
1 203 -20.0 1024 0.3789966440817807
1 204 -21.0 989 0.39744090114854824
1 205 -21.0 1068 0.3948895377333691
1 206 -19.0 1057 0.40425154690823695
1 207 -20.0 1068 0.382874078992824
1 208 -19.0 1302 0.39117117642715415
1 209 -21.0 1054 0.38065617988186495
1 210 -20.0 982 0.38068140418005086
1 211 -20.0 1206 0.39364906661150667
1 212 -21.0 1145 0.3932825408387913
1 213 -20.0 1009 0.3729612079141634
1 214 -21.0 1036 0.38541639084176205
1 215 -20.0 1191 0.3814380305540051
1 216 -20.0 1160 0.37467752648838637
1 217 -19.0 1342 0.408713534030225
1 218 -21.0 1115 0.4021625208480476
1 219 -21.0 884 0.41660289516950627
1 220 -18.0 1287 0.4184102014969186
1 221 -20.0 1008 0.40056234275892616
1 222 -21.0 964 0.413908067209592
1 223 -21.0 1188 0.42242945477316274
1 224 -21.0 907 0.4197289525411095
1 225 -19.0 1394 0.4181497470934046
1 226 -20.0 1129 0.3860357655319521
1 227 -20.0 1282 0.3901251580990421
1 228 -20.0 1132 0.4028414349884532
1 229 -19.0 1028 0.3877119962633352
1 230 -20.0 921 0.3827699982964643
1 231 -21.0 967 0.386780901680071568 0 -21.0 764 0.40253240162633475
8 1 -21.0 824 0.3893854901266908
8 2 -21.0 942 0.4082299754055189
8 3 -21.0 874 0.4089476050514924
8 4 -20.0 980 0.35548548342622055
8 5 -20.0 930 0.37645086687739177
8 6 -21.0 995 0.3914276352479829
8 7 -21.0 1008 0.3872899151451531
8 8 -21.0 885 0.3999733928906716
8 9 -20.0 919 0.36508372552506424
8 10 -21.0 872 0.35305534344200695
8 11 -21.0 824 0.3739225798946561
8 12 -21.0 964 0.3700457241896277
8 13 -21.0 912 0.37322082363984044
8 14 -20.0 870 0.39353381035656765
8 15 -20.0 1285 0.38008602781054573
8 16 -21.0 794 0.40659251264871216
8 17 -21.0 826 0.3828548444818354
8 18 -19.0 1077 0.36177143379838356
8 19 -21.0 854 0.36471302489765356
8 20 -21.0 824 0.37093187449047865
8 21 -21.0 843 0.3907665319360731
8 22 -18.0 1322 0.4089477152624217
8 23 -20.0 1008 0.37269499909783166
8 24 -21.0 824 0.39254218140996777
8 25 -21.0 852 0.4020777617541837
8 26 -20.0 1052 0.37875222845335876
8 27 -21.0 884 0.3545564754246587
8 28 -20.0 922 0.3449668097198656
8 29 -19.0 1073 0.3643505084992344
8 30 -19.0 1044 0.3479698759671372
8 31 -20.0 1174 0.3410800568239043
8 32 -21.0 764 0.34148405067115556
8 33 -21.0 912 0.3508946899193944
8 34 -21.0 764 0.3597907643589674
8 35 -21.0 1087 0.3598309402742184
8 36 -19.0 1178 0.3625138713922889
8 37 -20.0 1066 0.3637023367421041
8 38 -20.0 1131 0.3781033570422839
8 39 -21.0 824 0.3680701151273204
8 40 -19.0 1136 0.37548371281107545
8 41 -20.0 919 0.39096756783740694
8 42 -20.0 938 0.37044175506146476
8 43 -20.0 870 0.36318822064618955
8 44 -21.0 901 0.35584589121212046
8 45 -21.0 978 0.3636965242753487
8 46 -21.0 792 0.3655278883648641
8 47 -20.0 951 0.3747073567690784
8 48 -21.0 913 0.3677723468459841
8 49 -20.0 1102 0.3688211186557413
8 50 -20.0 1105 0.38868571660097906
8 51 -20.0 1010 0.4139831423464388
8 52 -21.0 948 0.4204375293687426
8 53 -21.0 888 0.441553705850163
8 54 -21.0 885 0.42323293588255756
8 55 -18.0 1177 0.39509731472905857
8 56 -20.0 1068 0.3620431357610985
8 57 -21.0 884 0.36882320494808224
8 58 -21.0 873 0.35739394612738357
8 59 -19.0 1025 0.36096026327551867
8 60 -21.0 822 0.35888780261913356
8 61 -21.0 914 0.36810868287243
8 62 -20.0 1039 0.3646927120825554
8 63 -20.0 879 0.3678979101983896
8 64 -19.0 1044 0.3636324474752178
8 65 -20.0 950 0.37939155531556984
8 66 -21.0 824 0.38145231593002393
8 67 -20.0 934 0.35777108862645113
8 68 -20.0 1207 0.3458992058122662
8 69 -21.0 792 0.35612008378210697
8 70 -21.0 783 0.3483968413271971
8 71 -21.0 919 0.3548965742396063
8 72 -20.0 904 0.3577263307782401
8 73 -21.0 826 0.366253009106576
8 74 -21.0 959 0.3734001315609631
8 75 -20.0 932 0.39941708845897805
8 76 -21.0 764 0.3752781561141863
8 77 -21.0 947 0.3726568162252432
8 78 -20.0 921 0.3541916086541713
8 79 -18.0 1213 0.3573261304817609
8 80 -21.0 764 0.3602765645266203
8 81 -21.0 1112 0.3752668084000512
8 82 -20.0 991 0.3788191744706224
8 83 -21.0 826 0.38053208142158196
8 84 -19.0 1120 0.3868765135694827
8 85 -21.0 888 0.38831293170113823
8 86 -21.0 973 0.3711554920501846
8 87 -21.0 945 0.35475903976531253
8 88 -21.0 826 0.34204795173669267
8 89 -21.0 884 0.3496023375052133
8 90 -20.0 1055 0.3627162709902813
8 91 -21.0 764 0.38818300148735496
8 92 -21.0 852 0.37485128718082894
8 93 -20.0 932 0.37169407436008617
8 94 -20.0 842 0.3885573770258036
8 95 -21.0 792 0.3875784288828421
8 96 -20.0 1010 0.37941680751224555
8 97 -20.0 842 0.3769222632439856
8 98 -21.0 884 0.3987934236073386
8 99 -21.0 824 0.39651336824720346
8 100 -19.0 1181 0.38859310042141454
8 101 -20.0 981 0.4050702075953391
8 102 -21.0 824 0.4077585261423611
8 103 -20.0 1025 0.42812948491515185
8 104 -21.0 933 0.4005157878544553
8 105 -20.0 1024 0.42439159320201725
8 106 -20.0 956 0.41162327268632387
8 107 -20.0 842 0.41988513478898665
8 108 -21.0 843 0.4245726676173906
8 109 -21.0 824 0.3992494528805747
8 110 -20.0 962 0.3734532034880406
8 111 -20.0 930 0.38644745487679716
8 112 -20.0 938 0.41902858937091664
8 113 -20.0 921 0.3959110837741214
8 114 -20.0 1038 0.3666099333177412
8 115 -21.0 826 0.3984442347836552
8 116 -20.0 1014 0.40277771401922613
8 117 -20.0 981 0.39652738057145287
8 118 -21.0 946 0.3733686904007486
8 119 -21.0 824 0.3678369611429358
8 120 -20.0 1038 0.3662037862346352
8 121 -20.0 1099 0.35362327896106016
8 122 -19.0 1086 0.35603961340300944
8 123 -21.0 973 0.35177315871125014
8 124 -21.0 915 0.35565035909902853
8 125 -21.0 944 0.35448188647248985
8 126 -20.0 1132 0.36347617519617925
8 127 -21.0 995 0.3762562132061426
8 128 -21.0 824 0.3889541315294585
8 129 -20.0 1241 0.38244077584899117
8 130 -20.0 941 0.403096665706442
8 131 -21.0 905 0.41351449186630673
8 132 -20.0 1115 0.416001461386146
8 133 -21.0 856 0.36873394177756574
8 134 -21.0 904 0.36426919715198797
8 135 -20.0 1041 0.3645025950343877
8 136 -21.0 783 0.3823266211673522
8 137 -20.0 991 0.38552807369217745
8 138 -21.0 1045 0.3564723138889057
8 139 -20.0 1161 0.3779799427121595
8 140 -17.0 1216 0.36598982103168964
8 141 -21.0 1073 0.37124212612532503
8 142 -20.0 871 0.3809664124188823
8 143 -21.0 972 0.37444366750771124
8 144 -21.0 852 0.3778958313621825
8 145 -19.0 1058 0.3785844841841714
8 146 -20.0 947 0.36959973874540236
8 147 -19.0 1105 0.37306936491129083
8 148 -20.0 963 0.3582129700347271
8 149 -20.0 842 0.37092069984190257
8 150 -21.0 880 0.3798410868441517
8 151 -20.0 980 0.35938323946023476
8 152 -20.0 1418 0.3597135217006519
8 153 -19.0 1130 0.3636763030976321
8 154 -20.0 887 0.3537872819043066
8 155 -19.0 997 0.3576648805959294
8 156 -21.0 826 0.35516654449282775
8 157 -21.0 1007 0.3708548192471236
8 158 -21.0 904 0.36621097870896346
8 159 -19.0 1184 0.3686151975463774
8 160 -20.0 842 0.38234863754122955
8 161 -21.0 933 0.38181832605236216
8 162 -20.0 980 0.3645971831618523
8 163 -21.0 824 0.3596166485866297
8 164 -21.0 991 0.36702793812535245
8 165 -21.0 783 0.37969235792318373
8 166 -21.0 1152 0.36507479611059857
8 167 -19.0 1060 0.3700747979137133
8 168 -21.0 915 0.363291755562923
8 169 -19.0 1164 0.3802915819731775
8 170 -21.0 824 0.3836726031257111
8 171 -20.0 1008 0.3766907674097826
8 172 -20.0 900 0.37276047309239707
8 173 -20.0 1044 0.3778247796712707
8 174 -17.0 1294 0.365919114633174
8 175 -20.0 842 0.3674769434113401
8 176 -21.0 886 0.3671656874918776
8 177 -21.0 1034 0.3631731356481519
8 178 -20.0 1052 0.36097355393742425
8 179 -20.0 981 0.36138844933592457
8 180 -21.0 988 0.382454668341378
8 181 -20.0 930 0.3808319758022985
8 182 -21.0 853 0.3953054158447216
8 183 -20.0 902 0.3631141103490229
8 184 -21.0 1098 0.37855450882286323
8 185 -21.0 914 0.36281124376885476
8 186 -20.0 921 0.35902581670514666
8 187 -21.0 963 0.3763122196509459
8 188 -20.0 902 0.37628894092767046
8 189 -21.0 884 0.3857914195880631
8 190 -21.0 1096 0.40137436075040894
8 191 -19.0 1051 0.38796086310206085
8 192 -20.0 1085 0.36667090404418207
8 193 -21.0 1038 0.37042807723056376
8 194 -19.0 1102 0.38418028980980334
8 195 -21.0 871 0.39121074675145023
8 196 -21.0 964 0.37786914649346065
8 197 -20.0 1009 0.37932682353394
8 198 -20.0 842 0.3693408557609821
8 199 -20.0 1023 0.37991295182460216
8 200 -21.0 964 0.3742602539260358
8 201 -20.0 1030 0.3709444793682654
8 202 -21.0 856 0.37121599884790796
8 203 -20.0 1283 0.39612396129944877
8 204 -20.0 898 0.38385652938239556
8 205 -21.0 993 0.41292921065803984
8 206 -21.0 885 0.40702895788149646
8 207 -17.0 1477 0.38629468472405876
8 208 -21.0 1007 0.37461599417570923
8 209 -19.0 1077 0.3757296889992699
8 210 -20.0 949 0.37396845846457527
8 211 -21.0 792 0.3782839961349964
8 212 -20.0 991 0.40050629103099544
8 213 -19.0 1284 0.38445661996848113
8 214 -20.0 879 0.3662805555894784
8 215 -20.0 903 0.36918315558734527
8 216 -20.0 1068 0.3784261319632834
8 217 -19.0 1036 0.393992598999191
8 218 -21.0 924 0.410151392447226
8 219 -20.0 1211 0.4267668279855336
8 220 -20.0 1251 0.40171984902960506
8 221 -20.0 1132 0.4191624492722771
8 222 -19.0 1140 0.41218181098239465
8 223 -19.0 1156 0.40345753984570915
8 224 -21.0 1068 0.4019454698381799
8 225 -19.0 1428 0.4070046914308345
8 226 -21.0 783 0.3877486793626466
8 227 -21.0 1006 0.3979854558559346
8 228 -21.0 966 0.4080242321172856
8 229 -19.0 1060 0.3838688331111422
8 230 -19.0 1117 0.3816977433306678
8 231 -20.0 1150 0.4011263950752175
8 232 6 0 -21.0 764 0.398507404701872
6 1 -20.0 881 0.38035286700820276
6 2 -20.0 949 0.3947022340257502
6 3 -21.0 853 0.4126723111025194
6 4 -20.0 1254 0.35771021491697913
6 5 -21.0 887 0.381598460465972
6 6 -21.0 875 0.38543192056247166
6 7 -21.0 826 0.3927619072989748
6 8 -19.0 982 0.3845546597011706
6 9 -21.0 783 0.3615837226958415
6 10 -20.0 930 0.35982410558449324
6 11 -21.0 1004 0.3762581364448327
6 12 -21.0 946 0.369280779210508
6 13 -20.0 976 0.39329756897126067
6 14 -21.0 886 0.384144115865096
6 15 -19.0 1117 0.3957377540392863
6 16 -21.0 880 0.3803187468173829
6 17 -20.0 959 0.3576597971948518
6 18 -21.0 824 0.37252847333122224
6 19 -21.0 885 0.36781860768458263
6 20 -21.0 824 0.39655916924470835
6 21 -21.0 843 0.4164531937980426
6 22 -18.0 1182 0.3783119793622022
6 23 -19.0 1042 0.39313730331506014
6 24 -19.0 1130 0.39734847405842977
6 25 -21.0 944 0.36140062028573733
6 26 -21.0 783 0.35107502173798905
6 27 -20.0 923 0.34467165706475406
6 28 -21.0 852 0.3676271071316491
6 29 -21.0 824 0.34657075400780707
6 30 -20.0 842 0.3420490166990887
6 31 -20.0 1022 0.3450790665562605
6 32 -21.0 944 0.35117008240293646
6 33 -20.0 921 0.3646253539930855
6 34 -21.0 991 0.3569539492775044
6 35 -20.0 959 0.36297219811440506
6 36 -21.0 824 0.36161913274271973
6 37 -21.0 764 0.3756850884144843
6 38 -21.0 824 0.3776439640273168
6 39 -21.0 826 0.37045214070823523
6 40 -21.0 825 0.3781498956680298
6 41 -21.0 871 0.39179553425134117
6 42 -21.0 973 0.3703549660795884
6 43 -21.0 824 0.3640872839729763
6 44 -19.0 1135 0.3578967823331051
6 45 -21.0 916 0.36114006173923024
6 46 -21.0 1095 0.3719572705220958
6 47 -21.0 914 0.370354197935672
6 48 -21.0 885 0.36543118704510275
6 49 -19.0 1054 0.3862721362138835
6 50 -20.0 979 0.398577454841417
6 51 -19.0 1149 0.42089987423650277
6 52 -21.0 826 0.44415776326927664
6 53 -21.0 824 0.42547925398911085
6 54 -21.0 932 0.4027469274887711
6 55 -20.0 1048 0.37467183152796657
6 56 -21.0 1001 0.36570128792530293
6 57 -21.0 885 0.36043368379275004
6 58 -21.0 886 0.3565267368848383
6 59 -20.0 1023 0.3586801274780654
6 60 -21.0 824 0.3690638302020656
6 61 -19.0 1122 0.36992670303466274
6 62 -21.0 811 0.36526217692877305
6 63 -19.0 1228 0.3672017948004244
6 64 -21.0 887 0.3842537185385101
6 65 -21.0 884 0.37450510988273233
6 66 -20.0 872 0.3493136173336331
6 67 -20.0 956 0.34692754643232754
6 68 -21.0 826 0.35376423063347473
6 69 -19.0 980 0.35035340776857066
6 70 -19.0 1026 0.3614878509534962
6 71 -17.0 1230 0.36424293118279155
6 72 -18.0 1216 0.3863782374384372
6 73 -20.0 962 0.38599668093134115
6 74 -21.0 912 0.37540569535472934
6 75 -20.0 1242 0.3608234471457016
6 76 -21.0 940 0.3538327529075298
6 77 -21.0 886 0.36135970735523015
6 78 -21.0 963 0.379080766519901
6 79 -20.0 981 0.37850915082368647
6 80 -21.0 824 0.38326573549109755
6 81 -21.0 945 0.3890563702772534
6 82 -21.0 973 0.3871364643431641
6 83 -21.0 854 0.3734124184562116
6 84 -20.0 842 0.35764357822807835
6 85 -21.0 843 0.343875397884973
6 86 -21.0 933 0.34969364357403493
6 87 -21.0 884 0.36409368406458675
6 88 -19.0 981 0.378778819127671
6 89 -21.0 992 0.3700601571509915
6 90 -20.0 947 0.3841410844479594
6 91 -21.0 905 0.3870986913449198
6 92 -21.0 934 0.38333551387843023
6 93 -20.0 962 0.37699386111911765
6 94 -21.0 792 0.39751882900041763
6 95 -20.0 948 0.3927321852762488
6 96 -21.0 986 0.3883684879928283
6 97 -21.0 1099 0.409311944701869
6 98 -21.0 824 0.40454918967144005
6 99 -21.0 852 0.43221345967110336
6 100 -21.0 912 0.4019935369949069
6 101 -21.0 825 0.4215789464387027
6 102 -21.0 792 0.41174817137946984
6 103 -21.0 794 0.4155679750127216
6 104 -20.0 1024 0.42381990954163484
6 105 -21.0 783 0.39976665861000654
6 106 -19.0 1182 0.37585102536048987
6 107 -20.0 980 0.3885431749176006
6 108 -20.0 1068 0.41876574655931986
6 109 -21.0 824 0.37914049882188583
6 110 -21.0 824 0.36627292889848495
6 111 -21.0 783 0.4017149878339901
6 112 -21.0 974 0.3966029510666947
6 113 -21.0 854 0.39741121120838147
6 114 -21.0 886 0.37252177755531285
6 115 -21.0 845 0.36784062135149037
6 116 -20.0 1102 0.357866809150701
6 117 -20.0 1100 0.3512634342637929
6 118 -21.0 1006 0.35819033294856906
6 119 -20.0 1009 0.3510761307063259
6 120 -21.0 873 0.35481660417947847
6 121 -21.0 965 0.3612246881186036
6 122 -21.0 1008 0.36251871429738547
6 123 -20.0 960 0.3842890135633449
6 124 -21.0 843 0.3874520457936351
6 125 -20.0 919 0.37577042875404065
6 126 -19.0 948 0.4130232235110259
6 127 -21.0 820 0.4107812785884229
6 128 -21.0 792 0.4166935719549656
6 129 -21.0 901 0.3829900353452342
6 130 -20.0 844 0.36585498184530657
6 131 -18.0 1111 0.35823867240003593
6 132 -20.0 902 0.38018248132750093
6 133 -20.0 1117 0.3763609857781187
6 134 -21.0 1092 0.3628610740159894
6 135 -20.0 1085 0.3790327951380734
6 136 -20.0 983 0.36227190652189517
6 137 -20.0 1159 0.3695984497679216
6 138 -20.0 902 0.3780677254805279
6 139 -20.0 872 0.37834410697495174
6 140 -21.0 914 0.39118960431289884
6 141 -21.0 905 0.3742112888157038
6 142 -20.0 1022 0.36500332039396355
6 143 -21.0 1124 0.37958217573971936
6 144 -20.0 1178 0.37581645642962236
6 145 -21.0 824 0.4003026073852789
6 146 -21.0 972 0.37513116630629745
6 147 -21.0 887 0.35891412183423993
6 148 -20.0 921 0.3544566247219889
6 149 -21.0 931 0.36068612212269185
6 150 -21.0 854 0.35471676436604044
6 151 -20.0 947 0.3559284759675563
6 152 -21.0 824 0.3625124252753929
6 153 -21.0 871 0.3608679080255817
6 154 -21.0 783 0.3622844304085387
6 155 -20.0 934 0.3712942521436822
6 156 -20.0 990 0.3778580248656899
6 157 -20.0 1101 0.3770731176494144
6 158 -19.0 1098 0.36199542831202025
6 159 -21.0 1046 0.3675950159591197
6 160 -21.0 885 0.37622630043891864
6 161 -18.0 1183 0.3713025375633852
6 162 -20.0 981 0.3786758306558708
6 163 -21.0 792 0.38343826327661074
6 164 -19.0 1107 0.3756717716990663
6 165 -21.0 783 0.3807615315396515
6 166 -21.0 843 0.3778439101940938
6 167 -20.0 1039 0.3760867731231583
6 168 -21.0 1010 0.37410107325799397
6 169 -20.0 878 0.37120271913690284
6 170 -21.0 962 0.3717673684851791
6 171 -21.0 903 0.3600589601304444
6 172 -20.0 887 0.3693040875463905
6 173 -20.0 1056 0.36004616630574066
6 174 -21.0 975 0.3633728654873677
6 175 -21.0 914 0.37804916201065614
6 176 -21.0 884 0.3751475252042529
6 177 -21.0 886 0.3991248523543166
6 178 -21.0 885 0.36577780152444783
6 179 -21.0 783 0.36731846590608475
6 180 -20.0 947 0.37260812590215375
6 181 -20.0 966 0.37124622401860435
6 182 -21.0 884 0.3612580271732753
6 183 -21.0 1093 0.38355657142013555
6 184 -21.0 974 0.3812083576249391
6 185 -20.0 1079 0.4051204007239779
6 186 -21.0 852 0.3913992604879146
6 187 -19.0 1072 0.37000553963233285
6 188 -21.0 913 0.3723175019384867
6 189 -21.0 783 0.3787762935286433
6 190 -21.0 852 0.3872747807785379
6 191 -21.0 1038 0.3811864782275492
6 192 -19.0 1240 0.3804724894704357
6 193 -19.0 1180 0.3754096307744414
6 194 -20.0 964 0.37916408030942267
6 195 -21.0 912 0.3679349560029151
6 196 -20.0 1089 0.36631651158394124
6 197 -21.0 764 0.4178394470461376
6 198 -20.0 931 0.3968480237060408
6 199 -21.0 888 0.3867999067244766
6 200 -21.0 966 0.40987049447330137
6 201 -20.0 979 0.3781196948395808
6 202 -19.0 1133 0.37890752492388685
6 203 -21.0 824 0.3760524286879498
6 204 -21.0 843 0.3666848262080377
6 205 -20.0 932 0.37758947835331824
6 206 -21.0 843 0.38412632802910085
6 207 -19.0 1229 0.3831174812538048
6 208 -20.0 1098 0.37680657224251274
6 209 -21.0 826 0.40373221382534824
6 210 -21.0 854 0.40969915743873603
6 211 -21.0 1133 0.37993720605219766
6 212 -18.0 1058 0.38425510758375625
6 213 -21.0 934 0.4048462391091108
6 214 -20.0 1161 0.4237249058500433
6 215 -21.0 824 0.4250467759963957
6 216 -21.0 1067 0.4229692357828825
6 217 -21.0 910 0.40865762312333664
6 218 -20.0 1026 0.3957067851202297
6 219 -21.0 1162 0.4171653394547264
6 220 -21.0 1034 0.41997879489939266
6 221 -20.0 1112 0.38901309939704354
6 222 -20.0 1041 0.3850257208035842
6 223 -20.0 1166 0.40370334804978214
6 224 -19.0 1222 0.3863924094483427
6 225 -21.0 886 0.37401589704151883
6 226 -21.0 845 0.38405648692119754
6 227 -21.0 995 0.4122293171271607
6 228 -19.0 1144 0.40462275320937585
6 229 -21.0 931 0.3792405525416488
6 230 -20.0 1100 0.4012187215143984
6 231 -20.0 1020 0.3868759793685932
6 232 -19.0 1076 0.3965335933415429 0 -20.0 979 0.39561470545470656
9 1 -21.0 884 0.3784094914389412
9 2 -20.0 942 0.41175175361699107
9 3 -21.0 973 0.39518361481218645
9 4 -18.0 1267 0.35794936422767276
9 5 -20.0 842 0.3885230809591728
9 6 -21.0 843 0.38469629108128034
9 7 -21.0 900 0.39010991745524937
9 8 -20.0 1160 0.3772745159936362
9 9 -20.0 1112 0.35449094097498507
9 10 -21.0 843 0.36893277292715415
9 11 -19.0 1078 0.3718574365293382
9 12 -20.0 932 0.38449345337218993
9 13 -19.0 1108 0.3879064498771829
9 14 -20.0 930 0.37667052470227724
9 15 -21.0 783 0.4053425421964468
9 16 -21.0 792 0.374492035482568
9 17 -21.0 843 0.3636462896319895
9 18 -20.0 1020 0.3645967978764983
9 19 -20.0 1008 0.3728973480562369
9 20 -21.0 812 0.3972866854864388
9 21 -21.0 764 0.4138383848192804
9 22 -21.0 947 0.37724704016098376
9 23 -21.0 844 0.38244102669270685
9 24 -20.0 905 0.39820641269341356
9 25 -21.0 972 0.3925956333738296
9 26 -20.0 1043 0.356663950880559
9 27 -20.0 922 0.34694332779746767
9 28 -21.0 823 0.35622503350456025
9 29 -21.0 764 0.35953245272967205
9 30 -21.0 824 0.34351342482474245
9 31 -21.0 965 0.345276188479804
9 32 -21.0 974 0.34302351227531197
9 33 -20.0 902 0.35371749324439106
9 34 -21.0 764 0.3686498729268294
9 35 -20.0 900 0.3559122535586357
9 36 -21.0 886 0.3655770543130203
9 37 -20.0 871 0.36259226820909607
9 38 -20.0 962 0.3763203836218483
9 39 -20.0 978 0.3718514146553714
9 40 -18.0 1045 0.3726104672160445
9 41 -20.0 842 0.39190189359873323
9 42 -20.0 843 0.378377694110712
9 43 -21.0 960 0.36860634529342257
9 44 -19.0 981 0.35808608959695737
9 45 -20.0 921 0.36265226642031884
9 46 -21.0 764 0.3624637103907725
9 47 -21.0 903 0.37351334035594597
9 48 -20.0 1042 0.36876261774843805
9 49 -19.0 1059 0.3653496698290813
9 50 -20.0 897 0.38937458814585885
9 51 -19.0 1017 0.40329185711364596
9 52 -19.0 1297 0.421096339925216
9 53 -21.0 824 0.44207769675740916
9 54 -21.0 945 0.42344536872767896
9 55 -21.0 824 0.39829073886124833
9 56 -21.0 911 0.3703890785362273
9 57 -20.0 842 0.36329023642664565
9 58 -20.0 1009 0.3636056202195208
9 59 -21.0 852 0.3569187530679322
9 60 -21.0 900 0.35702515191502043
9 61 -21.0 792 0.3653425441471615
9 62 -20.0 1051 0.3623506981457675
9 63 -21.0 884 0.37592937672569743
9 64 -21.0 884 0.36473013123505793
9 65 -21.0 872 0.36583748080451556
9 66 -20.0 1033 0.38369919574618455
9 67 -21.0 884 0.3701201708338379
9 68 -21.0 848 0.3517941839571269
9 69 -18.0 1152 0.35120504070073366
9 70 -21.0 903 0.35069509588206726
9 71 -21.0 792 0.34976820839625417
9 72 -20.0 930 0.36054535049905057
9 73 -20.0 1039 0.3645538656440805
9 74 -21.0 824 0.3755529079477764
9 75 -19.0 1268 0.3945487530590608
9 76 -21.0 887 0.3708018159584101
9 77 -20.0 1163 0.3613234821928029
9 78 -21.0 946 0.36033283155135826
9 79 -21.0 884 0.3581222124498894
9 80 -21.0 792 0.36631826473155404
9 81 -19.0 1156 0.3854901008694642
9 82 -20.0 902 0.3767486554291719
9 83 -20.0 1201 0.386276397180994
9 84 -21.0 842 0.39156790576751327
9 85 -20.0 1102 0.373109695104419
9 86 -19.0 1025 0.3579867350764391
9 87 -20.0 902 0.34545109587868145
9 88 -20.0 1159 0.3526504824807461
9 89 -21.0 946 0.37668078306109404
9 90 -21.0 764 0.3831516086119008
9 91 -19.0 1074 0.37260281420841784
9 92 -21.0 946 0.39095149527896533
9 93 -20.0 980 0.38574490723561267
9 94 -21.0 946 0.374723583144819
9 95 -19.0 1243 0.3870459574417826
9 96 -21.0 824 0.39719923672456187
9 97 -21.0 911 0.38257550610930674
9 98 -21.0 826 0.39756962213187186
9 99 -20.0 1023 0.4039402847066303
9 100 -20.0 965 0.4156905818170834
9 101 -21.0 1006 0.4157181703013407
9 102 -20.0 904 0.4179747692779102
9 103 -21.0 824 0.41817406413045904
9 104 -21.0 964 0.41658411576911125
9 105 -21.0 1062 0.43517248203413184
9 106 -21.0 792 0.40525553751774507
9 107 -18.0 1116 0.3715071301359857
9 108 -21.0 1051 0.3863841446664195
9 109 -21.0 1071 0.420391364452663
9 110 -21.0 880 0.3889709574932402
9 111 -21.0 783 0.3648881672442644
9 112 -18.0 1016 0.3981552222582299
9 113 -21.0 825 0.39819352438955596
9 114 -21.0 783 0.39938734622141714
9 115 -20.0 842 0.37247235248321026
9 116 -18.0 1089 0.3726601059607566
9 117 -21.0 911 0.3611339888444455
9 118 -20.0 1019 0.35452642109723975
9 119 -21.0 852 0.3489919632603305
9 120 -20.0 993 0.35111585496535597
9 121 -20.0 982 0.35434585761149884
9 122 -20.0 842 0.3502279326779825
9 123 -20.0 990 0.3582527129036007
9 124 -19.0 998 0.3651510967699464
9 125 -21.0 824 0.3940214745483352
9 126 -20.0 1024 0.38813034413033165
9 127 -21.0 845 0.38615968629453307
9 128 -21.0 825 0.43839260614279546
9 129 -19.0 1223 0.4158569608715257
9 130 -21.0 945 0.3813575795718602
9 131 -19.0 1018 0.3604375914119784
9 132 -21.0 783 0.3534766920529411
9 133 -20.0 1100 0.37768293299458244
9 134 -20.0 898 0.38251941599665346
9 135 -20.0 989 0.3600179491860319
9 136 -20.0 931 0.3753973472579337
9 137 -20.0 844 0.36667920317130065
9 138 -21.0 824 0.36462647272545157
9 139 -20.0 1042 0.3717361641708125
9 140 -20.0 903 0.3788345640283882
9 141 -19.0 920 0.3742310626351315
9 142 -21.0 946 0.388839063445307
9 143 -20.0 1025 0.36875512253947373
9 144 -21.0 884 0.36576275429709465
9 145 -21.0 912 0.38378394254597653
9 146 -21.0 908 0.35719272599346313
9 147 -19.0 1179 0.3820711693792044
9 148 -20.0 948 0.370784102675784
9 149 -18.0 1399 0.362468606876935
9 150 -19.0 1032 0.3602930859828642
9 151 -20.0 965 0.35944263039475277
9 152 -21.0 944 0.360176291853442
9 153 -21.0 915 0.3579825727014594
9 154 -21.0 1025 0.3756379860784949
9 155 -20.0 1041 0.36231263624602617
9 156 -20.0 1043 0.3608373914731886
9 157 -20.0 1009 0.37719726343929944
9 158 -21.0 872 0.37992933409613205
9 159 -20.0 925 0.36540429492254517
9 160 -20.0 902 0.36347411734830515
9 161 -21.0 973 0.36083910959597604
9 162 -21.0 794 0.3825823776142423
9 163 -20.0 1054 0.36421449273202633
9 164 -21.0 945 0.3783668192606124
9 165 -19.0 1075 0.3683605309419854
9 166 -19.0 948 0.38154270936919665
9 167 -20.0 887 0.3819468087582873
9 168 -19.0 1016 0.37081897428889915
9 169 -19.0 1033 0.37084003688635925
9 170 -20.0 980 0.3834819802216121
9 171 -21.0 1036 0.3763892820615566
9 172 -21.0 1006 0.3856516043187136
9 173 -20.0 1098 0.36621940695088634
9 174 -20.0 898 0.3607922061315358
9 175 -20.0 980 0.3588729800314319
9 176 -20.0 879 0.3675940487368522
9 177 -20.0 932 0.396406554069386
9 178 -21.0 1006 0.3784377277193676
9 179 -21.0 824 0.36568183896755707
9 180 -20.0 932 0.37529952958418067
9 181 -20.0 963 0.365600982187693
9 182 -21.0 821 0.3690422229223797
9 183 -21.0 913 0.36341489317774905
9 184 -21.0 886 0.3769451232446236
9 185 -20.0 1069 0.3785039330610502
9 186 -21.0 912 0.38899208938604907
9 187 -21.0 972 0.4019338361029762
9 188 -21.0 852 0.388155943141297
9 189 -20.0 842 0.3669650928778773
9 190 -20.0 1146 0.3728677879817407
9 191 -20.0 1100 0.37967974784699354
9 192 -21.0 943 0.38317266792406585
9 193 -20.0 1040 0.376123170583294
9 194 -20.0 1213 0.38322049249132506
9 195 -21.0 1038 0.3884049508153588
9 196 -20.0 1009 0.3828999111862674
9 197 -21.0 1063 0.3701159038133253
9 198 -21.0 948 0.3769265854660469
9 199 -20.0 1348 0.3995884733180618
9 200 -21.0 1340 0.38959010041026926
9 201 -21.0 886 0.4089100838514806
9 202 -20.0 1084 0.37320866177332795
9 203 -21.0 824 0.3659801697268069
9 204 -21.0 884 0.37515967929255367
9 205 -21.0 944 0.3700393730364108
9 206 -20.0 951 0.3768071422253497
9 207 -21.0 933 0.402201103212238
9 208 -20.0 904 0.3826021910439023
9 209 -21.0 845 0.38148713048393207
9 210 -20.0 1385 0.3791146789862361
9 211 -21.0 886 0.37318504445305256
9 212 -21.0 1006 0.3923100866155169
9 213 -21.0 949 0.3893315311917766
9 214 -20.0 1404 0.4091669697410021
9 215 -18.0 1070 0.3991280420918331
9 216 -20.0 1008 0.4067387234064795
9 217 -21.0 978 0.3993737286829022
9 218 -19.0 1086 0.39984812984040646
9 219 -19.0 1197 0.4000330234729158
9 220 -21.0 1035 0.40361008344641053
9 221 -16.0 1288 0.3982948253382437
9 222 -19.0 1123 0.3957284029742383
9 223 -17.0 1264 0.3827281585552647
9 224 -20.0 1347 0.4089598488878478
9 225 -20.0 1021 0.391517088444763
9 226 -19.0 1154 0.38573534665322595
9 227 -20.0 1174 0.4015495068119169
9 228 -20.0 994 0.3903458087856861
9 229 -20.0 1382 0.3959161437152954
9 230 -21.0 950 0.3910751027809946
9 231 -21.0 1266 0.3994753327320726
9 232 -19.0 958 0.39030482406904904